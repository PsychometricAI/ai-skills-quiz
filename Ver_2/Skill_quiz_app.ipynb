{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6049cee",
   "metadata": {},
   "source": [
    "Quiz web-application development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101bd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa71e9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read:  quiz_v2_2025_11_21.csv\n",
      "Number rows: 137\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "task_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "option_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "option_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "option_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "option_4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correct_answer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "probability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Explanation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "skill_definition",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f055d13f-9479-43bd-9281-69b686c72307",
       "rows": [
        [
         "0",
         "1",
         "Accelerated Tensor Programming",
         "In an AI inference service on GPUs, what does Accelerated Tensor Programming mainly target to boost throughput?",
         "Using tensor cores, fused GEMM, tiling, and PTX to maximize throughput",
         "Refactoring Python loops and pandas joins to simplify data preprocessing",
         "Encrypting checkpoints and rotating IAM keys to harden runtime security",
         "Extending context windows via retrieval to improve prompt adherence",
         "1",
         "0.7",
         "It focuses on low-level GPU math and kernel optimizations like GEMM, tensor cores, and tiling.",
         "Develop and optimize matrix and tensor computations on GPUs and TPUs using SIMD/AVX2, tensor cores, GEMM, loop tiling, and PTX to maximize throughput. Leverage ONNX Runtime or TensorRT with distributed trainers like Ray Train and OneTrainer, apply dtensor for partitioning, and monitor and tune Cloud TPU workloads with TensorBoard and TPU tooling."
        ],
        [
         "1",
         "2",
         "Adaptive Decision Optimization",
         "When deploying an AI system under uncertainty, what best characterizes Adaptive Decision Optimization?",
         "Using contextual bandits, MDPs, and MPC to tune actions under uncertainty",
         "Selecting static thresholds from historical A/B tests without exploration",
         "Encoding business rules in fixed if-else trees for deterministic outcomes",
         "Scaling batch inference by adding GPUs without behavior modeling",
         "1",
         "0.62",
         "It uses stochastic methods like bandits, MDPs, and MPC to adapt decisions to changing contexts.",
         "Design, implement, and tune adaptive, stochastic decision-making systems using methods like contextual bandits, MDP/MCTS, MPC, evolutionary algorithms, and Monte Carlo sampling to optimize outcomes under uncertainty. Select and configure algorithms, set decision thresholds, and deploy data-driven sampling and behavior trees to improve performance in dynamic environments."
        ],
        [
         "2",
         "3",
         "Advanced RAG Engineering",
         "In production LLM apps, what defines Advanced RAG Engineering beyond basic retrieval?",
         "Using agentic, corrective, and graph-aware retrieval with rigorous RAG evaluation",
         "Only increasing embedding dimensions to improve nearest neighbor recall",
         "Relying on static FAQs without vector or graph store integration",
         "Moving prompts to serverless functions to reduce memory costs",
         "1",
         "0.66",
         "Advanced RAG integrates vector and graph stores and tunes pipelines with dedicated RAG evaluations.",
         "Design, build, and optimize retrieval-augmented generation systems across text, vision, and video, including agentic, corrective, self-RAG, and graph/RDF variants. Integrate vector and graph stores, apply RAFT and RIG when appropriate, and evaluate and tune pipelines using RAG frameworks and Ragas."
        ],
        [
         "3",
         "4",
         "AI 3D Content Generation",
         "For AI-driven 3D asset creation from 2D inputs, what is the core capability?",
         "Training 3D neural models with depth estimation and generative rendering",
         "Compressing textures with ZIP to reduce asset download times",
         "Hosting static GLTF files on a CDN with cache headers",
         "Tracking user clicks to optimize UX funnels in analytics",
         "1",
         "0.63",
         "It focuses on 3D deep learning, depth inference, and generative rendering for assets and scenes.",
         "Design, train, and deploy 3D deep learning pipelines to reconstruct, generate, and animate assets and scenes from scans or 2D inputs. Apply 3D neural networks, depth estimation, and generative rendering to automate avatar creation, environment builds, and simulations."
        ],
        [
         "4",
         "5",
         "AI Accelerator Engineering",
         "In building custom AI chips, what is a primary focus of AI Accelerator Engineering?",
         "Designing compute and memory hierarchies with firmware for low-latency AI",
         "Creating React dashboards for model observability and user feedback",
         "Writing high-level prompts to guide chat agents on product FAQs",
         "Configuring IAM groups to manage developer permissions for APIs",
         "1",
         "0.59",
         "It targets chip architecture, memory, firmware, and accelerator programming for efficient AI compute.",
         "Architect, implement, and optimize AI accelerators and custom AI chips (ASIC/NPU), covering compute architecture, memory hierarchy, chiplet integration, and firmware to maximize throughput, minimize latency, and improve energy efficiency. Apply accelerator programming and hardware design flows on ARM, Apple Silicon, and specialized processors to take designs from concept to validation."
        ],
        [
         "5",
         "6",
         "AI Agent Engineering",
         "What best describes AI Agent Engineering for a production assistant?",
         "Building autonomous agents with planning loops, tools, state, and security",
         "Only tuning prompts to increase helpfulness without tool use",
         "Serving a single LLM endpoint without workflow orchestration",
         "Exporting logs to CSV for manual error inspection weekly",
         "1",
         "0.7",
         "Agents require planning, tool use, state management, protocols, and secure orchestration.",
         "Design, program, and deploy autonomous AI agents using agent frameworks and SDKs, implementing communication protocols, planning and coordination loops, state management, security, and interoperability. Orchestrate agent workflows end-to-end, and test, debug, and monitor agents from development through production."
        ],
        [
         "6",
         "7",
         "AI API Engineering",
         "In exposing AI models via APIs, what is the key concern for AI API Engineering?",
         "Secure, performant REST endpoints with keys, rotation, and rate limits",
         "Training larger models to avoid endpoint timeouts and throttling",
         "Hardcoding admin tokens in clients to simplify authentication",
         "Replacing HTTP with SMTP to reduce network latency",
         "1",
         "0.75",
         "It centers on secure API design, key management, rate limiting, and performance monitoring.",
         "Designs, builds, and integrates REST/HTTP APIs and gateways for accessing AI models and services, with secure key management, credential rotation, endpoint design, and performance optimization. Uses API management and APM tools to monitor, scale, and optimize requests, rate limits, and latency for reliable AI application delivery."
        ],
        [
         "7",
         "8",
         "AI Application and Platform Engineering",
         "What best defines AI Application and Platform Engineering in production?",
         "Designing scalable AI systems with pipelines, APIs, and monitoring on Linux",
         "Writing only research notebooks without deployment automation",
         "Embedding images in markdown to document experiment results",
         "Manually copying models to servers without version control",
         "1",
         "0.74",
         "It covers architecture, tooling, lifecycle management, deployment, and operations at scale.",
         "Designs, builds, and deploys AI-powered applications and platforms by defining system architecture, selecting frameworks and programming languages, developing prototypes and tools, and managing the full ML lifecycle from development to production in Linux-based environments. Implements deployment pipelines, APIs and protocols, monitoring, and project management practices to operationalize and scale AI services."
        ],
        [
         "8",
         "9",
         "AI Compliance and Licensing",
         "In deploying an AI app to regulated markets, what is essential for compliance?",
         "Automating license tracking, privacy checks, and evidence collection",
         "Favoring larger models to minimize regulatory scope and scrutiny",
         "Relying on public datasets to avoid data residency rules",
         "Skipping audits because models are open source and free",
         "1",
         "0.69",
         "Compliance requires tracking licenses, verifying privacy/security controls, and audit evidence.",
         "Ability to design, implement, and audit processes that ensure AI systems comply with privacy, security, and regulatory requirements (GDPR, HIPAA, FedRAMP, data residency) and organizational policies. Covers copyright and fair-use risk management, data and model license selection and tracking (e.g., MIT), automated compliance verification and evidence collection, and policy enforcement across the ML lifecycle."
        ],
        [
         "9",
         "10",
         "AI Computational Design",
         "What describes AI Computational Design in scientific product development?",
         "Combining ML with simulations for molecular and materials design",
         "Only using linear regression to analyze sales performance",
         "Optimizing CSS layouts for responsive web components",
         "Sending batch emails to recruit study participants",
         "1",
         "0.58",
         "It integrates ML and physics-based simulation to analyze and optimize complex designs.",
         "Build and integrate machine learning and physics-based simulation workflows to analyze omics data, predict molecular and material properties, and optimize designs using protein and chemical language models, Alphafold, CFD, and CAD/CAE. Develop end-to-end pipelines from genomic analysis and molecular modeling to parametric design and digital fabrication to accelerate discovery and product development."
        ],
        [
         "10",
         "11",
         "AI Content Moderation",
         "When building a moderation layer for an AI chatbot, what is key?",
         "AI-based detection with tuned thresholds and escalation workflows",
         "Using random sampling to approve most messages quickly",
         "Encrypting prompts so the model cannot read harmful inputs",
         "Serving images at lower resolution to reduce offense risk",
         "1",
         "0.77",
         "Effective moderation uses AI detectors, thresholds, and escalation while monitoring bias.",
         "Ability to design and implement AI-driven content moderation pipelines that detect and filter unsafe or policy-violating text and images. Includes integrating moderation APIs (e.g., OpenAI), tuning thresholds, managing escalation workflows, and monitoring accuracy and bias."
        ],
        [
         "11",
         "12",
         "AI Data Center Engineering",
         "For AI clusters, what is a core responsibility of AI Data Center Engineering?",
         "Designing high-density compute, networking, and power for AI workloads",
         "Writing data labeling guidelines for annotation teams",
         "Designing mobile UI for chatbot avatars in apps",
         "Drafting marketing copy for model release announcements",
         "1",
         "0.64",
         "It focuses on facilities for compute, storage, networking, power, and AIOps at scale.",
         "Design, deploy, and operate AI-optimized data center infrastructure, including high-density compute, networking, storage, and DC power systems. Apply AIOps and modular design to manage capacity, reliability, and cost for AI workloads."
        ],
        [
         "12",
         "13",
         "AI Data Engineering",
         "What best characterizes AI Data Engineering for training reliability?",
         "Building governed pipelines for ingestion, curation, and quality controls",
         "Hardcoding file paths in notebooks to speed up local runs",
         "Skipping schema validation to avoid ETL performance overhead",
         "Randomly mixing datasets without lineage or catalogs",
         "1",
         "0.8",
         "It delivers scalable, governed data pipelines with quality and lifecycle controls.",
         "Ability to design, build, and manage scalable data architectures and pipelines for AI/ML, including acquisition, ingestion, cleaning, curation, modeling, and cataloging. Implements governance, quality, ethics, and lifecycle controls to deliver reliable datasets for training and inference."
        ],
        [
         "13",
         "14",
         "AI Development Environment Integration",
         "In a collaborative AI team, what does environment integration emphasize?",
         "AI-enabled IDEs with Copilot, extensions, CI, tracking, and Git best practices",
         "Editing code directly in production containers without version control",
         "Using only email threads to manage issue tracking and alerts",
         "Disabling linting and tests to speed up code reviews",
         "1",
         "0.78",
         "It integrates AI assistants, extensions, automation, tracking, and Git workflows.",
         "Set up, customize, and maintain AI-enabled IDEs and notebooks (VS Code, JetBrains, Jupyter/Colab) integrating GitHub Copilot, Codespaces, Actions/APIs, Copilot Chat/Studio, and Cursor to streamline coding and collaboration. Build IDE extensions and automated workflows, connect Jira and Prometheus for tracking and monitoring, and apply Git version control best practices across repositories."
        ],
        [
         "14",
         "15",
         "AI Evaluation and Benchmarking",
         "What defines AI Evaluation and Benchmarking for model selection?",
         "Reproducible pipelines with proper metrics, automated grading, and reviews",
         "Choosing models by parameter count and recent hype alone",
         "Using a single accuracy metric across all tasks and domains",
         "Manually eyeballing few samples without test documentation",
         "1",
         "0.81",
         "It builds reproducible evaluations with task-appropriate metrics and reviews.",
         "Design and implement evaluation frameworks and benchmark tests for AI models and agents, including metric selection (accuracy, AP/MAP, classification), automated grading, and human review. Build reproducible pipelines to compute, analyze, and report performance metrics to compare systems and drive model improvements."
        ],
        [
         "15",
         "16",
         "AI Image Processing",
         "For AI-driven visual pipelines, what is a core capability?",
         "Super-resolution, denoising, inpainting, compositing, and color grading at scale",
         "Compressing ZIP files for faster dataset downloads only",
         "Using CSV exports to archive model predictions by hand",
         "Displaying thumbnails without GPU acceleration or quality checks",
         "1",
         "0.76",
         "Production image pipelines require enhancement, editing, and quality assessment tools.",
         "Build and operate AI-driven image editing and enhancement workflows for production and analysis, covering super-resolution, denoising, deblurring, inpainting/outpainting, compositing, color correction/grading and colorization, HDR processing, augmentation/preprocessing, and quality assessment/forensics. Use tools and frameworks such as Adobe Photoshop and Firefly, Albumentations, and GPU upscalers like DLSS and FSR to deliver reliable, high-quality visual outputs."
        ],
        [
         "16",
         "17",
         "AI Inference Caching",
         "In serving LLMs, what best describes AI Inference Caching?",
         "Managing KV caches, pooling, and eviction to cut latency and memory",
         "Saving full conversation logs in CSV without cache policies",
         "Using larger batch sizes without any cache consideration",
         "Encrypting outputs to reduce token generation time significantly",
         "1",
         "0.71",
         "KV cache optimization and eviction tuning reduce latency and VRAM usage.",
         "Ability to design and implement caching strategies and connection pooling for model serving, including KV cache management (quantization/compression, offload, optimization), LRU, memoization, and prefix caching to reduce latency and GPU memory. Monitor and tune cache hit rates, eviction policies, and resource utilization to maximize throughput and cost efficiency."
        ],
        [
         "17",
         "18",
         "AI Inference Engineering",
         "For CPU-edge inference, what is central to AI Inference Engineering?",
         "Runtime tuning, batching, caching, and C++ optimizations for low latency",
         "Only retraining models with more parameters for better throughput",
         "Replacing REST with FTP to transfer predictions faster",
         "Logging outputs in XML to reduce compute usage",
         "1",
         "0.74",
         "It focuses on backend and runtime optimizations to meet latency and cost goals.",
         "Design, implement, and optimize AI inference engines, APIs, backends, and serving endpoints to achieve low latency, high throughput, and cost efficiency on CPU and edge environments. Apply runtime tuning, C++/CPU optimizations, caching, batching, and orchestration to accelerate and scale production inference."
        ],
        [
         "18",
         "19",
         "AI Memory Optimization",
         "When running LLMs on limited VRAM, what practice is key?",
         "Hierarchical offloading, in-place ops, compression, and coalescing",
         "Storing all tensors in FP64 to improve numerical stability",
         "Disabling attention caching to reduce compute fragmentation",
         "Duplicating parameters across GPUs to simplify sharding",
         "1",
         "0.7",
         "Memory-aware techniques reduce footprint and enable low-VRAM inference.",
         "Design and tune memory architectures and strategies for AI and LLM workloads to minimize footprint and maximize throughput. Implement GPU/VRAM optimization, hierarchical offloading, in-place operations, coalescing, compression, and integrate external and long-term memory to enable low-VRAM inference and robust agent memory management."
        ],
        [
         "19",
         "20",
         "AI Model Debugging",
         "In debugging a failing model pipeline, what is the core approach?",
         "Instrument logs, trace data and behavior, and validate targeted fixes",
         "Increase training epochs and hope the issue disappears",
         "Delete old checkpoints to clear space without analysis",
         "Change the optimizer to a new variant without diagnostics",
         "1",
         "0.8",
         "Systematic diagnostics, tracing, and tests are required to isolate and fix issues.",
         "Systematically diagnose, reproduce, and resolve failures and performance anomalies in AI models and supporting code using debugging tools, automated diagnostics, and model inspection. Build tests, instrument logs/metrics, trace data and model behavior, and validate fixes to restore expected functionality."
        ],
        [
         "20",
         "21",
         "AI Model Engineering",
         "What captures AI Model Engineering for enterprise deployment?",
         "Selecting, adapting, and integrating models to meet performance needs",
         "Using only prebuilt APIs without any customization or validation",
         "Choosing the largest model regardless of latency constraints",
         "Skipping integration tests to speed up delivery schedules",
         "1",
         "0.78",
         "It includes selection, adaptation, and integration to meet requirements.",
         "Design, select, customize, and train AI models, including domain-specific variants, using modular architectures and model-agnostic techniques. Apply domain adaptation and generalization methods, perform model editing and refinement, and integrate models into software and system architectures to meet performance, reliability, and deployment requirements."
        ],
        [
         "21",
         "22",
         "AI Model Fine-Tuning",
         "In tuning a domain LLM, what choice defines effective fine-tuning practice?",
         "Selecting full or PEFT methods with HPO and efficient training",
         "Always using full fine-tuning regardless of memory limits",
         "Training on random internet text without domain instructions",
         "Ignoring evaluation while maximizing tokens processed",
         "1",
         "0.79",
         "It requires choosing the right strategy and optimizing hyperparameters and memory.",
         "Design and execute fine-tuning pipelines for language and multimodal models, choosing between full and parameter-efficient approaches (adapters, PEFT) based on domain goals and resource constraints. Perform hyperparameter optimization and autotuning, distributed and memory-efficient training, and iterative instruction and domain-specific tuning to meet target performance."
        ],
        [
         "22",
         "23",
         "AI Model Risk Management",
         "For compliant deployment, what is central to AI Model Risk Management?",
         "Assessing risks using NIST AI RMF and defining controls with monitoring",
         "Publishing model cards without any control implementation",
         "Focusing only on P99 latency and ignoring safety risks",
         "Scaling clusters before analyzing model harm scenarios",
         "1",
         "0.68",
         "Risk frameworks, controls, and monitoring underpin safe, compliant AI.",
         "Ability to assess, quantify, prioritize, and mitigate risks in AI systems using the NIST AI RMF and model risk management practices. Includes conducting rigorous risk analyses and credit risk modeling, defining controls and monitoring, and maintaining documentation to ensure compliant, reliable, and safe AI deployment."
        ],
        [
         "23",
         "24",
         "AI Model Serving and Deployment",
         "What deployment practice is key for safe model rollouts?",
         "Using blue-green, canary, and shadow strategies with monitoring",
         "Hot-swapping Docker images in-place without health checks",
         "Deploying all models to one endpoint without isolation",
         "Relying on manual SSH updates during peak traffic",
         "1",
         "0.82",
         "Progressive delivery strategies reduce risk and enable rapid rollback.",
         "Design, deploy, and operate microservices-based, modular model serving systems in production, including multi-model endpoints and multi-tenant architectures. Apply blue-green, canary, and shadow deployment strategies to safely release and scale models with isolation, monitoring, and rapid rollback using serving frameworks and plugins."
        ],
        [
         "24",
         "25",
         "AI Monitoring and Observability",
         "In production LLM apps, what should observability include?",
         "Drift detection, data quality, performance metrics, and audit logs",
         "Only CPU and RAM metrics without model behavior tracking",
         "Manual spot checks on a few user sessions monthly",
         "Email alerts for every request regardless of severity",
         "1",
         "0.81",
         "Monitoring needs behavior, data, and system metrics with auditing.",
         "Design and operate monitoring, logging, and observability for AI agents and ML models across data quality, drift, performance, and system health. Configure cloud logging and audit trails, implement drift and behavioral detection, dashboards and alerts, and continuous reporting to ensure reliability, compliance, and rapid incident response."
        ],
        [
         "25",
         "26",
         "AI Performance and Cost Optimization",
         "To meet SLAs and budgets, what is a core activity?",
         "Tuning algorithms, code, cache, I/O, and compute resource usage",
         "Buying newer GPUs instead of profiling bottlenecks",
         "Doubling batch size without measuring tail latency",
         "Caching every response forever regardless of accuracy",
         "1",
         "0.77",
         "Holistic optimization spans algorithmic, code, data I/O, and resource tuning.",
         "Analyze and optimize AI models, data pipelines, and infrastructure to improve throughput and latency while minimizing cloud, compute, and API spend via algorithm, code, cache, data I/O, and compute resource tuning across training and inference. Implement cost monitoring and compute cost estimation, and apply deep learning optimizers and architecture and model adjustments to meet performance SLAs and budget targets."
        ],
        [
         "26",
         "27",
         "AI Personalization Engineering",
         "In an AI recommender, what practice defines personalization engineering?",
         "Modeling behavior with collaborative and content filtering plus A/B tests",
         "Serving the same content to all users for fairness",
         "Ignoring privacy constraints when joining identity data",
         "Only counting page views as the relevance signal",
         "1",
         "0.73",
         "It builds behavioral models, tests variants, and respects privacy constraints.",
         "Design, train, and deploy end-to-end personalization and recommendation systems for ads, content, and search using behavioral modeling, collaborative and content-based filtering, and deep learning. Execute persona modeling, real-time inference, and A/B testing to maximize relevance, CTR, and conversion while honoring privacy and identity-preference constraints."
        ],
        [
         "27",
         "28",
         "AI Planning Systems",
         "For long-horizon tasks, what describes AI Planning Systems?",
         "Modeling domains, choosing planners, and integrating feedback for execution",
         "Using random actions to discover plans without constraints",
         "Rendering 3D scenes without any planning or goals",
         "Training a classifier to output plans as labels directly",
         "1",
         "0.64",
         "Planning systems model domains and execute plans with feedback loops.",
         "Designs and deploys planner-executor systems for long-horizon tasks by modeling domains in PDDL, selecting hierarchical/global/local strategies, and implementing path, motion, and trajectory planning under spatial-temporal constraints. Translates complex objectives into executable plans and integrates feedback to optimize performance and reliability."
        ],
        [
         "28",
         "29",
         "AI Privacy Engineering",
         "When handling user data in AI training, what is essential?",
         "Applying differential privacy, anonymization, and leak prevention controls",
         "Saving raw PII indefinitely for better model recall",
         "Sharing datasets freely to maximize collaboration speed",
         "Hashing only filenames to protect sensitive content",
         "1",
         "0.78",
         "Privacy engineering uses DP, masking, encryption, and DLP to reduce risk.",
         "Design and implement privacy-preserving data pipelines and ML systems using differential privacy, anonymization/masking/redaction, encryption, MPC, and DLP. Detect PII, prevent leakage/exfiltration, and mitigate dataset contamination and data poisoning across collection, training, deployment, and monitoring."
        ],
        [
         "29",
         "30",
         "AI Process Automation",
         "For automating enterprise workflows with AI, what is critical?",
         "Designing bots and orchestration with monitoring and scalability",
         "Replacing all systems with a single chatbot interface",
         "Copying data manually between spreadsheets daily",
         "Ignoring runbooks and recovering issues by memory",
         "1",
         "0.75",
         "It builds reliable AI and RPA workflows with integration and monitoring.",
         "Design, build, and optimize automated workflows using AI, RPA, and orchestration tools to streamline customer support, marketing, office apps, and enterprise processes. Includes task capture and record-and-playback, bot development, system integration (e.g., spreadsheets, email, smart home), runbook automation, monitoring, and scaling."
        ],
        [
         "30",
         "31",
         "AI Red Teaming",
         "What defines AI Red Teaming for a new model release?",
         "Generating adversarial attacks and mapping to MITRE ATLAS with mitigations",
         "Only running unit tests on preprocessing code modules",
         "Scaling inference GPUs to handle more benign traffic",
         "Relying on model size to make attacks ineffective",
         "1",
         "0.69",
         "Red teaming simulates attacks, validates weaknesses, and proposes defenses.",
         "Design and run manual and automated adversarial evaluations of AI models and pipelines, generating attacks (prompts, examples, backdoors) and mapping findings to MITRE ATLAS. Hunt, reverse engineer, and validate model poisoning, model theft, and exploit paths, and recommend mitigations via adversarial training and regularization."
        ],
        [
         "31",
         "32",
         "AI Reliability Engineering",
         "For resilient AI services, what practice is central?",
         "Applying SRE patterns like retries, idempotency, and chaos testing",
         "Pushing experimental models directly to production traffic",
         "Disabling health checks to avoid noisy alerts",
         "Accepting nondeterminism without any reproducibility guardrails",
         "1",
         "0.79",
         "SRE practices ensure robust, fault-tolerant, and reproducible AI operations.",
         "Designs and operates resilient, fault-tolerant, and reproducible AI systems across training and inference. Applies SRE practices such as retry strategies, idempotency, deterministic execution, chaos engineering, A/B testing, and robust evaluation to ensure model robustness, reliable performance, and recoverability under noise and adversarial conditions."
        ],
        [
         "32",
         "33",
         "AI Safety and Governance",
         "In an enterprise, what is core to AI Safety and Governance?",
         "Risk assessment, guardrails, audits, and accountability across lifecycle",
         "Letting product teams set safety rules ad hoc per sprint",
         "Skipping impact assessments for internal-only tools",
         "Relying only on terms of service to ensure safe use",
         "1",
         "0.74",
         "Governance sets standards, guardrails, and oversight throughout development.",
         "Ability to design and run AI governance, safety, and alignment programs, including risk assessment, guardrails, audits, and oversight aligned with regulations. Includes drafting AI policies, conducting algorithmic auditing and safety testing, and ensuring accountability and auditability from development through deployment."
        ],
        [
         "33",
         "34",
         "AI Scalability Engineering",
         "For scaling AI training and serving, what is the main focus?",
         "Autoscaling compute, serving, and data with reliability and cost awareness",
         "Migrating all compute to a single large instance type",
         "Combining train and serve workloads on one node always",
         "Ignoring scaling laws while increasing sequence length",
         "1",
         "0.73",
         "It builds scalable systems across compute, serving, and pipelines with SLAs.",
         "Design, build, and operate large-scale AI training and inference systems, including autoscaling compute, scalable model serving, and data pipelines. Apply model and inference scaling laws to optimize performance, reliability, and cost across clusters and deployments."
        ],
        [
         "34",
         "35",
         "AI Search Engineering",
         "In enterprise search, what defines AI Search Engineering?",
         "Hybrid lexical and semantic search with embeddings and ranking",
         "Only exact keyword matching with no vector similarity",
         "Randomly shuffling results to improve exploration",
         "Using image compression to accelerate text search",
         "1",
         "0.77",
         "It blends lexical and vector techniques to optimize relevance and scale.",
         "Design, build, and optimize AI-powered search engines using lexical, keyword, and semantic techniques with vector embeddings and cosine similarity to deliver high-relevance results across enterprise, file, and image search. Implement indexing pipelines, hybrid ranking and exploration strategies, integrate search APIs, and deploy and scale solutions on platforms such as Amazon OpenSearch or Meilisearch, including serverless options."
        ],
        [
         "35",
         "36",
         "AI Security Engineering",
         "What is a core activity in AI Security Engineering?",
         "Threat modeling and controls across data, models, and infrastructure",
         "Storing API keys in logs for quick debugging access",
         "Turning off SIEM alerts to reduce noise permanently",
         "Serving models without TLS to minimize overhead",
         "1",
         "0.78",
         "Security covers threats and controls across the AI stack, with monitoring.",
         "Design, implement, and audit security controls for AI/ML systems across data, models, infrastructure, and supply chain, including threat modeling, penetration testing, safety evaluation, and secure air-gapped or cloud deployment. Apply cybersecurity practices and tools (IAM, application, network, IoT, SIEM, cryptography) to detect, prevent, and respond to threats, insecure output handling, and model integrity risks in AI-enabled environments."
        ],
        [
         "36",
         "37",
         "AI Simulation Engineering",
         "For robotics training, what best describes AI Simulation Engineering?",
         "Building physics and agent simulations for training and sim-to-real transfer",
         "Using only static images for robot policy learning",
         "Optimizing HTML canvases for dashboard animations",
         "Replacing dynamics with random noise to encourage exploration",
         "1",
         "0.7",
         "It creates accurate simulation environments and models for robust transfer.",
         "Design, build, and calibrate physics-based and agent-based simulation environments and digital twins (e.g., CARLA, Isaac Sim) to train, test, and validate AI for robotics and autonomous vehicles. Apply physics-informed ML (PINNs), differentiable physics, PDE solvers, surrogate modeling, and world models to achieve accurate dynamics modeling and robust sim-to-real transfer."
        ],
        [
         "37",
         "38",
         "AI Strategy and Integration",
         "In leading AI adoption, what is a key responsibility?",
         "Defining use cases, integrating systems, piloting, and scaling with governance",
         "Choosing tools based only on vendor popularity rankings",
         "Skipping workforce training to accelerate initial delivery",
         "Avoiding measurements to prevent negative findings",
         "1",
         "0.74",
         "Strategy aligns use cases, integration, pilots, scaling, and governance.",
         "Define use cases, architect and integrate AI systems into products, services, and operating environments, selecting algorithms and tools, preparing training data, and embedding assistants and OS features with rigorous testing and governance. Lead pilots to scaled deployment, build workforce AI literacy and curricula, and deliver measurable benefits while managing cost, safety, and compliance."
        ],
        [
         "38",
         "39",
         "AI Validation and Verification",
         "What practice defines AI Validation and Verification in production?",
         "Automated tests, cross-validation, and consistency and factuality checks",
         "Approving models by team vote without evaluations",
         "Benchmarking once and never revalidating after changes",
         "Trusting vendor claims without any internal assessment",
         "1",
         "0.8",
         "V&V uses systematic testing and verification to ensure trustworthy behavior.",
         "Design and run end-to-end validation and verification for AI systems across data, models, and inputs/outputs using testing frameworks, cross-validation, formal methods, and consistency/factuality checks. Deploy automated fact-checking and source verification, input sanitization, inference-time output verification, and cryptographic proofs and verifiable credentials to ensure trustworthy, compliant behavior."
        ],
        [
         "39",
         "40",
         "AI Video Synthesis and Analytics",
         "For AI video pipelines, what capability is central?",
         "Generating and editing video with analytics for detection and events",
         "Only extracting audio tracks without any frame analysis",
         "Storing frames uncompressed to guarantee quality",
         "Converting videos to GIFs to simplify modeling",
         "1",
         "0.66",
         "It includes video generation/editing and analytics for robust applications.",
         "Capability to design, train, and deploy models and pipelines for video generation and editing (image/audio-to-video, vid2vid), frame interpolation/generation and enhancement (denoising), and content-aware inpainting, object removal, and RGBA compositing. Applies video analytics for classification, action recognition, moderation, forensics, and event detection, and optimizes multi-frame rendering with keyframe control and structure-aware techniques."
        ],
        [
         "40",
         "41",
         "AI Visual Perception",
         "In real-time perception systems, what is the core goal?",
         "Detecting, tracking, and avoiding objects with optimized models and sensors",
         "Randomly sampling frames to reduce GPU temperature",
         "Applying grayscale filters to all incoming camera feeds",
         "Compressing detections to CSV for monthly analysis only",
         "1",
         "0.77",
         "Perception integrates sensors and models for detection and tracking in real time.",
         "Build and deploy camera and sensor-based AI pipelines for object and obstacle detection, tracking, and collision avoidance in surveillance and interactive systems. Select sensors, integrate and tune models, and optimize real-time performance, accuracy, and alerting."
        ],
        [
         "41",
         "42",
         "AI Workflow Orchestration",
         "For multi-model AI pipelines, what does orchestration ensure?",
         "Stateful tasks, dependencies, monitoring, and resource optimization",
         "Single-threaded execution with manual retries for failures",
         "Random scheduling to maximize hardware utilization",
         "Hardcoded endpoints without any run tracking or logs",
         "1",
         "0.78",
         "Orchestration coordinates tasks, resources, observability, and reliability.",
         "Design, automate, and manage end-to-end, stateful AI workflows by orchestrating models, tools, APIs, data pipelines, containers, and GPU resources across multi-model and multi-node environments. Configure task dependencies, integrate services, monitor and debug runs, and optimize reliability, throughput, and cost using workflow engines and orchestrators."
        ],
        [
         "42",
         "43",
         "AI Workload Orchestration",
         "When serving AI at scale, what is a key orchestration activity?",
         "Asynchronous queues, micro-batching, rate limits, and capacity planning",
         "Disabling backpressure so producers never block",
         "Running all jobs on a single large queue without priorities",
         "Hardcoding budgets and ignoring quota alarms",
         "1",
         "0.76",
         "It manages queues, batching, limits, and resources to meet SLAs.",
         "Design and operate asynchronous and batch processing pipelines for AI services using message queues, job scheduling, dynamic/micro-batching, rate limiting, and load balancing to maximize throughput and stability. Plan and control cluster resource allocation, budgets, and service quotas with capacity planning, power management, and liquid/hybrid cooling constraints to meet SLAs."
        ],
        [
         "43",
         "44",
         "AI-Assisted Software Development",
         "In a secure dev workflow, how should AI coding assistants be used?",
         "Generate, review, and verify code with secure analysis pipelines",
         "Commit suggested code without tests or security checks",
         "Paste secrets to get better suggestions for deployments",
         "Disable code reviews when AI provides completions",
         "1",
         "0.79",
         "Assistants should integrate with testing, analysis, and secure workflows.",
         "Proficiency in using AI coding assistants and agents to generate, complete, review, debug, verify, and repair code across languages. Capable of configuring secure workflows for code analysis and audits, and optimizing productivity with AI pair programming and assisted editing."
        ],
        [
         "44",
         "45",
         "Algorithmic Fairness and Bias Mitigation",
         "For a loan model, what is key to mitigate bias?",
         "Measure fairness metrics and apply data, model, or post-processing fixes",
         "Hide sensitive columns but never evaluate disparities",
         "Use larger models to eliminate bias automatically",
         "Rely on randomization to guarantee fair outcomes",
         "1",
         "0.72",
         "Fairness requires metrics, diagnosis, and targeted mitigations and monitoring.",
         "Evaluate and audit AI/ML models for bias using fairness metrics and tests, diagnose sources of disparity, and implement mitigation techniques in data, model, and post-processing. Establish ongoing bias monitoring, reporting, and governance to meet ethical and regulatory standards."
        ],
        [
         "45",
         "46",
         "Applied AI Analytics",
         "In building AI analytics for decisions, what is essential?",
         "Selecting models, pipelines, BI integration, and validating outcomes",
         "Plotting sample charts without data provenance tracking",
         "Trusting raw outputs without cross-check or domain review",
         "Storing dashboards as images without underlying data",
         "1",
         "0.74",
         "Applied analytics integrates models, data, and validation to support decisions.",
         "Ability to design and deploy AI-driven analytics and diagnostics that process large, multi-source data to produce actionable insights in healthcare, finance, marketing, and drug discovery. Includes selecting models, building data pipelines, integrating BI tools, and validating outcomes to inform decisions and accelerate scientific discovery."
        ],
        [
         "46",
         "47",
         "Applied Classification and Clustering",
         "For end-to-end classification pipelines, what is core?",
         "Data labeling, training discriminative models, and tuning clustering methods",
         "Skipping labels and using only random features for training",
         "Reducing dataset size by deleting hard samples",
         "Grouping by file name similarity to form classes",
         "1",
         "0.78",
         "It spans annotation through training and evaluation of classifiers and clusters.",
         "Ability to build end-to-end pipelines for data annotation and labeling, and to train, evaluate, and deploy discriminative models for classification across text, images, audio, and graphs. Proficient in selecting and tuning supervised, semi-supervised, and self-supervised approaches and clustering algorithms (k-means, agglomerative, mean-shift) to deliver accurate content and metadata classification."
        ],
        [
         "47",
         "48",
         "Audio ML Engineering",
         "For real-time audio AI, what capability is central?",
         "Preprocessing, features, enhancement, separation, and streaming integration",
         "Converting audio to images to reuse CV models blindly",
         "Storing audio uncompressed to improve accuracy automatically",
         "Using only text embeddings to classify sound events",
         "1",
         "0.69",
         "Audio ML needs signal processing, modeling, streaming, and quality assessment.",
         "Build and optimize machine learning and signal processing systems for audio, including preprocessing, feature extraction, classification, enhancement, source separation, synthesis, event detection, and multimodal audio-language modeling. Integrate encoding and codecs, streaming, audio-visual synchronization, deepfake and forensic detection, adaptive noise cancellation, and quality assessment to deliver robust real-time applications."
        ],
        [
         "48",
         "49",
         "Automated Detection and Response",
         "For securing AI services in real time, what is key?",
         "Detect anomalies and orchestrate playbooks for automated response",
         "Disable logging to reduce storage and alert fatigue",
         "Only schedule weekly scans for offline threat reports",
         "Approve all external inputs to maintain availability",
         "1",
         "0.71",
         "It combines detection with automated containment and escalation.",
         "Designs, implements, and tunes systems that detect anomalies, threats, harmful content, fraud, and AI hallucinations in real time using behavioral analytics, feature filtering, and deception technologies. Orchestrates automated incident response to contain intrusions, mitigate DDoS, remediate malware and defects, and escalate critical events with defined playbooks."
        ],
        [
         "49",
         "50",
         "Autonomous Systems Control",
         "In robot control, what best describes this skill?",
         "Closed-loop decision-making with safety constraints and validation",
         "Manual teleoperation without any autonomy or feedback",
         "Static path scripts regardless of sensor inputs",
         "Random motor commands to explore unsafe states",
         "1",
         "0.67",
         "Autonomous control integrates perception, planning, and safe actuation.",
         "Design, implement, and tune AI-driven closed-loop control and decision-making for robots, drones, and vehicles. Integrate perception, planning, and actuation, develop control algorithms and safety constraints, and validate performance via simulation and real-world testing for navigation, manipulation, and collaboration."
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 137
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>question</th>\n",
       "      <th>option_1</th>\n",
       "      <th>option_2</th>\n",
       "      <th>option_3</th>\n",
       "      <th>option_4</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>probability</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>skill_definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Accelerated Tensor Programming</td>\n",
       "      <td>In an AI inference service on GPUs, what does ...</td>\n",
       "      <td>Using tensor cores, fused GEMM, tiling, and PT...</td>\n",
       "      <td>Refactoring Python loops and pandas joins to s...</td>\n",
       "      <td>Encrypting checkpoints and rotating IAM keys t...</td>\n",
       "      <td>Extending context windows via retrieval to imp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>It focuses on low-level GPU math and kernel op...</td>\n",
       "      <td>Develop and optimize matrix and tensor computa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Adaptive Decision Optimization</td>\n",
       "      <td>When deploying an AI system under uncertainty,...</td>\n",
       "      <td>Using contextual bandits, MDPs, and MPC to tun...</td>\n",
       "      <td>Selecting static thresholds from historical A/...</td>\n",
       "      <td>Encoding business rules in fixed if-else trees...</td>\n",
       "      <td>Scaling batch inference by adding GPUs without...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>It uses stochastic methods like bandits, MDPs,...</td>\n",
       "      <td>Design, implement, and tune adaptive, stochast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Advanced RAG Engineering</td>\n",
       "      <td>In production LLM apps, what defines Advanced ...</td>\n",
       "      <td>Using agentic, corrective, and graph-aware ret...</td>\n",
       "      <td>Only increasing embedding dimensions to improv...</td>\n",
       "      <td>Relying on static FAQs without vector or graph...</td>\n",
       "      <td>Moving prompts to serverless functions to redu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Advanced RAG integrates vector and graph store...</td>\n",
       "      <td>Design, build, and optimize retrieval-augmente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AI 3D Content Generation</td>\n",
       "      <td>For AI-driven 3D asset creation from 2D inputs...</td>\n",
       "      <td>Training 3D neural models with depth estimatio...</td>\n",
       "      <td>Compressing textures with ZIP to reduce asset ...</td>\n",
       "      <td>Hosting static GLTF files on a CDN with cache ...</td>\n",
       "      <td>Tracking user clicks to optimize UX funnels in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63</td>\n",
       "      <td>It focuses on 3D deep learning, depth inferenc...</td>\n",
       "      <td>Design, train, and deploy 3D deep learning pip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AI Accelerator Engineering</td>\n",
       "      <td>In building custom AI chips, what is a primary...</td>\n",
       "      <td>Designing compute and memory hierarchies with ...</td>\n",
       "      <td>Creating React dashboards for model observabil...</td>\n",
       "      <td>Writing high-level prompts to guide chat agent...</td>\n",
       "      <td>Configuring IAM groups to manage developer per...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>It targets chip architecture, memory, firmware...</td>\n",
       "      <td>Architect, implement, and optimize AI accelera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>Time Series Predictive Modeling</td>\n",
       "      <td>For demand forecasts, what is a core task?</td>\n",
       "      <td>Train temporal models and convert forecasts in...</td>\n",
       "      <td>Treat timestamps as unordered IDs to simplify ...</td>\n",
       "      <td>Use static averages for all future periods</td>\n",
       "      <td>Ignore uncertainty when planning inventory</td>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>Time series modeling forecasts and drives acti...</td>\n",
       "      <td>Designs, trains, and deploys time series and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>Transformer Attention Optimization</td>\n",
       "      <td>To speed attention on long sequences, what helps?</td>\n",
       "      <td>FlashAttention, efficient masking, and kernel ...</td>\n",
       "      <td>Disabling attention caches to avoid memory fra...</td>\n",
       "      <td>Always using full quadratic attention regardle...</td>\n",
       "      <td>Converting tokens to images to speed kernels</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Efficient mechanisms and tuned kernels improve...</td>\n",
       "      <td>Ability to design, implement, and optimize tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135</td>\n",
       "      <td>Vector Search Engineering</td>\n",
       "      <td>For scalable ANN search, what is essential?</td>\n",
       "      <td>HNSW or IVF indexes with filters and low-laten...</td>\n",
       "      <td>Linear scans over raw vectors for all queries</td>\n",
       "      <td>Indexing only metadata without vector fields</td>\n",
       "      <td>Using KNN on CPU with no batching or shards</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>ANN indexes and tuned deployments deliver rele...</td>\n",
       "      <td>Design, implement, and tune approximate neares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>Vision-Language Model Engineering</td>\n",
       "      <td>For document understanding with images and tex...</td>\n",
       "      <td>Fine-tune VLMs and optimize inference for inte...</td>\n",
       "      <td>Use only text models and ignore images entirely</td>\n",
       "      <td>Attach captions post-hoc without model alignment</td>\n",
       "      <td>Resize images to thumbnails for all tasks</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>VLM engineering aligns visual and language inp...</td>\n",
       "      <td>Design, fine-tune, and deploy vision- and vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>Voice AI Engineering</td>\n",
       "      <td>For a voice assistant, what is the core build?</td>\n",
       "      <td>ASR, TTS, voice biometrics, and robust voice U...</td>\n",
       "      <td>Simple DTMF menus with no speech features at all</td>\n",
       "      <td>Playing pre-recorded clips as every response</td>\n",
       "      <td>Ignoring latency while streaming responses slowly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>Voice AI integrates recognition, synthesis, bi...</td>\n",
       "      <td>Design, build, and integrate voice-driven AI a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     task_id                          skill_name  \\\n",
       "0          1      Accelerated Tensor Programming   \n",
       "1          2      Adaptive Decision Optimization   \n",
       "2          3            Advanced RAG Engineering   \n",
       "3          4            AI 3D Content Generation   \n",
       "4          5          AI Accelerator Engineering   \n",
       "..       ...                                 ...   \n",
       "132      133     Time Series Predictive Modeling   \n",
       "133      134  Transformer Attention Optimization   \n",
       "134      135           Vector Search Engineering   \n",
       "135      136   Vision-Language Model Engineering   \n",
       "136      137                Voice AI Engineering   \n",
       "\n",
       "                                              question  \\\n",
       "0    In an AI inference service on GPUs, what does ...   \n",
       "1    When deploying an AI system under uncertainty,...   \n",
       "2    In production LLM apps, what defines Advanced ...   \n",
       "3    For AI-driven 3D asset creation from 2D inputs...   \n",
       "4    In building custom AI chips, what is a primary...   \n",
       "..                                                 ...   \n",
       "132         For demand forecasts, what is a core task?   \n",
       "133  To speed attention on long sequences, what helps?   \n",
       "134        For scalable ANN search, what is essential?   \n",
       "135  For document understanding with images and tex...   \n",
       "136     For a voice assistant, what is the core build?   \n",
       "\n",
       "                                              option_1  \\\n",
       "0    Using tensor cores, fused GEMM, tiling, and PT...   \n",
       "1    Using contextual bandits, MDPs, and MPC to tun...   \n",
       "2    Using agentic, corrective, and graph-aware ret...   \n",
       "3    Training 3D neural models with depth estimatio...   \n",
       "4    Designing compute and memory hierarchies with ...   \n",
       "..                                                 ...   \n",
       "132  Train temporal models and convert forecasts in...   \n",
       "133  FlashAttention, efficient masking, and kernel ...   \n",
       "134  HNSW or IVF indexes with filters and low-laten...   \n",
       "135  Fine-tune VLMs and optimize inference for inte...   \n",
       "136  ASR, TTS, voice biometrics, and robust voice U...   \n",
       "\n",
       "                                              option_2  \\\n",
       "0    Refactoring Python loops and pandas joins to s...   \n",
       "1    Selecting static thresholds from historical A/...   \n",
       "2    Only increasing embedding dimensions to improv...   \n",
       "3    Compressing textures with ZIP to reduce asset ...   \n",
       "4    Creating React dashboards for model observabil...   \n",
       "..                                                 ...   \n",
       "132  Treat timestamps as unordered IDs to simplify ...   \n",
       "133  Disabling attention caches to avoid memory fra...   \n",
       "134      Linear scans over raw vectors for all queries   \n",
       "135    Use only text models and ignore images entirely   \n",
       "136   Simple DTMF menus with no speech features at all   \n",
       "\n",
       "                                              option_3  \\\n",
       "0    Encrypting checkpoints and rotating IAM keys t...   \n",
       "1    Encoding business rules in fixed if-else trees...   \n",
       "2    Relying on static FAQs without vector or graph...   \n",
       "3    Hosting static GLTF files on a CDN with cache ...   \n",
       "4    Writing high-level prompts to guide chat agent...   \n",
       "..                                                 ...   \n",
       "132         Use static averages for all future periods   \n",
       "133  Always using full quadratic attention regardle...   \n",
       "134       Indexing only metadata without vector fields   \n",
       "135   Attach captions post-hoc without model alignment   \n",
       "136       Playing pre-recorded clips as every response   \n",
       "\n",
       "                                              option_4  correct_answer  \\\n",
       "0    Extending context windows via retrieval to imp...               1   \n",
       "1    Scaling batch inference by adding GPUs without...               1   \n",
       "2    Moving prompts to serverless functions to redu...               1   \n",
       "3    Tracking user clicks to optimize UX funnels in...               1   \n",
       "4    Configuring IAM groups to manage developer per...               1   \n",
       "..                                                 ...             ...   \n",
       "132         Ignore uncertainty when planning inventory               1   \n",
       "133       Converting tokens to images to speed kernels               1   \n",
       "134        Using KNN on CPU with no batching or shards               1   \n",
       "135          Resize images to thumbnails for all tasks               1   \n",
       "136  Ignoring latency while streaming responses slowly               1   \n",
       "\n",
       "     probability                                        Explanation  \\\n",
       "0           0.70  It focuses on low-level GPU math and kernel op...   \n",
       "1           0.62  It uses stochastic methods like bandits, MDPs,...   \n",
       "2           0.66  Advanced RAG integrates vector and graph store...   \n",
       "3           0.63  It focuses on 3D deep learning, depth inferenc...   \n",
       "4           0.59  It targets chip architecture, memory, firmware...   \n",
       "..           ...                                                ...   \n",
       "132         0.77  Time series modeling forecasts and drives acti...   \n",
       "133         0.72  Efficient mechanisms and tuned kernels improve...   \n",
       "134         0.79  ANN indexes and tuned deployments deliver rele...   \n",
       "135         0.73  VLM engineering aligns visual and language inp...   \n",
       "136         0.78  Voice AI integrates recognition, synthesis, bi...   \n",
       "\n",
       "                                      skill_definition  \n",
       "0    Develop and optimize matrix and tensor computa...  \n",
       "1    Design, implement, and tune adaptive, stochast...  \n",
       "2    Design, build, and optimize retrieval-augmente...  \n",
       "3    Design, train, and deploy 3D deep learning pip...  \n",
       "4    Architect, implement, and optimize AI accelera...  \n",
       "..                                                 ...  \n",
       "132  Designs, trains, and deploys time series and s...  \n",
       "133  Ability to design, implement, and optimize tra...  \n",
       "134  Design, implement, and tune approximate neares...  \n",
       "135  Design, fine-tune, and deploy vision- and vide...  \n",
       "136  Design, build, and integrate voice-driven AI a...  \n",
       "\n",
       "[137 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get quiz questions and answers dataset\n",
    "file_path = 'C:\\\\Users\\\\Denis_Davydov2\\\\OneDrive - EPAM\\\\Prophet_AI_docs\\\\Datasets\\\\AI_skills\\\\Quiz\\\\'\n",
    "file_name = 'quiz_v2_2025_11_21.csv'\n",
    "quiz_text = pd.read_csv(file_path+file_name)\n",
    "print(\"File read: \", file_name)\n",
    "\n",
    "print(f\"Number rows: {len(quiz_text)}\")\n",
    "quiz_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d33dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['task_id', 'skill_name', 'question', 'option_1', 'option_2', 'option_3', 'option_4', 'correct_answer', 'probability', 'Explanation', 'skill_definition']\n",
      "\n",
      "First row:\n",
      "task_id                                                             1\n",
      "skill_name                             Accelerated Tensor Programming\n",
      "question            In an AI inference service on GPUs, what does ...\n",
      "option_1            Using tensor cores, fused GEMM, tiling, and PT...\n",
      "option_2            Refactoring Python loops and pandas joins to s...\n",
      "option_3            Encrypting checkpoints and rotating IAM keys t...\n",
      "option_4            Extending context windows via retrieval to imp...\n",
      "correct_answer                                                      1\n",
      "probability                                                       0.7\n",
      "Explanation         It focuses on low-level GPU math and kernel op...\n",
      "skill_definition    Develop and optimize matrix and tensor computa...\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Data types:\n",
      "task_id               int64\n",
      "skill_name           object\n",
      "question             object\n",
      "option_1             object\n",
      "option_2             object\n",
      "option_3             object\n",
      "option_4             object\n",
      "correct_answer        int64\n",
      "probability         float64\n",
      "Explanation          object\n",
      "skill_definition     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data structure\n",
    "print(\"Columns:\", quiz_text.columns.tolist())\n",
    "print(\"\\nFirst row:\")\n",
    "print(quiz_text.iloc[0])\n",
    "print(\"\\nData types:\")\n",
    "print(quiz_text.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ef6906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 137 questions to C:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\\Ver_2\\quiz-app/public\\quiz_data.json\n",
      "\n",
      "Sample question:\n",
      "{\n",
      "  \"task_id\": 2,\n",
      "  \"text\": \"When deploying an AI system under uncertainty, what best characterizes Adaptive Decision Optimization?\",\n",
      "  \"options\": [\n",
      "    \"Using contextual bandits, MDPs, and MPC to tune actions under uncertainty\",\n",
      "    \"Selecting static thresholds from historical A/B tests without exploration\",\n",
      "    \"Encoding business rules in fixed if-else trees for deterministic outcomes\",\n",
      "    \"Scaling batch inference by adding GPUs without behavior modeling\"\n",
      "  ],\n",
      "  \"correctIndex\": 0,\n",
      "  \"likely\": 0.62,\n",
      "  \"explanation\": \"It uses stochastic methods like bandits, MDPs, and MPC to adapt decisions to changing contexts.\",\n",
      "  \"skillName\": \"Adaptive Decision Optimization\",\n",
      "  \"skillDefinition\": \"Design, implement, and tune adaptive, stochastic decision-making systems using methods like contextual bandits, MDP/MCTS, MPC, evolutionary algorithms, and Monte Carlo sampling to optimize outcomes under uncertainty. Select and configure algorithms, set decision thresholds, and deploy data-driven sampling and behavior trees to improve performance in dynamic environments.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert quiz data to JSON format for web app\n",
    "# Rename 'probability' to 'likely' to match spec\n",
    "quiz_data = []\n",
    "\n",
    "for idx, row in quiz_text.iterrows():\n",
    "    question_obj = {\n",
    "        \"task_id\": row['task_id'],\n",
    "        \"text\": row['question'],\n",
    "        \"options\": [\n",
    "            row['option_1'],\n",
    "            row['option_2'],\n",
    "            row['option_3'],\n",
    "            row['option_4']\n",
    "        ],\n",
    "        \"correctIndex\": int(row['correct_answer']) - 1,  # Convert 1-4 to 0-3\n",
    "        \"likely\": float(row['probability']),\n",
    "        \"explanation\": row['Explanation'],\n",
    "        \"skillName\": row['skill_name'],\n",
    "        \"skillDefinition\": row['skill_definition']\n",
    "    }\n",
    "    quiz_data.append(question_obj)\n",
    "\n",
    "# Save to JSON file\n",
    "import json\n",
    "output_path = os.path.join(os.path.dirname(__file__) if '__file__' in dir() else '', 'quiz_data.json')\n",
    "output_path = r'C:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\\Ver_2\\quiz-app/public\\quiz_data.json'\n",
    "\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(quiz_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Exported {len(quiz_data)} questions to {output_path}\")\n",
    "print(f\"\\nSample question:\")\n",
    "print(json.dumps(quiz_data[1], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eba941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2920eaf6",
   "metadata": {},
   "source": [
    "## Quiz Application Development - Completed \n",
    "\n",
    "The web application has been successfully created and is located in `Ver_2/quiz-app/`\n",
    "\n",
    "### Project Structure\n",
    "\n",
    "```\n",
    "quiz-app/\n",
    " public/\n",
    "    quiz_data.json          # Quiz questions data\n",
    " src/\n",
    "    components/\n",
    "       Header.tsx          # Header with progress bar and Finish button\n",
    "       Header.css\n",
    "       Footer.tsx          # Footer component\n",
    "       Footer.css\n",
    "    pages/\n",
    "       Welcome.tsx         # Welcome/start screen\n",
    "       Welcome.css\n",
    "       Question.tsx        # Question display with radio options\n",
    "       Question.css\n",
    "       Result.tsx          # Result screen with feedback\n",
    "       Result.css\n",
    "       Finish.tsx          # Final statistics and training list\n",
    "       Finish.css\n",
    "    types.ts                # TypeScript type definitions\n",
    "    utils.ts                # Utility functions (shuffle, sort, stats)\n",
    "    store.ts                # Zustand state management with localStorage\n",
    "    App.tsx                 # Main app with routing\n",
    "    App.css\n",
    "    index.css               # Global styles with CSS variables\n",
    "    main.tsx\n",
    " package.json\n",
    " vite.config.ts\n",
    " tsconfig.json\n",
    "```\n",
    "\n",
    "### Key Features Implemented\n",
    "\n",
    "1. **State Management (Zustand)**\n",
    "   - Questions sorted by likelihood (easiest first)\n",
    "   - Options shuffled using Fisher-Yates algorithm\n",
    "   - Answers tracked with correctness and difficulty\n",
    "   - Training list for questions to review\n",
    "   - localStorage persistence (session survives page refresh)\n",
    "\n",
    "2. **Routing (React Router)**\n",
    "   - `/welcome` - Welcome screen with instructions\n",
    "   - `/q/:index` - Question page\n",
    "   - `/result/:index` - Result page with feedback\n",
    "   - `/finish` - Final statistics and training list\n",
    "\n",
    "3. **Components**\n",
    "   - **Header**: Progress bar showing \"Answered X / Total\", Finish button\n",
    "   - **Question**: Radio group with shuffled options, Submit button (disabled until option selected)\n",
    "   - **Result**: Correct/Incorrect verdict, explanation, checkboxes for training list and issue reporting\n",
    "   - **Finish**: Statistics (answered, correct, average difficulty), training list with Save/Print/Clear\n",
    "\n",
    "4. **Accessibility**\n",
    "   - Semantic HTML (header, main, footer, role=\"radiogroup\")\n",
    "   - aria-live region for result announcements\n",
    "   - Keyboard navigation support\n",
    "   - Focus styles\n",
    "\n",
    "5. **Responsive Design**\n",
    "   - Mobile-first approach\n",
    "   - Breakpoints: 320px, 480px, 768px, 1024px+\n",
    "   - Print styles for training list\n",
    "\n",
    "6. **Statistics**\n",
    "   - Average difficulty of correctly answered questions = avg(1 - likely) for correct answers\n",
    "   - Displayed as percentage (e.g., 37%)\n",
    "\n",
    "7. **Navigation Warning**\n",
    "   - Users are advised: *\"Please don't use browser navigation buttons (Back/Forward). Use in-app buttons for consistent results.\"*\n",
    "\n",
    "### How to Run\n",
    "\n",
    "1. **Development Server** (already running):\n",
    "   ```powershell\n",
    "   cd \"c:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\\Ver_2\\quiz-app\"\n",
    "   npm run dev\n",
    "   ```\n",
    "   Opens at: http://localhost:5173/\n",
    "\n",
    "2. **Build for Production**:\n",
    "   ```powershell\n",
    "   cd \"c:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\\Ver_2\\quiz-app\"\n",
    "   npm run build\n",
    "   npm run preview\n",
    "   ```\n",
    "\n",
    "3. **Update Quiz Data**:\n",
    "   - Run the Python cell above to generate new `quiz_data.json`\n",
    "   - Copy to `quiz-app/public/quiz_data.json`\n",
    "   - Refresh browser or restart dev server\n",
    "\n",
    "### Tech Stack\n",
    "\n",
    "- **Frontend**: React 18 + TypeScript\n",
    "- **Build Tool**: Vite\n",
    "- **Routing**: React Router v6\n",
    "- **State**: Zustand with persist middleware\n",
    "- **Styling**: CSS with custom properties (variables)\n",
    "- **No external UI libraries** - pure CSS for lightweight prototype\n",
    "\n",
    "### Next Steps (Optional Enhancements)\n",
    "\n",
    "- Deploy to Vercel/Netlify\n",
    "- Add serverless function for issue reporting (currently console.log)\n",
    "- Add Google Analytics\n",
    "- Add data validation with error page\n",
    "- Implement PDF export for training list (currently JSON only)\n",
    "- Add unit tests with Vitest\n",
    "- Add E2E tests with Playwright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d827a8",
   "metadata": {},
   "source": [
    "## Testing the Application\n",
    "\n",
    "The application is now running at **http://localhost:5174/**\n",
    "\n",
    "### User Flow\n",
    "\n",
    "1. **Welcome Page**\n",
    "   - Click \"Start Test\" to begin\n",
    "\n",
    "2. **Question Page**\n",
    "   - See question number and skill name (italicized)\n",
    "   - Read the question\n",
    "   - Select one of 4 radio button options (shuffled)\n",
    "   - Click \"Submit Answer\" (only enabled after selection)\n",
    "   - Click \"Back\" button to return to previous question (available from question 2 onwards)\n",
    "   - Or click \"Finish\" in header to end quiz early\n",
    "\n",
    "3. **Result Page**\n",
    "   - See \"Correct\" or \"Incorrect\" verdict\n",
    "   - View skill name and skill definition (in italicized note style)\n",
    "   - Read explanation\n",
    "   - Optionally check \"Add this skill to the training list\"\n",
    "   - Optionally check \"Report an issue with this question\"\n",
    "   - Click \"Next\" to continue (shows report modal if issue checkbox was checked)\n",
    "\n",
    "4. **Finish Page**\n",
    "   - View statistics:\n",
    "     - Total answered\n",
    "     - Correct answers\n",
    "     - Average difficulty of correctly answered questions (%)\n",
    "   - View training list (simplified list of skill names only)\n",
    "   - Save training list as CSV (skill names)\n",
    "   - Print training list\n",
    "   - Restart quiz\n",
    "   - **Test results are automatically saved to server** (no user action needed)\n",
    "\n",
    "### Features to Test\n",
    "\n",
    " Questions sorted by likelihood (easiest first)  \n",
    " Options shuffled each time  \n",
    " Progress indicator in header  \n",
    " Submit disabled until option selected  \n",
    " Can change selection before submit  \n",
    " Back button navigates to previous question  \n",
    " Skill name displayed on question page  \n",
    " Skill name and definition on result page  \n",
    " Training list shows only skill names  \n",
    " Training list persists across pages  \n",
    " Issue reporting with modal  \n",
    " Session persists on page refresh (localStorage)  \n",
    " Responsive design (try resizing browser)  \n",
    " Statistics calculation  \n",
    " Export training list as CSV  \n",
    " Print training list  \n",
    " **Automatic server-side results storage**  \n",
    "\n",
    "### Test Results Storage\n",
    "\n",
    "**Automatic Saving:**\n",
    "- Test results are automatically saved when user reaches the Finish page\n",
    "- No manual download or user interaction required\n",
    "- Results saved in both CSV and JSON formats\n",
    "\n",
    "**Storage Location:**\n",
    "- Directory: `Ver_2/quiz-app/test-results/`\n",
    "- File naming: `results_{userId}_{sessionId}_{date}.csv` and `.json`\n",
    "\n",
    "**Data Captured:**\n",
    "- `session_id` - Unique session identifier\n",
    "- `timestamp` - When each answer was submitted\n",
    "- `user_id` - User identifier (default: \"anonymous\")\n",
    "- `task_id` - Question/task identifier\n",
    "- `selected_option` - User's selected answer text\n",
    "- `is_correct` - Boolean (true/false)\n",
    "\n",
    "**Server Setup (Optional - for development):**\n",
    "If you want to test the server-side saving locally:\n",
    "\n",
    "```powershell\n",
    "# Install dependencies (if not already installed)\n",
    "cd \"c:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\\Ver_2\\quiz-app\"\n",
    "npm install express cors\n",
    "\n",
    "# Run the results server in a separate terminal\n",
    "node server/save-results-server.js\n",
    "# Server will run on http://localhost:3001\n",
    "```\n",
    "\n",
    "The results server will create a `test-results/` directory and save all completed tests there.\n",
    "\n",
    "### Keyboard Navigation\n",
    "\n",
    "- Tab: Move between elements\n",
    "- Space/Enter: Select radio option or activate button\n",
    "- Arrow keys: Navigate radio group\n",
    "\n",
    "### Recent Updates\n",
    "\n",
    "**Test Results Storage:**\n",
    "- Automatic server-side saving of all test results\n",
    "- Results saved in CSV and JSON formats\n",
    "- Includes session_id, timestamp, user_id, task_id, selected_option, is_correct\n",
    "- Storage location: `quiz-app/test-results/`\n",
    "\n",
    "**Navigation Enhancement:**\n",
    "- Back button navigates to previous question (not result page)\n",
    "- Users can review previous questions while maintaining their answers\n",
    "\n",
    "**Skill Information Display:**\n",
    "- Question page shows the skill name being tested\n",
    "- Result page displays both skill name and full definition\n",
    "- Skill definition shown in italicized style for clarity\n",
    "\n",
    "**Training List Improvements:**\n",
    "- Training list simplified to show only skill names\n",
    "- Export changed from JSON to CSV format\n",
    "- CSV contains single column with skill names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad35d8",
   "metadata": {},
   "source": [
    "Creating and publishing a web  application for the test. The application interface is in English.\n",
    "1.\tObjectives and main solutions\n",
    "\tSupported platforms: desktop and mobile (responsive design).\n",
    "\tStack :\n",
    "o\tFrontend: React + TypeScript, Vite, React Router, Zustand or Redux Toolkit for states , Tailwind CSS or CSS Modules for stylization .\n",
    "o\tparsing : Papa Parse.\n",
    "o\tHosting: Vercel or Netlify (static site + serverless  functions for feedback/logs).\n",
    "o\tAnalytics: Plausible / Google Analytics (no personal data).\n",
    "\tSession data storage: localStorage (progress, responses, training list).\n",
    "\tError reports: serverless  function ( Webhook in Slack / Email ) or form service ( Formsprue / Netlify) Forms ).\n",
    "2. CSV and data\n",
    "\tCSV format ( required) columns ): question, option_1, option_2, option_3, option_4, correct_answer (14), likely (01), explanation.\n",
    "\tValidation at loading :\n",
    "o\tAvailability everyone columns , correct_answer  {1,2, 3,4}, likely  [0,1].\n",
    "o\tHTML sanitization , escaping to prevent XSS .\n",
    "\tPreprocessing :\n",
    "o\tConvert to Question structure : id, text, options[ 4], correctIndex (03), likely, explanation.\n",
    "o\tSort questions by likelihood in ascending order (easiest first; if tied, random order for variety).\n",
    "o\tFor each session, a random permutation of options ( Fisher  Yates ) is performed, forming the correctOptionId after shuffling.\n",
    "\tNote on \"difficulty\": likely is the probability of a correct answer ( easiness ). For the difficulty metric, we use difficulty = 1 - likely . On the final page, we display \" Average\" difficulty of correctly answered questions  as the average difficulty for those answered correctly.\n",
    "3. Custom scenarios\n",
    "\tWelcome:\n",
    "o\tStart test button .\n",
    "o\tA short explanation of the process and a Finish button in a prominent place after the start.\n",
    "\tQuestion page:\n",
    "o\tOne question on screen .\n",
    "o\t4 radio  options (shuffled each time).\n",
    "o\tButtons: Submit (active only after selecting an option), Finish (in the header).\n",
    "o\tThe user can change the selection before Submit .\n",
    "o\tThe progress indicator is always visible:  Answered X / 144.\n",
    "\tResult page:\n",
    "o\tMessage Correct / Incorrect and the correct answer.\n",
    "o\tExplanation ( from CSV).\n",
    "o\tTwo checkbox :\n",
    "\tAdd this skill to the training list\n",
    "\tReport an issue with this question\n",
    "o\tNext button moves to the next question.\n",
    "o\tIf  Report an issue  is checked, when Next we show a modal window with the  Describe  field the issue ( optional ) and the Send button ; we send JSON to the serverles  function along with the question context and the user's option.\n",
    "\tFinish:\n",
    "o\tFinish button is always available (in the header). When when pressed - confirmation .\n",
    "o\tThank You Page you  and statistics:\n",
    "\tAnswered : N of 144\n",
    "\tCorrect answers: M\n",
    "\tAverage difficulty of correctly answered: value from 0 to 1 (and %, for example 0.37 = 37%)\n",
    "o\tTraining list block :\n",
    "\tView the list of pending questions (question text, correct answer, explanation ).\n",
    "\tButtons: Save (download as PDF / JSON ), Print , Clear (clear list).\n",
    "\tPossibility to continue testing after reboot (session state is stored in localStorage ).\n",
    "4. Architecture and Components\n",
    "\tLayout:\n",
    "o\tHeader : logo/title, progress bar/counter, button Finish .\n",
    "o\tMain: routes pages .\n",
    "o\tFooter ( minimalistic , copyright ).\n",
    "\tRoutes :\n",
    "o\t/ welcome\n",
    "o\t/q /:index ( screen question )\n",
    "o\t/result /:index\n",
    "o\t/ finish\n",
    "\tCondition (store):\n",
    "o\tquestions : an array of sorted questions with shuffled options.\n",
    "o\tcurrentIndex\n",
    "o\tanswers: list { questionId , selectedOptionId , isCorrect , likely}\n",
    "o\ttrainingList : set questionId\n",
    "o\treportsQueue : temporary reports to dispatches\n",
    "o\tpersisted timestamp, CSV version\n",
    "\tComponents :\n",
    "o\tProgressIndicator (Answered X/Total, progress bar )\n",
    "o\tQuestionCard ( radio  group , accessibility )\n",
    "o\tResultPanel ( verdict , explanation, checkboxes )\n",
    "o\tTrainingListView (table/list + export/print)\n",
    "o\tConfirmFinishModal\n",
    "\tStyles :\n",
    "o\tColors: blue/white, high contrast.\n",
    "o\tTopics via CSS variables : primary-blue, text, background.\n",
    "o\tAdaptive : mobile first , breakpoints for 3204807681024+.\n",
    "5. Logic and algorithms\n",
    "\tMixing options :\n",
    "o\tFisher  Yates over the options array , then compute the index of the correct answer in the new order.\n",
    "\tCount statistics :\n",
    "o\tanswered = length of answers\n",
    "o\tcorrect = quantity isCorrect = true\n",
    "o\tavgDifficultyCorrect = average of (1  likely ) correct answers only; if there are no correct answers,  N / A .\n",
    "\tProgress :\n",
    "o\tIt's increasing when Submit.\n",
    "\tStorage :\n",
    "o\tAll key structures in localStorage with the data version; if the CSV ( eTag /hash) changes , reset the session or offer to continue with the old one/start over.\n",
    "6. Accessibility (a11y)\n",
    "\tSemantic markup : <main>, <header>, <nav>, <section>.\n",
    "\tRadio  group with role = \" radiogroup \" and available labels.\n",
    "\tFocus  styles and keyboard controls ( Tab , Space / Enter ).\n",
    "\tLive region (aria-live=polite) for Correct/Incorrect verdict .\n",
    "\tColor contrast according to WCAG AA .\n",
    "7. Security and privacy\n",
    "\tEscape content from CSV , block dangerous HTML .\n",
    "\tLength limitation and text cleanup in error messages.\n",
    "\tCORS / CSRF : for serverless  functions - domain restriction, no return of sensitive data.\n",
    "\tNo personal data; analytics are aggregated.\n",
    "8. Export and print your training list\n",
    "\tFormats :\n",
    "o\tPrint : separate route/mode with print style (hide navigation).\n",
    "o\tSave : Generate PDF via browser print to PDF or use html 2 pdf ; also JSON file (for import back).\n",
    "\tContent :\n",
    "o\tQuestion, correct answer, explanation , probability label likely (or difficulty 1 - likely ).\n",
    "9. Interface content and texts (English)\n",
    "\tWelcome: Start test\n",
    "\tSubmit/Next/Finish\n",
    "\tResult: Correct / Incorrect, Explanation\n",
    "\tCheckboxes: Add this skill to the training list, Report an issue with this question\n",
    "\tFinish page: Thank you, Answered, Correct answers, Average difficulty of correctly answered questions, Training list, Save, Print.\n",
    "10. Testing\n",
    "\tUnit:\n",
    "o\tCSV parsing and validation .\n",
    "o\tShuffling and correct mapping of the correct answer.\n",
    "o\tCount statistics .\n",
    "\tE2E (Playwright/Cypress):\n",
    "o\tComplete passage of several questions, correct transitions, progress, finish.\n",
    "o\tMobile viewports .\n",
    "\tAccessibility: axe-core.\n",
    "\tRegression : UI snapshots .\n",
    "11. Performance\n",
    "\t144 questions is a small one volume , but :\n",
    "o\tLazy initialization of explanations in DOM .\n",
    "o\tPreloading next question .\n",
    "o\tVite code  splitting by routes .\n",
    "12. Assembly and deployment\n",
    "\tRepository : GitHub/GitLab.\n",
    "\tCI:\n",
    "o\tLint, TypeScript, unit  tests on push/PR.\n",
    "o\tBuild.\n",
    "\tHosting :\n",
    "o\tVercel /Netlify: one prod  environment , one preview.\n",
    "o\tServerless:\n",
    "\tPOST / api / reportIssue - accepts { questionId , questionText , selectedOption , correctOption , userNote , csvVersion , ua , time}, sends to Slack/Email.\n",
    "\tWednesdays :\n",
    "o\tENV: CSV_URL, REPORT_WEBHOOK_URL, ANALYTICS_KEY.\n",
    "\tDomains :\n",
    "o\tSubdomain , HTTPS, redirects .\n",
    "13. Plan works ( approximately )\n",
    "\tDay 12: UX  wireframes , approve interface texts, data schema.\n",
    "\tDay 3: State design, routing , parsing CSV , sorting, shuffling.\n",
    "\tDay 4: Welcome , Question , Result , Progress Header and Finish screens .\n",
    "\tDay 5: Export/Print Training list , Finish page with statistics.\n",
    "\tDay 6: Report issue ( serverles ), analytics, localStorage , session recovery.\n",
    "\tDay 7: Adaptive , a 11 y , tests, polishing, deploy to preview .\n",
    "\tDay 8: Review, fixes, production  deployment, monitoring.\n",
    "14. To the criteria acceptance\n",
    "\tApplication on English , adaptive .\n",
    "\tQuestions are displayed in ascending order of likely ; options are displayed in random order.\n",
    "\tUnable to ship without selected option.\n",
    "\tOn the Result  screen : verdict , explanation, 2 checkboxes , Next.\n",
    "\tConstant progress indicator and accessible Finish button .\n",
    "\tFinish  page: thanks, numbers answered / correct , average difficulty correct.\n",
    "\tTraining list can be viewed, saved ( PDF / JSON ) and printed.\n",
    "\tThe error report is sent and logged .\n",
    "\tSession is being restored after reboots .\n",
    "15. Risks and Solutions\n",
    "\tInterpretation of \"difficulty\": we use 1 - likely ; you can additionally display a hint on the page.\n",
    "\tCSV Quality : Add page  Data status  with the validation results and the number of ignored records.\n",
    "\tMass audience and load: static + server forest scale automatically.\n",
    "16. Short technical skeleton\n",
    "\tTypes :\n",
    "o\tQuestion { id , text, options: string[ 4], correctIndex : number, likely: number, explanation: string }\n",
    "o\tShuffledQuestion { id , text, options: { id :number , text:string }[ ], correctOptionId:number , likely:number , explanation:string }\n",
    "o\tAnswer { questionId , selectedOptionId , isCorrect , likely }\n",
    "\tMain functions :\n",
    "o\tparseCsv ( csvText ) -> Question[ ]\n",
    "o\tsortByLikely (questions)\n",
    "o\tshuffleOptions (question) -> ShuffledQuestion\n",
    "o\tcomputeStats (answers) -> { answered , correct, avgDifficultyCorrect }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
