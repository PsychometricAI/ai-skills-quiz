{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab3e4c6-13b9-44b1-b295-bd0f7ea5bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f829b7-3063-4070-a539-19ed8f507cb5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# old version\n",
    "\n",
    "# Function to extract text content after a specific title\n",
    "def get_content_after_title(soup, title_text):\n",
    "    \"\"\"\n",
    "    Finds the content after a given title (h1 or h2) until the next h1 or h2.\n",
    "    \"\"\"\n",
    "    # Find the title tag (h1 or h2) with the exact text\n",
    "    title = soup.find(lambda tag: tag.name in ['h1', 'h2'] and tag.get_text(strip=True) == title_text)\n",
    "    if not title:\n",
    "        print(f\"Title '{title_text}' not found.\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize an empty list to hold the content\n",
    "    content = []\n",
    "    \n",
    "    # Iterate over the next siblings until the next h1 or h2\n",
    "    for sibling in title.find_next_siblings():\n",
    "        if sibling.name in ['h1', 'h2']:\n",
    "            break\n",
    "        # Append the text content of the sibling\n",
    "        text = sibling.get_text(separator=\"\\n\", strip=True)\n",
    "        if text:  # Avoid adding empty strings\n",
    "            content.append(text)\n",
    "    \n",
    "    # Join the collected text into a single string\n",
    "    return \"\\n\".join(content) if content else None\n",
    "\n",
    "def main():\n",
    "    # URL of the web page to scrape\n",
    "    url = 'https://buttondown.com/ainews/archive/ainews-shazeer-et-al-2024/'\n",
    "    \n",
    "    try:\n",
    "        # Fetch the web page content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup with the 'lxml' parser\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    # Locate the main container holding the email content\n",
    "    email_body = soup.find('div', class_='email-body-content')\n",
    "    if not email_body:\n",
    "        print(\"Couldn't find the 'email-body-content' div.\")\n",
    "        return\n",
    "    \n",
    "    # 1. Extract the Date\n",
    "    date_tag = email_body.find('date')\n",
    "    date_text = date_tag.get_text(strip=True) if date_tag else \"Date not found.\"\n",
    "    \n",
    "    # 2. Extract the Post Title\n",
    "    title_tag = email_body.find('h1', class_='subject')\n",
    "    title_text = title_tag.get_text(strip=True) if title_tag else \"Title not found.\"\n",
    "    \n",
    "    # 3. Extract the News Period from the first blockquote containing a date range\n",
    "    blockquotes = email_body.find_all('blockquote')\n",
    "    news_period = None\n",
    "    for bq in blockquotes:\n",
    "        # Search for a date range pattern like '3/28/2025-3/31/2025'\n",
    "        match = re.search(r'\\b(\\d{1,2}/\\d{1,2}/\\d{4}-\\d{1,2}/\\d{1,2}/\\d{4})\\b', bq.get_text())\n",
    "        if match:\n",
    "            news_period = match.group(1)\n",
    "            break\n",
    "    if not news_period:\n",
    "        news_period = \"News period not found.\"\n",
    "    \n",
    "    # 4. Extract Content After Specific Titles\n",
    "    ai_twitter_recap = get_content_after_title(soup, 'AI Twitter Recap')\n",
    "    ai_reddit_recap = get_content_after_title(soup, 'AI Reddit Recap')\n",
    "    ai_discord_recap = get_content_after_title(soup, 'AI Discord Recap')\n",
    "    \n",
    "    # Organize the extracted data into a dictionary\n",
    "    extracted_data = {\n",
    "        'Date': date_text,\n",
    "        'Post Title': title_text,\n",
    "        'News Period': news_period,\n",
    "        'AI Twitter Recap': ai_twitter_recap,\n",
    "        'AI Reddit Recap': ai_reddit_recap,\n",
    "        'AI Discord Recap': ai_discord_recap\n",
    "    }\n",
    "    \n",
    "    # Display the extracted information\n",
    "    for key, value in extracted_data.items():\n",
    "        print(f\"{key}:\\n{value}\\n{'-'*50}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d221b21c-8cae-4959-9b93-35c1a1a1c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://news.smol.ai/issues/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-06-ainews-is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-07-ainews-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-08-ainews-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-09-ainews-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-23-not-much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-24-not-much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-27-minimax-m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-28-openai-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>https://news.smol.ai/issues/?pattern=gemini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                         https://news.smol.ai/issues/\n",
       "1    https://news.smol.ai/issues/23-12-06-ainews-is...\n",
       "2    https://news.smol.ai/issues/23-12-07-ainews-12...\n",
       "3    https://news.smol.ai/issues/23-12-08-ainews-12...\n",
       "4    https://news.smol.ai/issues/23-12-09-ainews-12...\n",
       "..                                                 ...\n",
       "492      https://news.smol.ai/issues/25-10-23-not-much\n",
       "493      https://news.smol.ai/issues/25-10-24-not-much\n",
       "494    https://news.smol.ai/issues/25-10-27-minimax-m2\n",
       "495  https://news.smol.ai/issues/25-10-28-openai-re...\n",
       "496        https://news.smol.ai/issues/?pattern=gemini\n",
       "\n",
       "[497 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'C:\\\\Users\\\\Denis_Davydov2\\\\OneDrive\\\\Scipts\\\\Py_Scripts\\\\EPAM\\\\Prophet\\\\AI_skills\\\\'\n",
    "\n",
    "print(file_path)\n",
    "file_name = 'smolai_urls.txt'\n",
    "\n",
    "\n",
    "links = pd.read_csv(file_path+file_name, header=None)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62a0350a-290a-47f4-ba17-5c8138cf01c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read:  smolai_urls.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://news.smol.ai/issues/</td>\n",
       "      <td>https://news.smol.ai/issues/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-06-ainews-is...</td>\n",
       "      <td>https://news.smol.ai/issues/23-12-06-ainews-is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-07-ainews-12...</td>\n",
       "      <td>https://news.smol.ai/issues/23-12-07-ainews-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-08-ainews-12...</td>\n",
       "      <td>https://news.smol.ai/issues/23-12-08-ainews-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://news.smol.ai/issues/23-12-09-ainews-12...</td>\n",
       "      <td>https://news.smol.ai/issues/23-12-09-ainews-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-23-not-much</td>\n",
       "      <td>https://news.smol.ai/issues/25-10-23-not-much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-24-not-much</td>\n",
       "      <td>https://news.smol.ai/issues/25-10-24-not-much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-27-minimax-m2</td>\n",
       "      <td>https://news.smol.ai/issues/25-10-27-minimax-m2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>https://news.smol.ai/issues/25-10-28-openai-re...</td>\n",
       "      <td>https://news.smol.ai/issues/25-10-28-openai-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>https://news.smol.ai/issues/?pattern=gemini</td>\n",
       "      <td>https://news.smol.ai/issues/?pattern=gemini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0                         https://news.smol.ai/issues/   \n",
       "1    https://news.smol.ai/issues/23-12-06-ainews-is...   \n",
       "2    https://news.smol.ai/issues/23-12-07-ainews-12...   \n",
       "3    https://news.smol.ai/issues/23-12-08-ainews-12...   \n",
       "4    https://news.smol.ai/issues/23-12-09-ainews-12...   \n",
       "..                                                 ...   \n",
       "492      https://news.smol.ai/issues/25-10-23-not-much   \n",
       "493      https://news.smol.ai/issues/25-10-24-not-much   \n",
       "494    https://news.smol.ai/issues/25-10-27-minimax-m2   \n",
       "495  https://news.smol.ai/issues/25-10-28-openai-re...   \n",
       "496        https://news.smol.ai/issues/?pattern=gemini   \n",
       "\n",
       "                                                  urls  \n",
       "0                         https://news.smol.ai/issues/  \n",
       "1    https://news.smol.ai/issues/23-12-06-ainews-is...  \n",
       "2    https://news.smol.ai/issues/23-12-07-ainews-12...  \n",
       "3    https://news.smol.ai/issues/23-12-08-ainews-12...  \n",
       "4    https://news.smol.ai/issues/23-12-09-ainews-12...  \n",
       "..                                                 ...  \n",
       "492      https://news.smol.ai/issues/25-10-23-not-much  \n",
       "493      https://news.smol.ai/issues/25-10-24-not-much  \n",
       "494    https://news.smol.ai/issues/25-10-27-minimax-m2  \n",
       "495  https://news.smol.ai/issues/25-10-28-openai-re...  \n",
       "496        https://news.smol.ai/issues/?pattern=gemini  \n",
       "\n",
       "[497 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links['urls'] = links[0].astype(str)\n",
    "\n",
    "#links = links.iloc[:10]\n",
    "\n",
    "print(\"File read: \", file_name)\n",
    "urls = links['urls'].tolist()\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59cd26a-8cc6-4a1a-90ce-9b531ab08272",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://news.smol.ai/issues/',\n",
       " 'https://news.smol.ai/issues/23-12-06-ainews-is-googles-gemini-legit',\n",
       " 'https://news.smol.ai/issues/23-12-07-ainews-1272023-anthropic-says-skill-issue',\n",
       " 'https://news.smol.ai/issues/23-12-08-ainews-1282023-mamba-v-mistral-v-hyena',\n",
       " 'https://news.smol.ai/issues/23-12-09-ainews-1292023-the-mixtral-rush',\n",
       " 'https://news.smol.ai/issues/23-12-10-ainews-12102023-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/23-12-11-ainews-12112023-mixtral-beats-gpt35-and-llama2-70b',\n",
       " 'https://news.smol.ai/issues/23-12-12-ainews-12122023-towards-langchain-01',\n",
       " 'https://news.smol.ai/issues/23-12-13-ainews-12132023-solar107b-upstages-mistral7b',\n",
       " 'https://news.smol.ai/issues/23-12-14-ainews-12142023-dollar1e7-for-superalignment',\n",
       " 'https://news.smol.ai/issues/23-12-15-ainews-12152023-mixtral-instruct-beats-gemini-pro-and-matches-gpt35',\n",
       " 'https://news.smol.ai/issues/23-12-16-ainews-12162023-bytedance-suspended-by-openai',\n",
       " 'https://news.smol.ai/issues/23-12-18-ainews-12182023-gaslighting-mistral-for-fun-and-profit',\n",
       " 'https://news.smol.ai/issues/23-12-20-ainews-12192023-everybody-loves-openrouter',\n",
       " 'https://news.smol.ai/issues/23-12-20-ainews-12202023-project-obsidian-multimodal-mistral-7b-from-nous',\n",
       " 'https://news.smol.ai/issues/23-12-21-ainews-12212023-the-state-of-ai-according-to-langchain',\n",
       " 'https://news.smol.ai/issues/23-12-22-ainews-12222023-anyscales-benchmark-criticisms',\n",
       " 'https://news.smol.ai/issues/23-12-23-ainews-12232023-neurips-best-papers-of-2023',\n",
       " 'https://news.smol.ai/issues/23-12-25-ainews-12242023-dolphin-mixtral-8x7b-is-wild',\n",
       " 'https://news.smol.ai/issues/23-12-25-ainews-12252023-nous-hermes-2-yi-34b-for-christmas',\n",
       " 'https://news.smol.ai/issues/23-12-29-ainews-12262023-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/23-12-29-ainews-12272023-nyt-vs-openai',\n",
       " 'https://news.smol.ai/issues/23-12-29-ainews-12282023-smol-talk-updates',\n",
       " 'https://news.smol.ai/issues/23-12-30-ainews-12292023-tinyllama-on-the-way',\n",
       " 'https://news.smol.ai/issues/23-12-31-ainews-12302023-mega-list-of-all-llms',\n",
       " 'https://news.smol.ai/issues/23-12-31-ainews-12312023-happy-new-year',\n",
       " 'https://news.smol.ai/issues/24-01-02-ainews-112024-how-to-start-with-open-source-ai',\n",
       " 'https://news.smol.ai/issues/24-01-02-ainews-122024-smol-tweaks-to-smol-talk',\n",
       " 'https://news.smol.ai/issues/24-01-03-ainews-132024-rip-coqui',\n",
       " 'https://news.smol.ai/issues/24-01-05-ainews-142024-jeff-bezos-backs-perplexitys-dollar520m-series-b',\n",
       " 'https://news.smol.ai/issues/24-01-07-ainews-16-72024-llama-pro-an-alternative-to-peftrag',\n",
       " 'https://news.smol.ai/issues/24-01-08-ainews-182024-the-four-wars-of-the-ai-stack',\n",
       " 'https://news.smol.ai/issues/24-01-10-ainews-192024-nous-research-lands-dollar5m-for-open-source-ai',\n",
       " 'https://news.smol.ai/issues/24-01-11-ainews-1102024-all-the-best-papers-for-ai-engineers',\n",
       " 'https://news.smol.ai/issues/24-01-12-ainews-1112024-mixing-experts-vs-merging-models',\n",
       " 'https://news.smol.ai/issues/24-01-13-ainews-1122024-anthropic-coins-sleeper-agents',\n",
       " 'https://news.smol.ai/issues/24-01-15-ainews-113-142024-dont-sleep-on-prompt-engineering',\n",
       " 'https://news.smol.ai/issues/24-01-16-ainews-1162024-ties-merging',\n",
       " 'https://news.smol.ai/issues/24-01-17-ainews-1162024-artificialanalysis-a-new-modelhost-benchmark-site',\n",
       " 'https://news.smol.ai/issues/24-01-18-ainews-1172024-help-crowdsource-function-calling-datasets',\n",
       " 'https://news.smol.ai/issues/24-01-22-ainews-nightshade-poisons-ai-art-kinda',\n",
       " 'https://news.smol.ai/issues/24-01-22-ainews-sama-says-gpt-5-soon',\n",
       " 'https://news.smol.ai/issues/24-01-23-ainews-rip-latent-diffusion-hello-hourglass-diffusion',\n",
       " 'https://news.smol.ai/issues/24-01-24-ainews-google-solves-text-to-video',\n",
       " 'https://news.smol.ai/issues/24-01-25-ainews-adept-fuyu-heavy-multimodal-model-for-agents',\n",
       " 'https://news.smol.ai/issues/24-01-26-ainews-gpt4turbo-ab-test-gpt-4-0125-preview',\n",
       " 'https://news.smol.ai/issues/24-01-26-ainews-gpt4turbo-ab-test-gpt-4-1106-preview',\n",
       " 'https://news.smol.ai/issues/24-01-29-ainews-rwkv-eagle-v5-your-move-mamba',\n",
       " 'https://news.smol.ai/issues/24-01-30-ainews-codellama-70b-beats-gpt4-on-humaneval',\n",
       " 'https://news.smol.ai/issues/24-01-31-ainews-miqu-confirmed-to-be-an-early-mistral-medium-checkpoint',\n",
       " 'https://news.smol.ai/issues/24-02-01-ainews-trust-in-gpts-at-all-time-low',\n",
       " 'https://news.smol.ai/issues/24-02-02-ainews-ai2-releases-olmo-the-4th-open-everything-llm',\n",
       " 'https://news.smol.ai/issues/24-02-03-ainews-the-core-skills-of-ai-engineering',\n",
       " 'https://news.smol.ai/issues/24-02-05-ainews-less-lazy-ai',\n",
       " 'https://news.smol.ai/issues/24-02-06-ainews-qwen-15-released',\n",
       " 'https://news.smol.ai/issues/24-02-07-ainews-metavoice-and-rip-bard',\n",
       " 'https://news.smol.ai/issues/24-02-08-ainews-gemini-ultra-is-out-to-mixed-reviews',\n",
       " 'https://news.smol.ai/issues/24-02-12-ainews-the-dissection-of-smaug-72b',\n",
       " 'https://news.smol.ai/issues/24-02-14-ainews-ai-gets-memory',\n",
       " 'https://news.smol.ai/issues/24-02-16-ainews-sora-pushes-sota',\n",
       " 'https://news.smol.ai/issues/24-02-19-ainews-companies-liable-for-ai-hallucination-is-good-actually-for-ai-engineers',\n",
       " 'https://news.smol.ai/issues/24-02-20-ainews-karpathy-emerges-from-stealth',\n",
       " 'https://news.smol.ai/issues/24-02-21-ainews-google-ai-win-some-gemma-15-pro-lose-some-image-gen',\n",
       " 'https://news.smol.ai/issues/24-02-22-ainews-ring-attention-for-greater1m-context',\n",
       " 'https://news.smol.ai/issues/24-02-23-ainews-one-year-of-latent-space',\n",
       " 'https://news.smol.ai/issues/24-02-26-ainews-mistral-large-disappoints',\n",
       " 'https://news.smol.ai/issues/24-02-27-ainews-welcome-interconnects-and-openrouter',\n",
       " 'https://news.smol.ai/issues/24-02-28-ainews-and-welcome-ai-twitter',\n",
       " 'https://news.smol.ai/issues/24-02-29-ainews-dia-de-las-secuelas-starcoder-the-stack-dune-semianalysis',\n",
       " 'https://news.smol.ai/issues/24-03-01-ainews-the-era-of-1-bit-llms',\n",
       " 'https://news.smol.ai/issues/24-03-04-ainews-claude-3-just-destroyed-gpt-4-see-for-yourself',\n",
       " 'https://news.smol.ai/issues/24-03-05-ainews-stable-diffusion-3-rombach-and-esser-did-it-again',\n",
       " 'https://news.smol.ai/issues/24-03-06-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-03-07-ainews-inflection-25-at-94percent-of-gpt4-and-pi-at-6m-mau',\n",
       " 'https://news.smol.ai/issues/24-03-08-ainews-fsdpqlora-the-answer-to-70b-scale-ai-for-desktop-class-gpus',\n",
       " 'https://news.smol.ai/issues/24-03-11-ainews-fixing-gemma',\n",
       " 'https://news.smol.ai/issues/24-03-12-ainews-the-worlds-first-fully-autonomous-ai-engineer',\n",
       " 'https://news.smol.ai/issues/24-03-13-ainews-deepmind-sima-one-ai-9-games-600-tasks-visionlanguage-only',\n",
       " 'https://news.smol.ai/issues/24-03-14-ainews-not-much-happened-piday',\n",
       " 'https://news.smol.ai/issues/24-03-15-ainews-mm1-apples-first-large-multimodal-model',\n",
       " 'https://news.smol.ai/issues/24-03-18-ainews-grok-1-in-bio',\n",
       " 'https://news.smol.ai/issues/24-03-19-ainews-worldsimexe',\n",
       " 'https://news.smol.ai/issues/24-03-20-ainews-shipping-and-dipping-inflection-stability-edition',\n",
       " 'https://news.smol.ai/issues/24-03-21-ainews-welcome-rlocalllama',\n",
       " 'https://news.smol.ai/issues/24-03-22-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-03-25-ainews-andrew-likes-agents',\n",
       " 'https://news.smol.ai/issues/24-03-26-ainews-claude-3-is-officially-americas-next-top-model',\n",
       " 'https://news.smol.ai/issues/24-03-27-ainews-dbrx-best-open-model-just-not-most-efficient',\n",
       " 'https://news.smol.ai/issues/24-03-28-ainews-jamba-mixture-of-architectures-dethrones-mixtral',\n",
       " 'https://news.smol.ai/issues/24-03-29-ainews-evals-based-ai-engineering',\n",
       " 'https://news.smol.ai/issues/24-04-01-ainews-adamw-greater-aarond',\n",
       " 'https://news.smol.ai/issues/24-04-02-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-04-03-ainews-realm-reference-resolution-as-language-modeling',\n",
       " 'https://news.smol.ai/issues/24-04-04-ainews-cohere-command-r-anthropic-claude-tool-use-openai-finetuning',\n",
       " 'https://news.smol.ai/issues/24-04-05-ainews-mixture-of-depths-dynamically-allocating-compute-in-transformer-based-language-models',\n",
       " 'https://news.smol.ai/issues/24-04-08-ainews-anime-pfp-anon-eclipses-dollar10k-ab-prompting-challenge',\n",
       " 'https://news.smol.ai/issues/24-04-09-ainews-gemini-pro-and-gpt4t-vision-go-ga-on-the-same-day-by-complete-coincidence',\n",
       " 'https://news.smol.ai/issues/24-04-10-ainews-musics-dall-e-moment',\n",
       " 'https://news.smol.ai/issues/24-04-11-ainews-mergestral-meta-mtiav2-cohere-rerank-3-google-infini-attention',\n",
       " 'https://news.smol.ai/issues/24-04-12-ainews-zero-to-gpt-in-1-year',\n",
       " 'https://news.smol.ai/issues/24-04-15-ainews-multi-modal-multi-aspect-multi-form-factor-ai',\n",
       " 'https://news.smol.ai/issues/24-04-16-ainews-lilian-weng-on-video-diffusion',\n",
       " 'https://news.smol.ai/issues/24-04-17-ainews-mixtral-8x22b-instruct-sparks-efficiency-memes',\n",
       " 'https://news.smol.ai/issues/24-04-18-ainews-meta-llama-3-8b-70b',\n",
       " 'https://news.smol.ai/issues/24-04-19-ainews-llama-3-70b-is-gpt-4-level-open-model',\n",
       " 'https://news.smol.ai/issues/24-04-22-ainews-fineweb-15t-tokens-12-years-of-commoncrawl-deduped-and-filtered-youre-welcome',\n",
       " 'https://news.smol.ai/issues/24-04-23-ainews-perplexity-the-newest-ai-unicorn',\n",
       " 'https://news.smol.ai/issues/24-04-24-ainews-openais-instruction-hierarchy-for-the-llm-os',\n",
       " 'https://news.smol.ai/issues/24-04-25-ainews-snowflake-arctic-fully-open-10b128x4b-dense-moe-hybrid-llm',\n",
       " 'https://news.smol.ai/issues/24-04-26-ainews-apples-openelm-beats-olmo-with-50percent-of-its-dataset-using-delight',\n",
       " 'https://news.smol.ai/issues/24-04-29-ainews-a-quiet-weekend',\n",
       " 'https://news.smol.ai/issues/24-04-30-ainews-llms-as-juries',\n",
       " 'https://news.smol.ai/issues/24-05-01-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-05-02-ainews-evals-the-next-generation',\n",
       " 'https://news.smol.ai/issues/24-05-03-ainews-dollar100k-to-predict-lmsys-human-preferences-in-a-kaggle-contest',\n",
       " 'https://news.smol.ai/issues/24-05-06-ainews-deepseek-v2-beats-mixtral-8x22b-with-greater160-experts-at-half-the-cost',\n",
       " 'https://news.smol.ai/issues/24-05-07-ainews-kolmogorov-arnold-networks-mlp-killers-or-just-spicy-mlps',\n",
       " 'https://news.smol.ai/issues/24-05-08-ainews-openais-pr-campaign',\n",
       " 'https://news.smol.ai/issues/24-05-09-ainews-lmsys-advances-llama-3-eval-analysis',\n",
       " 'https://news.smol.ai/issues/24-05-10-ainews-quis-promptum-ipso-promptiet',\n",
       " 'https://news.smol.ai/issues/24-05-13-ainews-gpt-4o-the-new-sota-everything-frontier-model-gpt4o-version',\n",
       " 'https://news.smol.ai/issues/24-05-13-ainews-gpt-4o-the-new-sota-everything-frontier-model-gpt4t-version',\n",
       " 'https://news.smol.ai/issues/24-05-14-ainews-google-io-in-60-seconds',\n",
       " 'https://news.smol.ai/issues/24-05-15-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-05-16-ainews-cursor-reaches-greater1000-toks-finetuning-llama3-70b-for-fast-file-editing',\n",
       " 'https://news.smol.ai/issues/24-05-17-ainews-chameleon-metas-unreleased-gpt4o-like-omnimodal-model',\n",
       " 'https://news.smol.ai/issues/24-05-20-ainews-skyfall',\n",
       " 'https://news.smol.ai/issues/24-05-21-ainews-anthropics-llm-genome-project-learning-and-clamping-34m-features-on-claude-sonnet',\n",
       " 'https://news.smol.ai/issues/24-05-22-ainews-all-of-ai-engineering-in-one-place',\n",
       " 'https://news.smol.ai/issues/24-05-23-ainews-clementine-fourrier-on-llm-evals',\n",
       " 'https://news.smol.ai/issues/24-05-24-ainews-ten-commandments-for-deploying-fine-tuned-models',\n",
       " 'https://news.smol.ai/issues/24-05-27-ainews-life-after-dpo-rewardbench',\n",
       " 'https://news.smol.ai/issues/24-05-28-ainews-somebody-give-andrej-some-h100s-already',\n",
       " 'https://news.smol.ai/issues/24-05-29-ainews-1-trillion-token-context-real-time-on-device',\n",
       " 'https://news.smol.ai/issues/24-05-30-ainews-contextual-position-encoding-cope',\n",
       " 'https://news.smol.ai/issues/24-05-31-ainews-ways-to-use-anthropics-tool-use-ga',\n",
       " 'https://news.smol.ai/issues/24-06-03-ainews-mamba-2-state-space-duality',\n",
       " 'https://news.smol.ai/issues/24-06-04-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-06-05-ainews-5-small-news-items',\n",
       " 'https://news.smol.ai/issues/24-06-06-ainews-qwen-2-beats-llama-3-and-we-dont-know-how',\n",
       " 'https://news.smol.ai/issues/24-06-07-ainews-hipporag-first-do-knowledge-graph',\n",
       " 'https://news.smol.ai/issues/24-06-10-ainews-talaria-apples-new-mlops-superweapon',\n",
       " 'https://news.smol.ai/issues/24-06-11-ainews-francois-chollet-launches-dollar1m-arc-prize',\n",
       " 'https://news.smol.ai/issues/24-06-12-ainews-the-last-hurrah-of-stable-diffusion',\n",
       " 'https://news.smol.ai/issues/24-06-13-ainews-hybrid-ssmtransformers-greater-pure-ssmspure-transformers',\n",
       " 'https://news.smol.ai/issues/24-06-14-ainews-nemotron-4-340b-nvidias-new-large-open-models-built-on-syndata-great-for-syndata',\n",
       " 'https://news.smol.ai/issues/24-06-17-ainews-is-this-openq',\n",
       " 'https://news.smol.ai/issues/24-06-18-ainews-gemini-launches-context-caching-or-does-it',\n",
       " 'https://news.smol.ai/issues/24-06-19-ainews-theres-ilya',\n",
       " 'https://news.smol.ai/issues/24-06-21-ainews-claude-crushes-code-92percent-humaneval-and-claudeai-artifacts',\n",
       " 'https://news.smol.ai/issues/24-06-21-ainews-shazeer-et-al-2024-you-are-overpaying-for-inference-greater13x',\n",
       " 'https://news.smol.ai/issues/24-06-25-ainews-gemini-nano-50-90percent-of-gemini-pro-less100ms-inference-on-device-in-chrome-canary',\n",
       " 'https://news.smol.ai/issues/24-06-25-ainews-shall-i-compare-thee-to-a-sonnets-day',\n",
       " 'https://news.smol.ai/issues/24-06-26-ainews-mozillas-ai-second-act',\n",
       " 'https://news.smol.ai/issues/24-06-27-ainews-gemma-2-the-open-model-for-everyone',\n",
       " 'https://news.smol.ai/issues/24-06-28-ainews-that-gpt-4o-demo',\n",
       " 'https://news.smol.ai/issues/24-07-01-ainews-routellm-rip-martian-plus-ainews-structured-summaries-update',\n",
       " 'https://news.smol.ai/issues/24-07-02-ainews-graphrag-the-marriage-of-knowledge-graphs-and-rag',\n",
       " 'https://news.smol.ai/issues/24-07-03-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-07-05-ainews-qdrants-bm42-please-dont-trust-us',\n",
       " 'https://news.smol.ai/issues/24-07-08-ainews-problems-with-mmlu-pro',\n",
       " 'https://news.smol.ai/issues/24-07-09-ainews-test-time-training-mobilellm-lilian-weng-on-hallucination-plus-turbopuffer',\n",
       " 'https://news.smol.ai/issues/24-07-10-ainews-nothing-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-07-12-ainews-flashattention-3-paligemma-openais-5-levels-to-superintelligence',\n",
       " 'https://news.smol.ai/issues/24-07-12-ainews-we-solved-hallucinations',\n",
       " 'https://news.smol.ai/issues/24-07-15-ainews-microsoft-agentinstruct-orca-3',\n",
       " 'https://news.smol.ai/issues/24-07-16-ainews-scicode-humaneval-gets-a-stem-phd-upgrade',\n",
       " 'https://news.smol.ai/issues/24-07-17-ainews-gemma-2-tops-rlocalllama-vibe-check',\n",
       " 'https://news.smol.ai/issues/24-07-18-ainews-mini-nemo-turbo-lite-smol-models-go-brrr-gpt4o-mini-version',\n",
       " 'https://news.smol.ai/issues/24-07-18-ainews-mini-nemo-turbo-lite-smol-models-go-brrr-gpt4o-version',\n",
       " 'https://news.smol.ai/issues/24-07-19-ainews-datacomp-lm-the-best-open-data-7b-modelbenchmarkdataset',\n",
       " 'https://news.smol.ai/issues/24-07-22-ainews-llama-31-leaks-big-bumps-to-8b-minor-bumps-to-70b-and-sota-oss-405b-model',\n",
       " 'https://news.smol.ai/issues/24-07-23-ainews-llama-31-the-synthetic-data-model',\n",
       " 'https://news.smol.ai/issues/24-07-24-ainews-mistral-large-2-rip-mistral-7b-8x7b-8x22b',\n",
       " 'https://news.smol.ai/issues/24-07-25-ainews-alphaproof-alphageometry2-reach-1-point-short-of-imo-gold',\n",
       " 'https://news.smol.ai/issues/24-07-29-ainews-apple-intelligence-beta-segment-anything-model-2',\n",
       " 'https://news.smol.ai/issues/24-07-31-ainews-gemma-2-2b-scope-shield',\n",
       " 'https://news.smol.ai/issues/24-07-31-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-08-01-ainews-rombach-et-al-flux1-proordevorschnell-dollar31m-seed-for-black-forest-labs',\n",
       " 'https://news.smol.ai/issues/24-08-02-ainews-execuhires-tempting-the-wrath-of-khan',\n",
       " 'https://news.smol.ai/issues/24-08-05-ainews-how-carlini-uses-ai',\n",
       " 'https://news.smol.ai/issues/24-08-06-ainews-gpt4o-august-100percent-structured-outputs-for-all-gpt4o-august-edition',\n",
       " 'https://news.smol.ai/issues/24-08-06-ainews-gpt4o-august-100percent-structured-outputs-for-all-gpt4o-mini-edition',\n",
       " 'https://news.smol.ai/issues/24-08-07-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-08-08-ainews-too-cheap-to-meter-ai-prices-cut-50-70percent-in-last-30-days',\n",
       " 'https://news.smol.ai/issues/24-08-09-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-08-12-ainews-a-quiet-weekend',\n",
       " 'https://news.smol.ai/issues/24-08-13-ainews-gemini-live',\n",
       " 'https://news.smol.ai/issues/24-08-14-ainews-grok-2-and-chatgpt-4o-latest-confuses-everybody',\n",
       " 'https://news.smol.ai/issues/24-08-15-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-08-16-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-08-19-ainews-the-dspy-roadmap',\n",
       " 'https://news.smol.ai/issues/24-08-20-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-08-21-ainews-ideogram-2-berkeley-function-calling-leaderboard-v2',\n",
       " 'https://news.smol.ai/issues/24-08-22-ainews-super-quiet-day',\n",
       " 'https://news.smol.ai/issues/24-08-23-ainews-nvidia-minitron-llm-pruning-and-distillation-updated-for-llama-31',\n",
       " 'https://news.smol.ai/issues/24-08-26-ainews-not-much-happened-this-weekend',\n",
       " 'https://news.smol.ai/issues/24-08-27-ainews-cogvideox-zhipus-open-source-sora',\n",
       " 'https://news.smol.ai/issues/24-08-28-ainews-cerebras-inference-faster-better-and-cheaper',\n",
       " 'https://news.smol.ai/issues/24-08-29-ainews-summer-of-code-ai-dollar16b-raised-1-usable-product',\n",
       " 'https://news.smol.ai/issues/24-08-30-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-09-03-ainews-everybody-shipped-small-things-this-holiday-weekend',\n",
       " 'https://news.smol.ai/issues/24-09-04-ainews-dollar1150m-for-ssi-sakana-youcom-claude-500m-context',\n",
       " 'https://news.smol.ai/issues/24-09-05-ainews-replit-agent-how-did-everybody-beat-devin-to-market',\n",
       " 'https://news.smol.ai/issues/24-09-06-ainews-reflection-70b-by-matt-from-it-department',\n",
       " 'https://news.smol.ai/issues/24-09-09-ainews-aiphone-16-the-visual-intelligence-phone',\n",
       " 'https://news.smol.ai/issues/24-09-10-ainews-not-much-happened-today-ainews-podcast',\n",
       " 'https://news.smol.ai/issues/24-09-11-ainews-pixtral-12b-mistral-beats-llama-to-multimodality',\n",
       " 'https://news.smol.ai/issues/24-09-12-ainews-o1-openais-new-general-reasoning-models',\n",
       " 'https://news.smol.ai/issues/24-09-13-ainews-learnings-from-o1-ama',\n",
       " 'https://news.smol.ai/issues/24-09-16-ainews-a-quiet-weekend',\n",
       " 'https://news.smol.ai/issues/24-09-17-ainews-nothing-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-09-18-ainews-o1-destroys-lmsys-arena-qwen-25-kyutai-moshi-release',\n",
       " 'https://news.smol.ai/issues/24-09-19-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-09-20-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-09-23-ainews-a-calm-before-the-storm',\n",
       " 'https://news.smol.ai/issues/24-09-24-ainews-chatgpt-advanced-voice-mode',\n",
       " 'https://news.smol.ai/issues/24-09-25-ainews-llama-32-on-device-1b3b-and-multimodal-11b90b-with-ai2-molmo-kicker',\n",
       " 'https://news.smol.ai/issues/24-09-26-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-09-27-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-09-30-ainews-liquid-foundation-models-a-new-transformers-alternative-ainews-pod-2',\n",
       " 'https://news.smol.ai/issues/24-10-01-ainews-openai-realtime-api-and-other-dev-day-goodies',\n",
       " 'https://news.smol.ai/issues/24-10-02-ainews-not-much-technical-happened-today',\n",
       " 'https://news.smol.ai/issues/24-10-03-ainews-canvas-openais-answer-to-claude-artifacts',\n",
       " 'https://news.smol.ai/issues/24-10-04-ainews-contextual-document-embeddings-cde-small-v1',\n",
       " 'https://news.smol.ai/issues/24-10-07-ainews-not-much-happened-this-weekend',\n",
       " 'https://news.smol.ai/issues/24-10-08-ainews-the-ai-nobel-prize',\n",
       " 'https://news.smol.ai/issues/24-10-09-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-10-10-ainews-state-of-ai-2024',\n",
       " 'https://news.smol.ai/issues/24-10-11-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-10-14-ainews-not-much-in-ai-happened-this-weekend',\n",
       " 'https://news.smol.ai/issues/24-10-15-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-10-16-ainews-did-nvidias-nemotron-70b-train-on-test',\n",
       " 'https://news.smol.ai/issues/24-10-17-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-10-18-ainews-deepseek-janus-and-meta-spirit-lm-decoupled-image-and-expressive-voice-omnimodality',\n",
       " 'https://news.smol.ai/issues/24-10-21-ainews-docetl-agentic-query-rewriting-and-evaluation-for-complex-document-processing',\n",
       " 'https://news.smol.ai/issues/24-10-22-ainews-claude-35-sonnet-new-gets-computer-use',\n",
       " 'https://news.smol.ai/issues/24-10-23-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-10-24-ainews-simpleortableorcalable-consistency-models',\n",
       " 'https://news.smol.ai/issues/24-10-25-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-10-28-ainews-not-much-happened-this-weekend',\n",
       " 'https://news.smol.ai/issues/24-10-29-ainews-github-copilot-strikes-back',\n",
       " 'https://news.smol.ai/issues/24-10-30-ainews-creating-a-llm-as-a-judge',\n",
       " 'https://news.smol.ai/issues/24-11-01-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-11-01-ainews-the-ai-search-wars-have-begun-searchgpt-gemini-grounding-and-more',\n",
       " 'https://news.smol.ai/issues/24-11-04-ainews-openai-beats-anthropic-to-releasing-speculative-decoding',\n",
       " 'https://news.smol.ai/issues/24-11-05-ainews-tencents-hunyuan-large-claims-to-beat-deepseek-v2-and-llama3-405b-with-less-data',\n",
       " 'https://news.smol.ai/issues/24-11-06-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-11-07-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-11-08-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-11-11-ainews-frontiermath-a-benchmark-for-evaluating-advanced-mathematical-reasoning-in-ai',\n",
       " 'https://news.smol.ai/issues/24-11-12-ainews-bitnet-was-a-lie',\n",
       " 'https://news.smol.ai/issues/24-11-13-ainews-common-corpus-2t-open-tokens-with-provenance',\n",
       " 'https://news.smol.ai/issues/24-11-14-ainews-gemini-experimental-1114-retakes-1-llm-rank-with-1344-elo',\n",
       " 'https://news.smol.ai/issues/24-11-15-ainews-stripe-lets-agents-spend-money-with-stripeagenttoolkit',\n",
       " 'https://news.smol.ai/issues/24-11-18-ainews-pixtral-large-124b-beats-llama-32-90b-with-updated-mistral-large-2411',\n",
       " 'https://news.smol.ai/issues/24-11-19-ainews-perplexity-starts-shopping-for-you',\n",
       " 'https://news.smol.ai/issues/24-11-20-ainews-deepseek-r1-claims-to-beat-o1-preview-and-will-be-open-sourced',\n",
       " 'https://news.smol.ai/issues/24-11-21-ainews-lmsys-killed-model-versioning-gpt-4o-1120-gemini-exp-1121',\n",
       " 'https://news.smol.ai/issues/24-11-22-ainews-vision-everywhere-apple-aimv2-and-jina-clip-v2',\n",
       " 'https://news.smol.ai/issues/24-11-25-ainews-anthropic-launches-the-model-context-protocol',\n",
       " 'https://news.smol.ai/issues/24-11-26-ainews-olmo-2-new-sota-fully-open-llm',\n",
       " 'https://news.smol.ai/issues/24-11-27-ainews-qwen-with-questions-32b-open-weights-reasoning-model-nears-o1-in-gpqaaimemath500',\n",
       " 'https://news.smol.ai/issues/24-11-29-ainews-not-much-happened-to-end-the-week',\n",
       " 'https://news.smol.ai/issues/24-12-02-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-12-03-ainews-olympus-has-dropped-aka-amazon-nova-microorliteorproorpremierorcanvasorreel',\n",
       " 'https://news.smol.ai/issues/24-12-04-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-12-05-ainews-dollar200-chatgpt-pro-and-o1-fullpro-with-vision-without-api-and-mixed-reviews',\n",
       " 'https://news.smol.ai/issues/24-12-06-ainews-meta-llama-33-405bnova-pro-performance-at-70b-price',\n",
       " 'https://news.smol.ai/issues/24-12-09-ainews-openai-sora-turbo-and-soracom',\n",
       " 'https://news.smol.ai/issues/24-12-10-ainews-chatgpt-canvas-ga',\n",
       " 'https://news.smol.ai/issues/24-12-11-ainews-google-wakes-up-gemini-20-et-al',\n",
       " 'https://news.smol.ai/issues/24-12-13-ainews-meta-blt-tokenizer-free-byte-level-llm',\n",
       " 'https://news.smol.ai/issues/24-12-16-ainews-meta-apollo-video-understanding-up-to-1-hour-sota-open-weights',\n",
       " 'https://news.smol.ai/issues/24-12-17-ainews-o1-api-4o4o-mini-in-realtime-api-webrtc-dpo-finetuning',\n",
       " 'https://news.smol.ai/issues/24-12-18-ainews-genesis-generative-physics-engine-for-robotics-o1-2024-12-17',\n",
       " 'https://news.smol.ai/issues/24-12-18-ainews-genesis-generative-physics-engine-for-robotics-o1-mini-version',\n",
       " 'https://news.smol.ai/issues/24-12-18-ainews-openai-voice-mode-can-see-now-after-gemini-does',\n",
       " 'https://news.smol.ai/issues/24-12-19-ainews-modernbert-small-new-retrieverclassifier-workhorse-8k-context-2t-tokens',\n",
       " 'https://news.smol.ai/issues/24-12-20-ainews-o3-solves-aime-gpqa-codeforces-makes-11-years-of-progress-in-arc-agi-and-25percent-in-frontiermath',\n",
       " 'https://news.smol.ai/issues/24-12-23-ainews-not-much-happened-this-weekend',\n",
       " 'https://news.smol.ai/issues/24-12-24-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-12-26-ainews-deepseek-v3-671b-finegrained-moe-trained-for-dollar55m-usd-of-compute-on-15t-tokens',\n",
       " 'https://news.smol.ai/issues/24-12-27-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-12-30-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/24-12-31-ainews-not-much-happened-to-end-the-year',\n",
       " 'https://news.smol.ai/issues/25-01-03-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-06-ainews-prime-process-reinforcement-through-implicit-rewards',\n",
       " 'https://news.smol.ai/issues/25-01-07-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-08-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-09-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-10-ainews-moondream-202519-structured-text-enhanced-ocr-gaze-detection-in-a-2b-model',\n",
       " 'https://news.smol.ai/issues/25-01-13-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-14-ainews-small-little-news-items',\n",
       " 'https://news.smol.ai/issues/25-01-15-ainews-titans-learning-to-memorize-at-test-time',\n",
       " 'https://news.smol.ai/issues/25-01-16-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-17-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-20-ainews-deepseek-r1-o1-level-open-weights-model-and-a-simple-recipe-for-upgrading-15b-models-to-sonnet4o-level',\n",
       " 'https://news.smol.ai/issues/25-01-21-ainews-project-stargate-dollar500b-datacenter-17percent-of-us-gdp-and-gemini-2-flash-thinking-2',\n",
       " 'https://news.smol.ai/issues/25-01-22-ainews-bespoke-stratos-sky-t1-the-vicunaalpaca-moment-for-reasoning',\n",
       " 'https://news.smol.ai/issues/25-01-23-ainews-openai-launches-operator-its-first-agent',\n",
       " 'https://news.smol.ai/issues/25-01-24-ainews-tinyzero-reproduce-deepseek-r1-zero-for-dollar30',\n",
       " 'https://news.smol.ai/issues/25-01-27-ainews-deepseek-1-on-us-app-store-nvidia-stock-tanks-17percent',\n",
       " 'https://news.smol.ai/issues/25-01-28-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-29-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-01-30-ainews-mistral-small-3-24b-and-tulu-3-405b',\n",
       " 'https://news.smol.ai/issues/25-02-01-ainews-o3-mini-launches-openai-on-wrong-side-of-history',\n",
       " 'https://news.smol.ai/issues/25-02-03-ainews-openai-takes-on-geminis-deep-research',\n",
       " 'https://news.smol.ai/issues/25-02-04-ainews-how-to-scale-your-model-by-deepmind',\n",
       " 'https://news.smol.ai/issues/25-02-05-ainews-gemini-20-flash-ga-with-new-flash-lite-20-pro-and-flash-thinking',\n",
       " 'https://news.smol.ai/issues/25-02-06-ainews-s1-simple-test-time-scaling-and-kyutai-hibiki',\n",
       " 'https://news.smol.ai/issues/25-02-07-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-02-10-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-02-11-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-02-12-ainews-small-news-items',\n",
       " 'https://news.smol.ai/issues/25-02-13-ainews-reasoning-models-are-near-superhuman-coders-openai-ioi-nvidia-kernels',\n",
       " 'https://news.smol.ai/issues/25-02-14-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-02-17-ainews-llada-large-language-diffusion-models',\n",
       " 'https://news.smol.ai/issues/25-02-18-ainews-xai-grok-3-and-mira-muratis-thinking-machines',\n",
       " 'https://news.smol.ai/issues/25-02-19-ainews-the-ultra-scale-playbook-training-llms-on-gpu-clusters',\n",
       " 'https://news.smol.ai/issues/25-02-21-ainews-ai-engineer-summit-day-1',\n",
       " 'https://news.smol.ai/issues/25-02-21-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-02-24-ainews-claude-37-sonnet',\n",
       " 'https://news.smol.ai/issues/25-02-25-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-02-26-ainews-lots-of-small-launches',\n",
       " 'https://news.smol.ai/issues/25-02-27-ainews-gpt-45-chonky-orion-ships',\n",
       " 'https://news.smol.ai/issues/25-02-28-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-03-ainews-anthropics-dollar615b-series-e',\n",
       " 'https://news.smol.ai/issues/25-03-04-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-06-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-07-ainews-deepseeks-open-source-stack',\n",
       " 'https://news.smol.ai/issues/25-03-10-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-11-ainews-the-new-openai-agents-platform',\n",
       " 'https://news.smol.ai/issues/25-03-12-ainews-gemma-3-beats-deepseek-v3-in-elo-20-flash-beats-gpt4o-with-native-image-gen',\n",
       " 'https://news.smol.ai/issues/25-03-13-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-14-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-17-ainews-coheres-command-a-claims-3-open-model-spot-after-deepseek-and-gemma',\n",
       " 'https://news.smol.ai/issues/25-03-18-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-19-ainews-every-7-months-the-moores-law-for-agent-autonomy',\n",
       " 'https://news.smol.ai/issues/25-03-20-ainews-promptable-prosody-sota-asr-and-semantic-vad-openai-revamps-voice-ai',\n",
       " 'https://news.smol.ai/issues/25-03-21-ainews-lots-of-little-things-happened-this-week',\n",
       " 'https://news.smol.ai/issues/25-03-24-ainews-halfmoon-is-reve-image-a-new-sota-image-model-from-ex-adobestability-trio',\n",
       " 'https://news.smol.ai/issues/25-03-25-ainews-gemini-25-pro-4o-native-image-gen',\n",
       " 'https://news.smol.ai/issues/25-03-26-ainews-openai-adopts-mcp',\n",
       " 'https://news.smol.ai/issues/25-03-27-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-28-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-03-31-ainews-greaterdollar41b-raised-today-openai-300b-cursor-95b-etched-15b',\n",
       " 'https://news.smol.ai/issues/25-04-01-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-04-03-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-04-04-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-04-07-ainews-llama-4s-controversial-weekend-release',\n",
       " 'https://news.smol.ai/issues/25-04-09-ainews-deepcoder-a-fully-open-source-14b-coder-at-o3-mini-level',\n",
       " 'https://news.smol.ai/issues/25-04-09-ainews-googles-agent2agent-protocol-a2a',\n",
       " 'https://news.smol.ai/issues/25-04-10-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-04-11-ainews-not-much-happened-today',\n",
       " 'https://news.smol.ai/issues/25-04-14-ainews-gpt-41-the-new-openai-workhorse',\n",
       " 'https://news.smol.ai/issues/25-04-15-ainews-sota-video-gen-veo-2-and-kling-2-are-ga-for-developers',\n",
       " 'https://news.smol.ai/issues/25-04-16-ainews-openai-o3-o4-mini-and-codex-cli',\n",
       " 'https://news.smol.ai/issues/25-04-16-ainews-qwq-32b-claims-to-match-deepseek-r1-671b',\n",
       " 'https://news.smol.ai/issues/25-04-17-ainews-gemini-25-flash-completes-the-total-domination-of-the-pareto-frontier',\n",
       " 'https://news.smol.ai/issues/25-04-18-ainews-grok-3-and-3-mini-now-api-available',\n",
       " 'https://news.smol.ai/issues/25-04-21-not-much-resend',\n",
       " 'https://news.smol.ai/issues/25-04-22-not-much',\n",
       " 'https://news.smol.ai/issues/25-04-23-gpt-image-1',\n",
       " 'https://news.smol.ai/issues/25-04-24-not-much',\n",
       " 'https://news.smol.ai/issues/25-04-25-cognition-deepwiki',\n",
       " 'https://news.smol.ai/issues/25-04-28-qwen-3',\n",
       " 'https://news.smol.ai/issues/25-04-29-llamacon',\n",
       " 'https://news.smol.ai/issues/25-04-30-glazegate',\n",
       " 'https://news.smol.ai/issues/25-05-01-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-02-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-05-cursor-openai-windsurf',\n",
       " 'https://news.smol.ai/issues/25-05-06-gemini-2-5-pro',\n",
       " 'https://news.smol.ai/issues/25-05-07-aiewf-2025',\n",
       " 'https://news.smol.ai/issues/25-05-08-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-09-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-12-intellect-2',\n",
       " 'https://news.smol.ai/issues/25-05-13-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-14-notion-granola',\n",
       " 'https://news.smol.ai/issues/25-05-15-alphaevolve',\n",
       " 'https://news.smol.ai/issues/25-05-16-codex',\n",
       " 'https://news.smol.ai/issues/25-05-19-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-20-google-io',\n",
       " 'https://news.smol.ai/issues/25-05-21-openai-io',\n",
       " 'https://news.smol.ai/issues/25-05-22-claude-4',\n",
       " 'https://news.smol.ai/issues/25-05-23-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-26-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-27-mistral-agents',\n",
       " 'https://news.smol.ai/issues/25-05-28-not-much',\n",
       " 'https://news.smol.ai/issues/25-05-29-deepseek-r1-0528',\n",
       " 'https://news.smol.ai/issues/25-05-30-mary-meeker',\n",
       " 'https://news.smol.ai/issues/25-06-02-not-much',\n",
       " 'https://news.smol.ai/issues/25-06-03-not-much',\n",
       " 'https://news.smol.ai/issues/25-06-04-not-much',\n",
       " 'https://news.smol.ai/issues/25-06-05-aia',\n",
       " 'https://news.smol.ai/issues/25-06-06-not-much',\n",
       " 'https://news.smol.ai/issues/25-06-09-apple-letdown',\n",
       " 'https://news.smol.ai/issues/25-06-10-o3-cut',\n",
       " 'https://news.smol.ai/issues/25-06-11-execuhires-2',\n",
       " 'https://news.smol.ai/issues/25-06-12-not-much',\n",
       " 'https://news.smol.ai/issues/25-06-13-cognition-vs-anthropic',\n",
       " 'https://news.smol.ai/issues/25-06-16-chinese-models',\n",
       " 'https://news.smol.ai/issues/25-06-17-gemini-2-5',\n",
       " 'https://news.smol.ai/issues/25-06-18-zuck-founder-mode',\n",
       " 'https://news.smol.ai/issues/25-06-19-followups',\n",
       " 'https://news.smol.ai/issues/25-06-20-claude-code',\n",
       " 'https://news.smol.ai/issues/25-06-23-not-much',\n",
       " 'https://news.smol.ai/issues/25-06-24-fair-use',\n",
       " 'https://news.smol.ai/issues/25-06-25-context-eng',\n",
       " 'https://news.smol.ai/issues/25-06-26-deepresearch-api',\n",
       " 'https://news.smol.ai/issues/25-06-27-not-much',\n",
       " 'https://news.smol.ai/issues/25-06-30-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-01-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-02-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-03-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-07-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-08-smollm3',\n",
       " 'https://news.smol.ai/issues/25-07-09-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-10-grok-4',\n",
       " 'https://news.smol.ai/issues/25-07-11-kimi-k2',\n",
       " 'https://news.smol.ai/issues/25-07-14-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-15-voxtral',\n",
       " 'https://news.smol.ai/issues/25-07-16-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-17-chatgpt-agent',\n",
       " 'https://news.smol.ai/issues/25-07-21-imo-gold',\n",
       " 'https://news.smol.ai/issues/25-07-22-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-23-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-24-cogsurf-cursor',\n",
       " 'https://news.smol.ai/issues/25-07-25-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-28-glm-45',\n",
       " 'https://news.smol.ai/issues/25-07-29-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-30-not-much',\n",
       " 'https://news.smol.ai/issues/25-07-31-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-01-deep-think',\n",
       " 'https://news.smol.ai/issues/25-08-04-qwen-image',\n",
       " 'https://news.smol.ai/issues/25-08-05-gpt-oss',\n",
       " 'https://news.smol.ai/issues/25-08-06-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-07-gpt-5',\n",
       " 'https://news.smol.ai/issues/25-08-08-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-11-ioi-gold',\n",
       " 'https://news.smol.ai/issues/25-08-12-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-13-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-14-cohere-ai2',\n",
       " 'https://news.smol.ai/issues/25-08-15-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-18-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-19-databricks',\n",
       " 'https://news.smol.ai/issues/25-08-20-deepseekv31',\n",
       " 'https://news.smol.ai/issues/25-08-21-cohere-command-a-reasoning',\n",
       " 'https://news.smol.ai/issues/25-08-22-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-25-not-much',\n",
       " 'https://news.smol.ai/issues/25-08-26-nano-banana',\n",
       " 'https://news.smol.ai/issues/25-08-27-codex-2',\n",
       " 'https://news.smol.ai/issues/25-08-28-gpt-realtime',\n",
       " 'https://news.smol.ai/issues/25-08-29-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-01-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-02-anthropic-f',\n",
       " 'https://news.smol.ai/issues/25-09-03-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-04-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-05-1t-models',\n",
       " 'https://news.smol.ai/issues/25-09-08-cog-smol',\n",
       " 'https://news.smol.ai/issues/25-09-09-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-10-oci',\n",
       " 'https://news.smol.ai/issues/25-09-11-qwen3-next',\n",
       " 'https://news.smol.ai/issues/25-09-12-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-15-gpt5-codex',\n",
       " 'https://news.smol.ai/issues/25-09-16-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-17-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-18-nvidia-intc',\n",
       " 'https://news.smol.ai/issues/25-09-19-grok-4-fast',\n",
       " 'https://news.smol.ai/issues/25-09-22-nvda-oai',\n",
       " 'https://news.smol.ai/issues/25-09-23-alibaba-yunqi',\n",
       " 'https://news.smol.ai/issues/25-09-24-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-25-gdpval',\n",
       " 'https://news.smol.ai/issues/25-09-26-not-much',\n",
       " 'https://news.smol.ai/issues/25-09-29-sonnet-45',\n",
       " 'https://news.smol.ai/issues/25-09-30-sora2',\n",
       " 'https://news.smol.ai/issues/25-10-01-thinky',\n",
       " 'https://news.smol.ai/issues/25-10-02-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-03-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-06-devday',\n",
       " 'https://news.smol.ai/issues/25-10-07-gemini-cua',\n",
       " 'https://news.smol.ai/issues/25-10-08-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-09-state-of-ai',\n",
       " 'https://news.smol.ai/issues/25-10-10-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-13-oai-broadcom',\n",
       " 'https://news.smol.ai/issues/25-10-14-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-15-haiku-45',\n",
       " 'https://news.smol.ai/issues/25-10-16-claude-skills',\n",
       " 'https://news.smol.ai/issues/25-10-17-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-20-deepseek-ocr',\n",
       " 'https://news.smol.ai/issues/25-10-21-chatgpt-atlas',\n",
       " 'https://news.smol.ai/issues/25-10-22-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-23-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-24-not-much',\n",
       " 'https://news.smol.ai/issues/25-10-27-minimax-m2',\n",
       " 'https://news.smol.ai/issues/25-10-28-openai-restructure',\n",
       " 'https://news.smol.ai/issues/?pattern=gemini']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc699a-e8c8-4b7e-aea9-8069a7b9392e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# old \n",
    "\n",
    "def fetch_html(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; WebScraper/1.0; +http://effcon.com/)\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "def parse_section(html, start_id, end_id):\n",
    "    \"\"\"\n",
    "    Parses the HTML and extracts all visible text between two <h1> sections identified by their IDs.\n",
    "    \n",
    "    Args:\n",
    "        html (str): The HTML content to parse.\n",
    "        start_id (str): The ID of the starting <h1> tag.\n",
    "        end_id (str): The ID of the ending <h1> tag.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted content.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # Locate the starting <h1> tag\n",
    "    start_tag = soup.find('h1', id=start_id)\n",
    "    if not start_tag:\n",
    "        print(f\"Start tag with id '{start_id}' not found.\")\n",
    "        return {}\n",
    "    \n",
    "    # Locate the ending <h1> tag\n",
    "    end_tag = soup.find('h1', id=end_id)\n",
    "    if not end_tag:\n",
    "        print(f\"End tag with id '{end_id}' not found.\")\n",
    "        return {}\n",
    "    \n",
    "    # Initialize variables to store content\n",
    "    extracted_text = []\n",
    "    \n",
    "    # Iterate over the next siblings after the start_tag until the end_tag\n",
    "    for sibling in start_tag.find_next_siblings():\n",
    "        if sibling == end_tag:\n",
    "            break\n",
    "        # If the sibling is a tag and visible, extract its text\n",
    "        if sibling.name:\n",
    "            # Optionally, skip certain tags (e.g., script, style)\n",
    "            if sibling.name in ['script', 'style']:\n",
    "                continue\n",
    "            text = sibling.get_text(separator=\"\\n\", strip=True)\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "        # If the sibling is a NavigableString (text outside tags)\n",
    "        elif hasattr(sibling, 'strip'):\n",
    "            text = sibling.strip()\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "    \n",
    "    # Join all extracted texts into a single string\n",
    "    section_content = \"\\n\".join(extracted_text)\n",
    "    \n",
    "    return {f\"Content from <h1 id='{start_id}'> to <h1 id='{end_id}'>\": section_content}\n",
    "\n",
    "def main():\n",
    "    # URL of the web page to scrape\n",
    "    url = 'https://buttondown.com/ainews/archive/ainews-41b-raised-today-openai-300b-cursor-95b/'\n",
    "    \n",
    "    # IDs of the starting and ending <h1> tags\n",
    "    start_id = 'ai-twitter-recap'\n",
    "    end_id = 'part-1-high-level-discord-summaries'\n",
    "    \n",
    "    try:\n",
    "        # Fetch the HTML content from the URL\n",
    "        html_content = fetch_html(url)\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "        return\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "        return\n",
    "    \n",
    "    # Parse the desired section\n",
    "    extracted_data = parse_section(html_content, start_id, end_id)\n",
    "    \n",
    "    if extracted_data:\n",
    "        # Save the extracted information to a JSON file\n",
    "        with open('extracted_content.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(extracted_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        # Also, print the extracted content\n",
    "        for key, value in extracted_data.items():\n",
    "            print(f\"{key}:\\n{'='*len(key)}\\n{value}\\n\")\n",
    "        \n",
    "        print(\"Content extracted and saved to 'extracted_content.json'.\")\n",
    "    else:\n",
    "        print(\"No content extracted.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc756f1a-0aa4-4b3f-a063-aa99ce560f27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:\n",
      "June 22, 2024\n",
      "--------------------------------------------------\n",
      "Post Title:\n",
      "[AINews] Shazeer et al (2024): you are overpaying for inference >13x\n",
      "--------------------------------------------------\n",
      "News Period:\n",
      "6/20/2024-6/21/2024\n",
      "--------------------------------------------------\n",
      "Content:\n",
      "all recaps done by Claude 3 Opus, best of 4 runs. We are working on clustering and flow engineering with Haiku.\n",
      "Claude 3.5 Sonnet Release by Anthropic\n",
      "Improved Performance\n",
      ":\n",
      "@AnthropicAI\n",
      "released Claude 3.5 Sonnet, outperforming competitor models on key evaluations at twice the speed of Claude 3 Opus and one-fifth the cost. It shows marked improvement in grasping nuance, humor, and complex instructions.\n",
      "@alexalbert__\n",
      "noted it passed\n",
      "64% of internal pull request test cases\n",
      ", compared to 38% for Claude 3 Opus.\n",
      "New Features\n",
      ":\n",
      "@AnthropicAI\n",
      "introduced Artifacts, allowing generation of docs, code, diagrams, graphics, and games that appear next to the chat for real-time iteration.\n",
      "@omarsar0\n",
      "used it to visualize deep learning concepts.\n",
      "Coding Capabilities\n",
      ": In\n",
      "@alexalbert__\n",
      "'s demo, Claude 3.5 Sonnet autonomously fixed a pull request.\n",
      "@virattt\n",
      "highlighted the agentic coding evals, where it reads code, gets instructions, creates an action plan, implements changes, and is evaluated on tests.\n",
      "LLM Architecture and Scaling Discussions\n",
      "Transformer Dominance\n",
      ":\n",
      "@KevinAFischer\n",
      "argued transformers will continue to scale and dominate, drawing parallels to silicon processors. He advised against working on alternative architectures in academia.\n",
      "Scaling and Overfitting\n",
      ":\n",
      "@SebastienBubeck\n",
      "discussed challenges in scaling to AGI, noting models may overfit capabilities at larger scales rather than discovering desired \"operations\". Smooth scaling trajectories are not guaranteed.\n",
      "Importance of Architecture\n",
      ":\n",
      "@\n",
      "aidan_clark\n",
      "emphasized the importance of architecture work to enable current progress, countering views that only scaling matters.\n",
      "@karpathy\n",
      "shared a 94-line autograd engine as the core of neural network training.\n",
      "Retrieval, RAG, and Context Length\n",
      "Long-Context LLMs vs Retrieval\n",
      ": Google DeepMind's\n",
      "@kelvin_guu\n",
      "shared a paper analyzing long-context LLMs on retrieval and reasoning tasks. They rival retrieval and RAG systems without explicit training, but still struggle with compositional reasoning.\n",
      "Infini-Transformer for Unbounded Context\n",
      ":\n",
      "@rohanpaul_ai\n",
      "highlighted the Infini-Transformer, which enables unbounded context with bounded memory using a recurrent-based token mixer and GLU-based channel mixer.\n",
      "Improving RAG Systems\n",
      ":\n",
      "@jxnlco\n",
      "discussed strategies to improve RAG systems, focusing on data coverage and metadata/indexing capabilities to enhance search relevance and user satisfaction.\n",
      "Benchmarks, Evals, and Safety\n",
      "Benchmark Saturation Concerns\n",
      ": Some expressed concerns about benchmarks becoming saturated or less useful, such as\n",
      "@polynoamial\n",
      "on GSM8K and\n",
      "@\n",
      "arohan\n",
      "on HumanEval for coding.\n",
      "Rigorous Pre-Release Testing\n",
      ":\n",
      "@andy_l_jones\n",
      "highlighted @AISafetyInst's testing of Claude 3.5 pre-release as a first for a government assessing a frontier model before release.\n",
      "Evals Enabling Fine-Tuning\n",
      ":\n",
      "@HamelHusain\n",
      "shared a slide from @emilsedgh on how evals set up for fine-tuning, creating a flywheel effect.\n",
      "Multimodal Models and Vision\n",
      "Differing Multimodal Priorities\n",
      ":\n",
      "@_philschmid\n",
      "compared recent releases, noting OpenAI and DeepMind prioritized multimodality while Anthropic focused on improving text capabilities in Claude 3.5.\n",
      "4M-21 Any-to-Any Model\n",
      ":\n",
      "@mervenoyann\n",
      "unpacked EPFL and Apple's 4M-21 model, a single any-to-any model for text-to-image, depth masks, and more.\n",
      "PixelProse Dataset for Instructions\n",
      ":\n",
      "@tomgoldsteincs\n",
      "introduced PixelProse, a 16M image dataset with dense captions for refactoring into instructions and QA pairs using LLMs.\n",
      "Miscellaneous\n",
      "DeepSeek-Coder-V2 Browser Coding\n",
      ":\n",
      "@deepseek_ai\n",
      "showcased DeepSeek-Coder-V2's ability to develop mini-games and websites directly in the browser.\n",
      "Challenges Productionizing LLMs\n",
      ":\n",
      "@svpino\n",
      "noted companies pausing LLM efforts due to challenges in scaling past demos. However,\n",
      "@alexalbert__\n",
      "shared that Anthropic engineers now use Claude to save hours on coding tasks.\n",
      "Mixture of Agents Beats GPT-4\n",
      ":\n",
      "@corbtt\n",
      "introduced a Mixture of Agents (MoA) model that beats GPT-4 while being 25x cheaper. It generates initial completions, reflects, and produces a final output.\n",
      "AI Reddit Recap\n",
      "Across r/LocalLlama, r/machinelearning, r/openai, r/stablediffusion, r/ArtificialInteligence, /r/LLMDevs, /r/Singularity. Comment crawling works now but has lots to improve!\n",
      "Claude 3.5 Sonnet Release\n",
      "Impressive performance\n",
      ": In /r/singularity, Claude 3.5 Sonnet was released by Anthropic and\n",
      "outperforms GPT-4o and other models on benchmarks like LiveBench and GPQA\n",
      ". It also\n",
      "solved 64% of agentic coding problems compared to 38% for Claude 3 Opus\n",
      "in an internal evaluation.\n",
      "Vision reasoning abilities\n",
      ": Claude 3.5 Sonnet\n",
      "outperforms GPT-4o on visual tasks\n",
      ", showcasing impressive vision reasoning abilities.\n",
      "UI enhancements\n",
      ": In addition to performance improvements, Claude 3.5 Sonnet\n",
      "comes with UI enhancements\n",
      "as noted in /r/LocalLLaMA.\n",
      "Promising writing partner\n",
      ": Early tests shared in\n",
      "a YouTube video\n",
      "suggest Claude 3.5 Sonnet shows promise as a writing partner.\n",
      "OpenAI and Competition\n",
      "Desire for competition\n",
      ": In /r/OpenAI, some express\n",
      "a desire for OpenAI to have a model competitive with Claude 3.5 Sonnet\n",
      "to maintain competition and progress in the field.\n",
      "Criticism and distrust\n",
      ": OpenAI is\n",
      "facing criticism and distrust over issues like dismissing safety concerns, breaking compute commitments, and the delayed voice model\n",
      ".\n",
      "Other AI Model Releases and Benchmarks\n",
      "Models from China\n",
      ":\n",
      "Over half of recent large language models are coming from China\n",
      ", as noted in /r/singularity.\n",
      "Aider benchmark\n",
      ": DeepSeek Coder V2 and Sonnet 3.5\n",
      "top the Aider benchmark leaderboard\n",
      ", according to a post in /r/LocalLLaMA.\n",
      "Florence-2 vision model\n",
      ": Microsoft released Florence-2,\n",
      "a versatile open-source vision model that can handle multiple tasks in a unified way\n",
      ", as shared in /r/OpenAI.\n",
      "Stable Diffusion and Image Generation\n",
      "Stable Diffusion 3 for cars\n",
      ": In /r/StableDiffusion, the Stable Diffusion 3 medium model is considered\n",
      "good at following prompts for generating cars and other subjects\n",
      ", though anatomy and consistency need work.\n",
      "Consistent scenes with SD XL\n",
      ":\n",
      "A Reddit video post\n",
      "demonstrates how combining Stable Diffusion XL with img2img and other techniques enables generating consistent scenes and characters.\n",
      "Memes and Humor\n",
      "ChatGPT users leaving for Claude\n",
      ":\n",
      "A meme in /r/singularity\n",
      "jokes about ChatGPT users leaving for Claude after seeing the 3.5 Sonnet update.\n",
      "AI Discord Recap\n",
      "SPECIAL NOTE\n",
      ": As we do for fresh frontier model launches, we are displaying the differences in output from running the same prompts across Claude 3.5 and 3 and GPT4o.\n",
      "Claude 3 Sonnet\n",
      "1. LLM Advancements and Benchmarking\n",
      "Meta's\n",
      "Llama 3\n",
      "has topped leaderboards like ChatbotArena, outperforming GPT-4-Turbo and Claude 3 Opus as mentioned in\n",
      "this Discord discussion\n",
      ".\n",
      "IBM's\n",
      "Granite-8B-Code-Instruct\n",
      "and DeepSeek's\n",
      "DeepSeek-V2\n",
      "(236B params) were highlighted in\n",
      "this channel\n",
      "for code abilities.\n",
      "Skepticism was expressed in\n",
      "this research channel\n",
      "about certain benchmarks, calling for credible sources to set realistic standards.\n",
      "2. Optimizing LLM Inference and Training\n",
      "ZeRO++\n",
      "promising 4x faster GPU training was discussed in\n",
      "this channel\n",
      ".\n",
      "The\n",
      "vAttention\n",
      "paper on efficient KV-caching was mentioned\n",
      "here\n",
      ".\n",
      "QServe\n",
      "using W4A8KV4 quantization for GPU serving was brought up\n",
      "in this discussion\n",
      ".\n",
      "Techniques like\n",
      "Consistency LLMs\n",
      "exploring parallel decoding were mentioned\n",
      "in this channel\n",
      ".\n",
      "3. Open-Source AI Frameworks and Community Efforts\n",
      "Axolotl\n",
      "supporting diverse datasets was highlighted\n",
      "here\n",
      ".\n",
      "Andrew Ng's course on\n",
      "LlamaIndex\n",
      "for building agentic RAG systems was mentioned\n",
      "in this channel\n",
      ".\n",
      "The open-source\n",
      "RefuelLLM-2\n",
      "was introduced\n",
      "in this discussion\n",
      "as a top model for \"unsexy\" tasks.\n",
      "Modular's Mojo\n",
      "and its potential for AI extensions were teased\n",
      "here\n",
      ".\n",
      "4. Multimodal AI and Generative Modeling\n",
      "Idefics2 8B Chatty\n",
      "for chat and\n",
      "CodeGemma 1.1 7B\n",
      "for coding were discussed in\n",
      "this channel\n",
      ".\n",
      "The\n",
      "Phi 3\n",
      "WebGPU chatbot was mentioned\n",
      "here\n",
      ".\n",
      "Combining Pixart Sigma, SDXL and PAG to achieve DALLE-3 outputs was proposed\n",
      "in this generative AI discussion\n",
      ".\n",
      "The\n",
      "IC-Light\n",
      "open-source project on image relighting was shared\n",
      "in this channel\n",
      ".\n",
      "Claude 3.5 Sonnet\n",
      "1. AI Model Releases and Performance Comparisons\n",
      "New Models Claim Benchmark Victories\n",
      ": Nous Research's\n",
      "Hermes 2 Theta 70B\n",
      "and\n",
      "Turbcat 8b\n",
      "both claim to outperform larger models like Llama-3 Instruct on various benchmarks. Users across Discord channels discussed these releases, comparing their capabilities to established models like GPT-4 and Claude.\n",
      "Claude 3.5 Sonnet Generates Mixed Reactions\n",
      ": Discussions in multiple Discords highlighted Claude 3.5 Sonnet's improved Python coding abilities, but some users found it lacking in JavaScript tasks compared to GPT-4. The model's ability to handle obscure programming languages was noted in the Nous Research Discord.\n",
      "Code-Focused Models Gain Traction\n",
      ": The release of\n",
      "DeepSeek Coder v2\n",
      "sparked conversations about specialized models for coding tasks, with claims of performance comparable to GPT4-Turbo in this domain.\n",
      "2. AI Development Tools and Infrastructure Challenges\n",
      "LangChain Alternatives Sought\n",
      ": A\n",
      "blog post\n",
      "detailing Octomind's move away from LangChain resonated across multiple Discords, with developers discussing alternatives like Langgraph for AI agent development.\n",
      "Hardware Limitations Frustrate Developers\n",
      ": Discussions in the LM Studio and CUDA MODE Discords highlighted ongoing challenges with running advanced LLMs on consumer hardware. Users debated the merits of various GPUs, including NVIDIA's 4090 vs. the upcoming 5090, and explored workarounds for memory constraints.\n",
      "Groq's Whisper Performance Claims\n",
      ": Groq's announcement of running the\n",
      "Whisper model at 166x real-time speeds\n",
      "generated interest and skepticism across channels, with developers discussing potential applications and limitations.\n",
      "3. Ethical Concerns in AI Industry Practices\n",
      "OpenAI's Government Collaboration Raises Questions\n",
      ": A\n",
      "tweet\n",
      "discussing OpenAI's early access provision to government entities sparked debates across multiple Discords about AI regulation and AGI safety strategies.\n",
      "Perplexity AI Faces Criticism\n",
      ": A\n",
      "CNBC interview\n",
      "criticizing Perplexity AI's practices led to discussions in various channels about ethical considerations in AI development and deployment.\n",
      "OpenAI's Public Relations Challenges\n",
      ": Members in multiple Discords, including Interconnects, discussed repeated PR missteps by OpenAI representatives, speculating on their implications for the company's public image and internal strategies.\n",
      "Claude 3 Opus\n",
      "1. Model Performance Optimization and Benchmarking\n",
      "[Quantization]\n",
      "techniques like\n",
      "AQLM\n",
      "and\n",
      "QuaRot\n",
      "aim to run large language models (\n",
      "LLMs\n",
      ") on individual GPUs while maintaining performance. Example:\n",
      "AQLM project\n",
      "with\n",
      "Llama-3-70b\n",
      "running on RTX3090.\n",
      "Efforts to\n",
      "boost transformer efficiency\n",
      "through methods like\n",
      "Dynamic Memory Compression (DMC)\n",
      ", potentially improving throughput by up to 370% on\n",
      "H100 GPUs\n",
      ". Example:\n",
      "DMC paper\n",
      "by @p_nawrot.\n",
      "Discussions on\n",
      "optimizing CUDA operations\n",
      "like fusing element-wise operations, using\n",
      "Thrust library's\n",
      "transform\n",
      "for near-bandwidth-saturating performance. Example:\n",
      "Thrust documentation\n",
      ".\n",
      "Comparisons of\n",
      "model performance\n",
      "across benchmarks like\n",
      "AlignBench\n",
      "and\n",
      "MT-Bench\n",
      ", with\n",
      "DeepSeek-V2\n",
      "surpassing GPT-4 in some areas. Example:\n",
      "DeepSeek-V2 announcement\n",
      ".\n",
      "2. Fine-tuning Challenges and Prompt Engineering Strategies\n",
      "Difficulties in\n",
      "retaining fine-tuned data\n",
      "when converting\n",
      "Llama3\n",
      "models to GGUF format, with a\n",
      "confirmed bug\n",
      "discussed.\n",
      "Importance of\n",
      "prompt design\n",
      "and usage of correct templates, including end-of-text tokens, for influencing model performance during fine-tuning and evaluation. Example:\n",
      "Axolotl prompters.py\n",
      ".\n",
      "Strategies for\n",
      "prompt engineering\n",
      "like splitting complex tasks into multiple prompts, investigating\n",
      "logit bias\n",
      "for more control. Example:\n",
      "OpenAI logit bias guide\n",
      ".\n",
      "Teaching LLMs to use\n",
      "<RET>\n",
      "token for\n",
      "information retrieval\n",
      "when uncertain, improving performance on infrequent queries. Example:\n",
      "ArXiv paper\n",
      ".\n",
      "3. Open-Source AI Developments and Collaborations\n",
      "Launch of\n",
      "StoryDiffusion\n",
      ", an open-source alternative to Sora with MIT license, though weights not released yet. Example:\n",
      "GitHub repo\n",
      ".\n",
      "Release of\n",
      "OpenDevin\n",
      ", an open-source autonomous AI engineer based on Devin by Cognition, with\n",
      "webinar\n",
      "and growing interest on GitHub.\n",
      "Calls for collaboration on open-source\n",
      "machine learning paper\n",
      "predicting IPO success, hosted at\n",
      "RicercaMente\n",
      ".\n",
      "Community efforts around\n",
      "LlamaIndex\n",
      "integration, with issues faced in Supabase Vectorstore and package imports after updates. Example:\n",
      "llama-hub documentation\n",
      ".\n",
      "GPT4O (gpt-4o-2024-05-13)\n",
      "AI Model Performance and Training Techniques\n",
      ":\n",
      "Gemini 1.5 excels with 1M tokens\n",
      ":\n",
      "Gemini 1.5 Pro\n",
      "impressed users by handling\n",
      "up to 1M tokens\n",
      "effectively, outperforming other models like\n",
      "Claude 3.5\n",
      "and gaining positive feedback for long-context tasks. This model's ability to process extensive documents and transcripts was highlighted.\n",
      "FP8 Flash Attention and GPTFast speed up inference\n",
      ": Discussions around\n",
      "INT8/FP8 kernels\n",
      "in flash attention and the recently introduced\n",
      "GPTFast\n",
      "indicated significant boosts in HF model inference speeds by up to 9x. Notable mentions included an open-source FP8 flash attention addition, set to receive official CUDA support in 12.5.\n",
      "Null-shot prompting and DPO over RLHF\n",
      ": Community debates touched on the\n",
      "efficacy of null-shot prompting\n",
      "to exploit hallucinations in LLMs and the shift from\n",
      "Reinforcement Learning with Human Feedback (RLHF) to Direct Policy Optimization (DPO)\n",
      "for simplified training. Paper references included the concept's advantages in the LLMs' task performance.\n",
      "AI Ethics and Accessibility\n",
      ":\n",
      "AI Ethics spark debate\n",
      ": A\n",
      "Nature article\n",
      "criticizing OpenAI's departure from open-source principles stirred discussions on AI transparency and accessibility. Concerns were raised over the increasing difficulty of accessing cutting-edge AI tools and code.\n",
      "Avoiding insincere AI apologies\n",
      ": Users voiced frustration with AI-generated apologies, calling them insincere and unnecessary. This sentiment reflected broader expectations for more authentic and practical AI interactions rather than automated expressions of regret.\n",
      "OpenAI and government collaboration concerns\n",
      ": Concerns mounted over OpenAI's early model access for government entities, highlighted in a\n",
      "tweet\n",
      ". The conversation pointed to potential regulatory implications and strategic shifts towards AGI safety.\n",
      "Open-Source AI Developments and Community Contributions\n",
      ":\n",
      "Introducing\n",
      "Turbcat 8b\n",
      ": Announcements of the\n",
      "Turbcat 8b model\n",
      "included notable improvements like expanded datasets and added Chinese support. The model now boasts 5GB in data, with comparisons drawn against larger yet underdeveloped models.\n",
      "Axolotl and Backgammon AI Tool\n",
      ": Collaboration efforts highlighted the open-sourced\n",
      "Backgammon AI tool\n",
      ", which simulates scenarios in backgammon for strategic enhancements. Discussions also included the Turbcat model and its functionalities for multilingual processing.\n",
      "Dataset for computer vision from Stability.ai\n",
      ": Stability.ai released a dataset featuring\n",
      "235,000 prompts and images\n",
      "from the Stable Diffusion community. This\n",
      "StableSemantics\n",
      "dataset aims to augment computer vision systems by providing extensive visual semantics data.\n",
      "Hardware and Deployment Challenges\n",
      ":\n",
      "GPU usage challenges and optimizations\n",
      ": Engineers shared insights and solutions for optimizing GPU and CPU integrations in different setups, such as enabling the second GPU for\n",
      "LM Studio\n",
      "and discussing alternatives for running sophisticated models. Used\n",
      "3090s\n",
      "were recommended for cost efficiency, anticipating performance comparisons between\n",
      "NVIDIA 4090 and 5090\n",
      ".\n",
      "TinyGrad's tangles with\n",
      "clip_grad_norm_\n",
      ": Implementing\n",
      "clip_grad_norm_\n",
      "in\n",
      "TinyGrad\n",
      "faced bottlenecks due to\n",
      "Metal's buffer size limitations\n",
      ", suggesting division into 31-tensor chunks as a workaround. The comparison between\n",
      "Metal and CUDA\n",
      "highlighted performance differences, specifically for gradient clipping operations.\n",
      "Model deployment issues\n",
      ": Deployment challenges with models like\n",
      "Unsloth\n",
      "on platforms like Hugging Face created discussions around tokenizer compatibility and alternative deployment suggestions. Fine-tuning costs also varied dramatically between\n",
      "Together.ai\n",
      "and\n",
      "Unsloth's H100\n",
      ", raising questions about pricing errors.\n",
      "Event Discussions and Professional Opportunities\n",
      ":\n",
      "Techstars and RecSys Virtual Meetups\n",
      ": Upcoming events like the\n",
      "Techstars Startup Weekend in SF\n",
      "from June 28-30 and the\n",
      "RecSys Learners Virtual Meetup\n",
      "on June 29 were highlighted as opportunities for AI professionals to network, learn, and present innovative ideas. Details and RSVP links were shared for participants' convenience.\n",
      "Job hunting and skill showcasing\n",
      ": Python AI Engineers actively sought job opportunities, emphasizing their skills in NLP and LLMs. Conversations also included insights into companies' support frameworks, like the\n",
      "Modal team\n",
      "'s assistance with large models and developer preferences for Slack over Discord.\n",
      "Talks and announcements at AI events\n",
      ": LlamaIndex's founder Jerry Liu's talks at the World's Fair on the future of knowledge assistants were promoted, with mentions of forthcoming special announcements\n",
      "on Twitter\n",
      ".\n",
      "These discussions provide a comprehensive glance at the innovative, ethical, and practical aspects actively shaping the AI community.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# old - Vers 2\n",
    "\n",
    "def fetch_html(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; WebScraper/1.0; +http://effcon.com/)\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "def parse_section(html, start_id, end_id):\n",
    "    \"\"\"\n",
    "    Parses the HTML and extracts all visible text between two <h1> sections identified by their IDs.\n",
    "    \n",
    "    Args:\n",
    "        html (str): The HTML content to parse.\n",
    "        start_id (str): The ID of the starting <h1> tag.\n",
    "        end_id (str): The ID of the ending <h1> tag.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted content.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # Locate the starting <h1> tag\n",
    "    start_tag = soup.find('h1', id=start_id)\n",
    "    if not start_tag:\n",
    "        print(f\"Start tag with id '{start_id}' not found.\")\n",
    "        return {}\n",
    "    \n",
    "    # Locate the ending <h1> tag\n",
    "    end_tag = soup.find('h1', id=end_id)\n",
    "    if not end_tag:\n",
    "        print(f\"End tag with id '{end_id}' not found.\")\n",
    "        return {}\n",
    "    \n",
    "    # Initialize variables to store content\n",
    "    extracted_text = []\n",
    "    \n",
    "    # Iterate over the next siblings after the start_tag until the end_tag\n",
    "    for sibling in start_tag.find_next_siblings():\n",
    "        if sibling == end_tag:\n",
    "            break\n",
    "        # If the sibling is a tag and visible, extract its text\n",
    "        if sibling.name:\n",
    "            # Optionally, skip certain tags (e.g., script, style)\n",
    "            if sibling.name in ['script', 'style']:\n",
    "                continue\n",
    "            text = sibling.get_text(separator=\"\\n\", strip=True)\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "        # If the sibling is a NavigableString (text outside tags)\n",
    "        elif hasattr(sibling, 'strip'):\n",
    "            text = sibling.strip()\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "    \n",
    "    # Join all extracted texts into a single string\n",
    "    section_content = \"\\n\".join(extracted_text)\n",
    "    \n",
    "    return section_content\n",
    "    \n",
    "\n",
    "# Function to extract text content after a specific title\n",
    "def get_content_after_title(soup, title_text):\n",
    "    \"\"\"\n",
    "    Finds the content after a given title (h1 or h2) until the next h1 or h2.\n",
    "    \"\"\"\n",
    "    # Find the title tag (h1 or h2) with the exact text\n",
    "    title = soup.find(lambda tag: tag.name in ['h1', 'h2'] and tag.get_text(strip=True) == title_text)\n",
    "    if not title:\n",
    "        print(f\"Title '{title_text}' not found.\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize an empty list to hold the content\n",
    "    content = []\n",
    "    \n",
    "    # Iterate over the next siblings until the next h1 or h2\n",
    "    for sibling in title.find_next_siblings():\n",
    "        if sibling.name in ['h1', 'h2']:\n",
    "            break\n",
    "        # Append the text content of the sibling\n",
    "        text = sibling.get_text(separator=\"\\n\", strip=True)\n",
    "        if text:  # Avoid adding empty strings\n",
    "            content.append(text)\n",
    "    \n",
    "    # Join the collected text into a single string\n",
    "    return \"\\n\".join(content) if content else None\n",
    "\n",
    "def main():\n",
    "    # URL of the web page to scrape\n",
    "    url = 'https://buttondown.com/ainews/archive/ainews-shazeer-et-al-2024/'\n",
    "    \n",
    "    try:\n",
    "        # Fetch the web page content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup with the 'lxml' parser\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    # Locate the main container holding the email content\n",
    "    email_body = soup.find('div', class_='email-body-content')\n",
    "    if not email_body:\n",
    "        print(\"Couldn't find the 'email-body-content' div.\")\n",
    "        return\n",
    "    \n",
    "    # 1. Extract the Date\n",
    "    date_tag = email_body.find('date')\n",
    "    date_text = date_tag.get_text(strip=True) if date_tag else \"Date not found.\"\n",
    "    \n",
    "    # 2. Extract the Post Title\n",
    "    title_tag = email_body.find('h1', class_='subject')\n",
    "    title_text = title_tag.get_text(strip=True) if title_tag else \"Title not found.\"\n",
    "    \n",
    "    # 3. Extract the News Period from the first blockquote containing a date range\n",
    "    blockquotes = email_body.find_all('blockquote')\n",
    "    news_period = None\n",
    "    for bq in blockquotes:\n",
    "        # Search for a date range pattern like '3/28/2025-3/31/2025'\n",
    "        match = re.search(r'\\b(\\d{1,2}/\\d{1,2}/\\d{4}-\\d{1,2}/\\d{1,2}/\\d{4})\\b', bq.get_text())\n",
    "        if match:\n",
    "            news_period = match.group(1)\n",
    "            break\n",
    "    if not news_period:\n",
    "        news_period = \"News period not found.\"\n",
    "    \n",
    "    # 4. Extract Content starting and ending <h1> tags\n",
    "    start_id = 'ai-twitter-recap'\n",
    "    end_id = 'part-1-high-level-discord-summaries'\n",
    "    \n",
    "    try:\n",
    "        # Fetch the HTML content from the URL\n",
    "        html_content = fetch_html(url)\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "        return\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "        return\n",
    "    \n",
    "    # Parse the desired section\n",
    "    extracted_content = parse_section(html_content, start_id, end_id)\n",
    "        \n",
    "    # Organize the extracted data into a dictionary\n",
    "    extracted_data = {\n",
    "        'Date': date_text,\n",
    "        'Post Title': title_text,\n",
    "        'News Period': news_period,\n",
    "        'Content': extracted_content\n",
    "    }\n",
    "    \n",
    "    # Display the extracted information\n",
    "    for key, value in extracted_data.items():\n",
    "        print(f\"{key}:\\n{value}\\n{'-'*50}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a550e40-f9fa-473a-91dd-19ae39b42e4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# return dataframe\n",
    "\n",
    "def fetch_html(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; WebScraper/1.0; +http://effcon.com/)\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)  # Added timeout\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL '{url}': {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_section(html, start_id, end_id, url):\n",
    "    \"\"\"Parses HTML and extracts text between two <h1> tags by ID.\"\"\"\n",
    "    if not html:\n",
    "        return None  # Handle cases where fetching HTML failed\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    start_tag = soup.find('h1', id=start_id)\n",
    "    end_tag = soup.find('h1', id=end_id)\n",
    "\n",
    "    if not start_tag or not end_tag:\n",
    "        print(f\"Start or end tag not found for '{start_id}' and '{end_id}'.\")\n",
    "        print(f\"Start or end tag not found for '{start_id}' and '{end_id}': {url}\")\n",
    "        return None\n",
    "\n",
    "    extracted_text = []\n",
    "    for sibling in start_tag.find_next_siblings():\n",
    "        if sibling == end_tag:\n",
    "            break\n",
    "        if sibling.name and sibling.name not in ['script', 'style']:\n",
    "            text = sibling.get_text(separator=\"\\n\", strip=True)\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "        elif hasattr(sibling, 'strip'):\n",
    "            text = sibling.strip()\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "    return \"\\n\".join(extracted_text)\n",
    "\n",
    "\n",
    "def extract_data(url):\n",
    "    \"\"\"Extracts data from a single URL.\"\"\"\n",
    "    html = fetch_html(url)\n",
    "    if not html:\n",
    "        return None # Return None if HTML fetching failed.\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    email_body = soup.find('div', class_='email-body-content')\n",
    "    if not email_body:\n",
    "        print(f\"Email body not found for '{url}'.\")\n",
    "        return None\n",
    "\n",
    "    date_text = email_body.find('date').get_text(strip=True) if email_body.find('date') else None\n",
    "    title_text = email_body.find('h1', class_='subject').get_text(strip=True) if email_body.find('h1', class_='subject') else None\n",
    "    \n",
    "    news_period = None\n",
    "    for bq in email_body.find_all('blockquote'):\n",
    "        match = re.search(r'\\b(\\d{1,2}/\\d{1,2}/\\d{4}-\\d{1,2}/\\d{1,2}/\\d{4})\\b', bq.get_text())\n",
    "        if match:\n",
    "            news_period = match.group(1)\n",
    "            break\n",
    "\n",
    "    start_id = 'ai-twitter-recap'\n",
    "    end_id = 'part-1-high-level-discord-summaries'\n",
    "    content = parse_section(html, start_id, end_id, url)\n",
    "\n",
    "    return {'url': url, 'title': title_text, 'date': date_text, 'news_period': news_period, 'content': content}\n",
    "\n",
    "def main(urls):\n",
    "    \"\"\"Processes multiple URLs and returns a DataFrame.\"\"\"\n",
    "    all_data = []\n",
    "    for url in urls:\n",
    "        data = extract_data(url)\n",
    "        if data: #Append if data extraction is successful\n",
    "            all_data.append(data)\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    urls = urls\n",
    "    df = main(urls)\n",
    "    display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59b7c2e7-0e5f-465f-87aa-c7f2de0b6865",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     83\u001b[0m     urls \u001b[38;5;241m=\u001b[39m urls\n\u001b[1;32m---> 84\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43murls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     display(df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m))\n",
      "Cell \u001b[1;32mIn[42], line 76\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(urls)\u001b[0m\n\u001b[0;32m     74\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[1;32m---> 76\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data: \u001b[38;5;66;03m#Append if data extraction is successful\u001b[39;00m\n\u001b[0;32m     78\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "Cell \u001b[1;32mIn[42], line 65\u001b[0m, in \u001b[0;36mextract_data\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     61\u001b[0m         news_period \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m soup \u001b[38;5;241m=\u001b[39m bs(\u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Get the main page text with tags\u001b[39;00m\n\u001b[0;32m     67\u001b[0m content \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "# return dataframe  ver 3\n",
    "\n",
    "def fetch_html(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; browser; +http://effcon.com/)\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)  # Added timeout\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL '{url}': {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_section(html, start_id, end_id, url):\n",
    "    \"\"\"Parses HTML and extracts text between two <h1> tags by ID.\"\"\"\n",
    "    if not html:\n",
    "        return None  # Handle cases where fetching HTML failed\n",
    "    soup = bs(html, 'lxml')\n",
    "    start_tag = soup.find('h1', id=start_id)\n",
    "    end_tag = soup.find('h1', id=end_id)\n",
    "\n",
    "    if not start_tag or not end_tag:\n",
    "        print(f\"Start or end tag not found for '{start_id}' and '{end_id}'.\")\n",
    "        print(f\"Start or end tag not found for '{start_id}' and '{end_id}': {url}\")\n",
    "        return None\n",
    "\n",
    "    extracted_text = []\n",
    "    for sibling in start_tag.find_next_siblings():\n",
    "        if sibling == end_tag:\n",
    "            break\n",
    "        if sibling.name and sibling.name not in ['script', 'style']:\n",
    "            text = sibling.get_text(separator=\"\\n\", strip=True)\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "        elif hasattr(sibling, 'strip'):\n",
    "            text = sibling.strip()\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "    return \"\\n\".join(extracted_text)\n",
    "\n",
    "\n",
    "def extract_data(url):\n",
    "    \"\"\"Extracts data from a single URL.\"\"\"\n",
    "    html = fetch_html(url)\n",
    "    if not html:\n",
    "        return None # Return None if HTML fetching failed.\n",
    "    soup = bs(html, 'lxml')\n",
    "    email_body = soup.find('div', class_='email-body-content')\n",
    "    if not email_body:\n",
    "        print(f\"Email body not found for '{url}'.\")\n",
    "        return None\n",
    "\n",
    "    date_text = email_body.find('date').get_text(strip=True) if email_body.find('date') else None\n",
    "    title_text = email_body.find('h1', class_='subject').get_text(strip=True) if email_body.find('h1', class_='subject') else None\n",
    "    \n",
    "    news_period = None\n",
    "    for bq in email_body.find_all('blockquote'):\n",
    "        match = re.search(r'\\b(\\d{1,2}/\\d{1,2}/\\d{4}-\\d{1,2}/\\d{1,2}/\\d{4})\\b', bq.get_text())\n",
    "        if match:\n",
    "            news_period = match.group(1)\n",
    "            break\n",
    "\n",
    "\n",
    "    soup = bs(html.content, 'html.parser')\n",
    "    # Get the main page text with tags\n",
    "    content = soup.find_all(['title', 'h1', 'h2', 'p', 'li', 'ul', 'h3'])\n",
    "    \n",
    "\n",
    "    return {'url': url, 'title': title_text, 'date': date_text, 'news_period': news_period, 'content': content}\n",
    "\n",
    "def main(urls):\n",
    "    \"\"\"Processes multiple URLs and returns a DataFrame.\"\"\"\n",
    "    all_data = []\n",
    "    for url in urls:\n",
    "        data = extract_data(url)\n",
    "        if data: #Append if data extraction is successful\n",
    "            all_data.append(data)\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    urls = urls\n",
    "    df = main(urls)\n",
    "    display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a926d1-3ca2-43b0-8fa8-c4c80ff9966b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get the page title and publication data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m title \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m----> 9\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[43mtitle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Get the main page text with tags\u001b[39;00m\n\u001b[0;32m     11\u001b[0m page_text \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# Iterate through all the UTL entities in the dataframe column df['Page_link']\n",
    "for index, row in links.iterrows():\n",
    "    page_link = row['urls']\n",
    "    page = requests.get(page_link)\n",
    "    # Parse the page content\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    # Get the page title and publication data\n",
    "    title = soup.find('title').text\n",
    "    # Get the main page text with tags\n",
    "    page_text = soup.find_all(['title', 'h1', 'h2', 'p', 'li', 'ul', 'h3'])\n",
    "    # Add page title and publication data\n",
    "    links.at[index, 'Page_title'] = title\n",
    "    # Write only text to the corresponding row of the dataframe\n",
    "    links.at[index, 'Page_text'] = ' '.join([text.get_text() for text in page_text])\n",
    "\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e532306-d62f-4669-b4c1-f28c2e464c4c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through all the UTL entities in the dataframe column df['Page_link']\n",
    "for index, row in links.iterrows():\n",
    "    page_link = row['urls']\n",
    "    page = requests.get(page_link)\n",
    "    # Parse the page content\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    # Get the page title and publication data\n",
    "    title = soup.find('title').text\n",
    "    # Get the main page text with tags\n",
    "    page_text = soup.find_all(['title', 'h1', 'h2', 'p', 'li', 'ul', 'h3'])\n",
    "    # Add page title and publication data\n",
    "    links.at[index, 'Page_title'] = title\n",
    "    # Write only text to the corresponding row of the dataframe\n",
    "    links.at[index, 'Page_text'] = ' '.join([text.get_text() for text in page_text])\n",
    "\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36d553-5526-43e2-9f97-58713f35644d",
   "metadata": {},
   "source": [
    "# working version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fed0ea26-a694-43b6-aaba-b2729f6e05a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  2025-04-05 01:19:57.867639\n",
      "Error fetching URL 'https://buttondown.com/ainews/archive/ainews-sxxx/': HTTPSConnectionPool(host='buttondown.com', port=443): Read timed out. (read timeout=10)\n",
      "Error fetching URL 'https://buttondown.com/ainews/archive/ainews-talaria-apples-new-mlops-superweapon-4066/': HTTPSConnectionPool(host='buttondown.com', port=443): Read timed out. (read timeout=10)\n",
      "Error fetching URL 'https://buttondown.com/ainews/archive/ainews-the-ultra-scale-playbook-training-llms-on/': HTTPSConnectionPool(host='buttondown.com', port=443): Read timed out. (read timeout=10)\n",
      "Error fetching URL 'https://buttondown.com/ainews/archive/ainews-the-worlds-first-fully-autonomous-ai/': HTTPSConnectionPool(host='buttondown.com', port=443): Read timed out. (read timeout=10)\n",
      "Error fetching URL 'https://buttondown.com/ainews/archive/ainews-tinyzero-reproduce-deepseek-r1-zero-for-30/': HTTPSConnectionPool(host='buttondown.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>news_period</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/10/2024: All the best papers for AI...</td>\n",
       "      <td>January 11, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News\\n[AINews] 1/10/2024: All the best pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/11/2024: Mixing Experts vs Merging ...</td>\n",
       "      <td>January 12, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News\\n[AINews] 1/11/2024: Mixing Experts vs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/1/2024: How to start with Open Sour...</td>\n",
       "      <td>January 3, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News\\n[AINews] 1/1/2024: How to start with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://buttondown.com/ainews/archive/ainews-1...   \n",
       "1  https://buttondown.com/ainews/archive/ainews-1...   \n",
       "2  https://buttondown.com/ainews/archive/ainews-1...   \n",
       "\n",
       "                                               title              date  \\\n",
       "0  [AINews] 1/10/2024: All the best papers for AI...  January 11, 2024   \n",
       "1  [AINews] 1/11/2024: Mixing Experts vs Merging ...  January 12, 2024   \n",
       "2  [AINews] 1/1/2024: How to start with Open Sour...   January 3, 2024   \n",
       "\n",
       "  news_period                                            content  \n",
       "0        None  AI News\\n[AINews] 1/10/2024: All the best pape...  \n",
       "1        None  AI News\\n[AINews] 1/11/2024: Mixing Experts vs...  \n",
       "2        None  AI News\\n[AINews] 1/1/2024: How to start with ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish:  2025-04-05 01:29:44.538359\n",
      "0:09:46.670720\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Return HTML content\n",
    "def fetch_html(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; WebScraper/1.0; +http://effcon.com/)\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)  # Added timeout\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL '{url}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Parse all visible page text\n",
    "def parse_page_text(html):\n",
    "    \"\"\"Parses HTML and returns all visible text on the page.\"\"\"\n",
    "    if not html:\n",
    "        return None  # Handle cases where fetching HTML failed\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # Extract text from specific visible tags\n",
    "    elements = soup.find_all(['h1', 'h2', 'h3', 'p', 'li', 'ul'])\n",
    "    visible_text = []\n",
    "    \n",
    "    for element in elements:\n",
    "        text = element.get_text(separator=\"\\n\", strip=True)\n",
    "        if text:\n",
    "            visible_text.append(text)\n",
    "    \n",
    "    # Combine text content into a single string\n",
    "    return \"\\n\".join(visible_text)\n",
    "\n",
    "# Extract data from a single URL\n",
    "def extract_data(url):\n",
    "    \"\"\"Extracts data from a single URL.\"\"\"\n",
    "    html = fetch_html(url)\n",
    "    if not html:\n",
    "        return None  # Return None if HTML fetching failed\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # Extract email body content if available\n",
    "    email_body = soup.find('div', class_='email-body-content')\n",
    "    date_text = email_body.find('date').get_text(strip=True) if email_body and email_body.find('date') else None\n",
    "    title_text = email_body.find('h1', class_='subject').get_text(strip=True) if email_body and email_body.find('h1', class_='subject') else None\n",
    "    \n",
    "    # Extract news period\n",
    "    news_period = None\n",
    "    if email_body:\n",
    "        for bq in email_body.find_all('blockquote'):\n",
    "            match = re.search(r'\\b(\\d{1,2}/\\d{1,2}/\\d{4}-\\d{1,2}/\\d{1,2}/\\d{4})\\b', bq.get_text())\n",
    "            if match:\n",
    "                news_period = match.group(1)\n",
    "                break\n",
    "\n",
    "    # Extract all visible page text\n",
    "    content = parse_page_text(html)\n",
    "\n",
    "    return {'url': url, 'title': title_text, 'date': date_text, 'news_period': news_period, 'content': content}\n",
    "\n",
    "# Process multiple URLs and return a DataFrame\n",
    "def main(urls):\n",
    "    \"\"\"Processes multiple URLs and returns a DataFrame.\"\"\"\n",
    "    all_data = []\n",
    "    for url in urls:\n",
    "        data = extract_data(url)\n",
    "        if data:  # Append if data extraction is successful\n",
    "            all_data.append(data)\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Execution\n",
    "now1 = datetime.datetime.now()\n",
    "print(\"start: \", now1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    urls = urls\n",
    "    raw_text = main(urls)\n",
    "    display(raw_text.head(3))\n",
    "\n",
    "now2 = datetime.datetime.now()\n",
    "print(\"finish: \", now2)\n",
    "print(now2-now1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8350ecc-00c0-4fd7-97dc-81356cd0a6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>news_period</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/10/2024: All the best papers for AI...</td>\n",
       "      <td>January 11, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News [AINews] 1/10/2024: All the best paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/11/2024: Mixing Experts vs Merging ...</td>\n",
       "      <td>January 12, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News [AINews] 1/11/2024: Mixing Experts vs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/1/2024: How to start with Open Sour...</td>\n",
       "      <td>January 3, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News [AINews] 1/1/2024: How to start with O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/12/2024: Anthropic coins Sleeper Ag...</td>\n",
       "      <td>January 13, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News [AINews] 1/12/2024: Anthropic coins Sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/13-14/2024: Don't sleep on #prompt-...</td>\n",
       "      <td>January 16, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News [AINews] 1/13-14/2024: Don't sleep on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] Welcome Interconnects and OpenRouter</td>\n",
       "      <td>February 27, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>AI News [AINews] Welcome Interconnects and Ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] Welcome /r/LocalLlama!</td>\n",
       "      <td>March 21, 2024</td>\n",
       "      <td>3/20/2024-3/21/2024</td>\n",
       "      <td>AI News [AINews] Welcome /r/LocalLlama! This i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] We Solved Hallucinations</td>\n",
       "      <td>July 13, 2024</td>\n",
       "      <td>7/11/2024-7/12/2024</td>\n",
       "      <td>AI News [AINews] We Solved Hallucinations This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-x...</td>\n",
       "      <td>[AINews] X.ai Grok 3 and Mira Murati's Thinkin...</td>\n",
       "      <td>February 18, 2025</td>\n",
       "      <td>2/17/2025-2/18/2025</td>\n",
       "      <td>AI News [AINews] X.ai Grok 3 and Mira Murati's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-z...</td>\n",
       "      <td>[AINews] Zero to GPT in 1 Year</td>\n",
       "      <td>April 12, 2024</td>\n",
       "      <td>4/11/2024-4/12/2024</td>\n",
       "      <td>AI News [AINews] Zero to GPT in 1 Year This is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "1    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "2    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "3    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "4    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "..                                                 ...   \n",
       "367  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "368  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "369  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "370  https://buttondown.com/ainews/archive/ainews-x...   \n",
       "371  https://buttondown.com/ainews/archive/ainews-z...   \n",
       "\n",
       "                                                 title               date  \\\n",
       "0    [AINews] 1/10/2024: All the best papers for AI...   January 11, 2024   \n",
       "1    [AINews] 1/11/2024: Mixing Experts vs Merging ...   January 12, 2024   \n",
       "2    [AINews] 1/1/2024: How to start with Open Sour...    January 3, 2024   \n",
       "3    [AINews] 1/12/2024: Anthropic coins Sleeper Ag...   January 13, 2024   \n",
       "4    [AINews] 1/13-14/2024: Don't sleep on #prompt-...   January 16, 2024   \n",
       "..                                                 ...                ...   \n",
       "367      [AINews] Welcome Interconnects and OpenRouter  February 27, 2024   \n",
       "368                    [AINews] Welcome /r/LocalLlama!     March 21, 2024   \n",
       "369                  [AINews] We Solved Hallucinations      July 13, 2024   \n",
       "370  [AINews] X.ai Grok 3 and Mira Murati's Thinkin...  February 18, 2025   \n",
       "371                     [AINews] Zero to GPT in 1 Year     April 12, 2024   \n",
       "\n",
       "             news_period                                            content  \n",
       "0                   None  AI News [AINews] 1/10/2024: All the best paper...  \n",
       "1                   None  AI News [AINews] 1/11/2024: Mixing Experts vs ...  \n",
       "2                   None  AI News [AINews] 1/1/2024: How to start with O...  \n",
       "3                   None  AI News [AINews] 1/12/2024: Anthropic coins Sl...  \n",
       "4                   None  AI News [AINews] 1/13-14/2024: Don't sleep on ...  \n",
       "..                   ...                                                ...  \n",
       "367                 None  AI News [AINews] Welcome Interconnects and Ope...  \n",
       "368  3/20/2024-3/21/2024  AI News [AINews] Welcome /r/LocalLlama! This i...  \n",
       "369  7/11/2024-7/12/2024  AI News [AINews] We Solved Hallucinations This...  \n",
       "370  2/17/2025-2/18/2025  AI News [AINews] X.ai Grok 3 and Mira Murati's...  \n",
       "371  4/11/2024-4/12/2024  AI News [AINews] Zero to GPT in 1 Year This is...  \n",
       "\n",
       "[372 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text1 = raw_text.copy()\n",
    "raw_text1['content'] = [bs(text).get_text() for text in raw_text1['content']]\n",
    "raw_text1['content'] = [re.sub('\\\\n\\\\n+', '\\n', ct) for ct in raw_text1['content']]\n",
    "raw_text1['content'] = [re.sub('\\ \\ +', ' ', ct) for ct in raw_text1['content']]\n",
    "raw_text1['content'] = raw_text1['content'].replace(r'\\s+', ' ', regex=True)\n",
    "raw_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4a4feec-09a9-4dbb-9a8a-972961cc301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  2025-04-05 02:05:48.080479\n",
      "finish:  2025-04-05 02:06:15.004899\n",
      "0:00:26.924420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>news_period</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/10/2024: All the best papers for AI...</td>\n",
       "      <td>January 11, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents GitHub - Notes from the Late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/11/2024: Mixing Experts vs Merging ...</td>\n",
       "      <td>January 12, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents Nous Research AI Discord Sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/1/2024: How to start with Open Sour...</td>\n",
       "      <td>January 3, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents OpenAI Discord Summary Nous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/12/2024: Anthropic coins Sleeper Ag...</td>\n",
       "      <td>January 13, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents Nous Research AI Discord Sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/13-14/2024: Don't sleep on #prompt-...</td>\n",
       "      <td>January 16, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents OpenAI Discord Summary Nous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] Welcome Interconnects and OpenRouter</td>\n",
       "      <td>February 27, 2024</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents PART Summary of Summaries of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] Welcome /r/LocalLlama!</td>\n",
       "      <td>March 21, 2024</td>\n",
       "      <td>3/20/2024-3/21/2024</td>\n",
       "      <td>Table of Contents PART AI Twitter Recap PART S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] We Solved Hallucinations</td>\n",
       "      <td>July 13, 2024</td>\n",
       "      <td>7/11/2024-7/12/2024</td>\n",
       "      <td>Table of Contents AI Twitter Recap AI Reddit R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-x...</td>\n",
       "      <td>[AINews] X.ai Grok 3 and Mira Murati's Thinkin...</td>\n",
       "      <td>February 18, 2025</td>\n",
       "      <td>2/17/2025-2/18/2025</td>\n",
       "      <td>Table of Contents AI Twitter Recap AI Reddit R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-z...</td>\n",
       "      <td>[AINews] Zero to GPT in 1 Year</td>\n",
       "      <td>April 12, 2024</td>\n",
       "      <td>4/11/2024-4/12/2024</td>\n",
       "      <td>Table of Contents AI Reddit Recap AI Twitter R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "1    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "2    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "3    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "4    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "..                                                 ...   \n",
       "367  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "368  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "369  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "370  https://buttondown.com/ainews/archive/ainews-x...   \n",
       "371  https://buttondown.com/ainews/archive/ainews-z...   \n",
       "\n",
       "                                                 title               date  \\\n",
       "0    [AINews] 1/10/2024: All the best papers for AI...   January 11, 2024   \n",
       "1    [AINews] 1/11/2024: Mixing Experts vs Merging ...   January 12, 2024   \n",
       "2    [AINews] 1/1/2024: How to start with Open Sour...    January 3, 2024   \n",
       "3    [AINews] 1/12/2024: Anthropic coins Sleeper Ag...   January 13, 2024   \n",
       "4    [AINews] 1/13-14/2024: Don't sleep on #prompt-...   January 16, 2024   \n",
       "..                                                 ...                ...   \n",
       "367      [AINews] Welcome Interconnects and OpenRouter  February 27, 2024   \n",
       "368                    [AINews] Welcome /r/LocalLlama!     March 21, 2024   \n",
       "369                  [AINews] We Solved Hallucinations      July 13, 2024   \n",
       "370  [AINews] X.ai Grok 3 and Mira Murati's Thinkin...  February 18, 2025   \n",
       "371                     [AINews] Zero to GPT in 1 Year     April 12, 2024   \n",
       "\n",
       "             news_period                                            content  \n",
       "0                   None  Table of Contents GitHub - Notes from the Late...  \n",
       "1                   None  Table of Contents Nous Research AI Discord Sum...  \n",
       "2                   None  Table of Contents OpenAI Discord Summary Nous ...  \n",
       "3                   None  Table of Contents Nous Research AI Discord Sum...  \n",
       "4                   None  Table of Contents OpenAI Discord Summary Nous ...  \n",
       "..                   ...                                                ...  \n",
       "367                 None  Table of Contents PART Summary of Summaries of...  \n",
       "368  3/20/2024-3/21/2024  Table of Contents PART AI Twitter Recap PART S...  \n",
       "369  7/11/2024-7/12/2024  Table of Contents AI Twitter Recap AI Reddit R...  \n",
       "370  2/17/2025-2/18/2025  Table of Contents AI Twitter Recap AI Reddit R...  \n",
       "371  4/11/2024-4/12/2024  Table of Contents AI Reddit Recap AI Twitter R...  \n",
       "\n",
       "[372 rows x 5 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "now1 = datetime.datetime.now()\n",
    "print(\"start: \", now1)\n",
    "\n",
    "\n",
    "def remove_lines_starting_with_arrow(text):\n",
    "    if not text:  # Handle empty or None content gracefully\n",
    "        return text\n",
    "    lines = text.split(\"\\n\")  # Split content into individual lines\n",
    "    filtered_lines = [line for line in lines if not line.lstrip().startswith(\"▷\")]  # Remove lines starting with '▷'\n",
    "    return \"\\n\".join(filtered_lines)  # Join the filtered lines back into a single string\n",
    "\n",
    "# Apply the function to the content column\n",
    "raw_text1['content'] = raw_text1['content'].apply(remove_lines_starting_with_arrow)\n",
    "\n",
    "\n",
    "# Function to remove words containing unallowed symbols\n",
    "def remove_unallowed_words(text):\n",
    "    if not text:  # Handle empty or None content gracefully\n",
    "        return text\n",
    "    \n",
    "    # Regex to keep words containing only allowed characters (letters, digits, punctuation, _, -, +, ·, \\n)\n",
    "    allowed_pattern = r\"[a-zA-Z0-9._+\\-·]+|\\n\"  # Allowed characters in a word or newline\n",
    "    \n",
    "    # Split text into words or lines, including retaining newline as a delimiter\n",
    "    cleaned_text = []\n",
    "    for part in text.split(\"\\n\"):  # Split by newline first to preserve \"\\n\"\n",
    "        words = part.split()  # Further split by whitespace to isolate words\n",
    "        filtered_words = [word for word in words if re.fullmatch(allowed_pattern, word)]  # Retain only allowed words\n",
    "        cleaned_text.append(\" \".join(filtered_words))  # Reassemble lines\n",
    "    \n",
    "    # Rejoin lines separated by \"\\n\"\n",
    "    return \"\\n\".join(cleaned_text)\n",
    "\n",
    "# Apply the function to the content column\n",
    "raw_text1['content'] = raw_text1['content'].apply(remove_unallowed_words)\n",
    "\n",
    "\n",
    "# Function to clean the content\n",
    "def clean_content(text):\n",
    "    if not text:  # Handle empty/None content safely\n",
    "        return text\n",
    "    \n",
    "    # Step 1: Delete text before 'Table of Contents' (case-insensitive)\n",
    "    text = re.sub(r\"^(.*?)Table of Contents\", \"Table of Contents\", text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    # Step 2: Delete '\\nthanks\\n'\n",
    "    text = text.replace(\"\\nthanks\\n\", \"\\n\")\n",
    "    \n",
    "    # Step 3: Delete '\\nand\\n'\n",
    "    text = text.replace(\"\\nand\\n\", \"\\n\")\n",
    "    text = text.replace(\"\\n.\\n\", \"\\n\")\n",
    "    text = text.replace(\"\\n. \", \"\\n\")\n",
    "    text = text.replace(\"\\nin\\n \", \" in \")\n",
    "    text = text.replace(\" of\\n \", \" of \")\n",
    "    text = text.replace(\" by\\n\", \" by \")\n",
    "    text = text.replace(\"The\\n\", \"The \")\n",
    "    text = text.replace(\"A\\n\", \"A \")\n",
    "    text = text.replace(\"a\\n\", \"a \")\n",
    "    text = text.replace(\"Only 1 channel had so no need to summarize...\", \" \")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Step 4: Remove blank or nearly blank strings like '\\n\\n' or 'n \\n'\n",
    "    text = re.sub(r\"(\\n\\s*\\n)\", \"\\n\", text)  # Matches multiple newlines with optional spaces\n",
    "    \n",
    "    # Strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'content' column\n",
    "raw_text1['content'] = raw_text1['content'].apply(clean_content)\n",
    "\n",
    "\n",
    "# Function to remove line breaks before lowercase words\n",
    "def remove_line_break_before_lowercase(text):\n",
    "    if not text:  # Handle empty or None content safely\n",
    "        return text\n",
    "    # Use regex to remove '\\n' before lowercase words\n",
    "    return re.sub(r\"\\n([a-z])\", r\" \\1\", text)\n",
    "\n",
    "# Apply the function to the 'content' column\n",
    "raw_text1['content'] = raw_text1['content'].apply(remove_line_break_before_lowercase)\n",
    "\n",
    "\n",
    "\n",
    "# Function to remove duplicate lines within each value\n",
    "def remove_duplicate_lines(text):\n",
    "    if not text:  # Handle empty/None content gracefully\n",
    "        return text\n",
    "    # Split the text into individual lines\n",
    "    lines = text.split(\"\\n\")\n",
    "    # Remove duplicate lines while preserving order, and join them back\n",
    "    unique_lines = list(dict.fromkeys(lines))  # Use `dict.fromkeys` to preserve order and remove duplicates\n",
    "    return \"\\n\".join(unique_lines)\n",
    "\n",
    "raw_text1['content'] = raw_text1['content'].apply(remove_duplicate_lines)\n",
    "\n",
    "now2 = datetime.datetime.now()\n",
    "print(\"finish: \", now2)\n",
    "print(now2-now1)\n",
    "raw_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "259e90d3-4415-4604-adb7-9fe99200f985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum date: 2023-11-04 00:00:00\n",
      "Maximum date: 2025-04-03 00:00:00\n",
      "\n",
      "Date findings range from 2023-11-04 00:00:00 to 2025-04-03 00:00:00, duration = 516 days.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>news_period</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/10/2024: All the best papers for AI...</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents GitHub - Notes from the Late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/11/2024: Mixing Experts vs Merging ...</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents Nous Research AI Discord Sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/1/2024: How to start with Open Sour...</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents OpenAI Discord Summary Nous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/12/2024: Anthropic coins Sleeper Ag...</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents Nous Research AI Discord Sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-1...</td>\n",
       "      <td>[AINews] 1/13-14/2024: Don't sleep on #prompt-...</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents OpenAI Discord Summary Nous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] Welcome Interconnects and OpenRouter</td>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>None</td>\n",
       "      <td>Table of Contents PART Summary of Summaries of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] Welcome /r/LocalLlama!</td>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>3/20/2024-3/21/2024</td>\n",
       "      <td>Table of Contents PART AI Twitter Recap PART S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-w...</td>\n",
       "      <td>[AINews] We Solved Hallucinations</td>\n",
       "      <td>2024-07-13</td>\n",
       "      <td>7/11/2024-7/12/2024</td>\n",
       "      <td>Table of Contents AI Twitter Recap AI Reddit R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-x...</td>\n",
       "      <td>[AINews] X.ai Grok 3 and Mira Murati's Thinkin...</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>2/17/2025-2/18/2025</td>\n",
       "      <td>Table of Contents AI Twitter Recap AI Reddit R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>https://buttondown.com/ainews/archive/ainews-z...</td>\n",
       "      <td>[AINews] Zero to GPT in 1 Year</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>4/11/2024-4/12/2024</td>\n",
       "      <td>Table of Contents AI Reddit Recap AI Twitter R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "1    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "2    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "3    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "4    https://buttondown.com/ainews/archive/ainews-1...   \n",
       "..                                                 ...   \n",
       "367  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "368  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "369  https://buttondown.com/ainews/archive/ainews-w...   \n",
       "370  https://buttondown.com/ainews/archive/ainews-x...   \n",
       "371  https://buttondown.com/ainews/archive/ainews-z...   \n",
       "\n",
       "                                                 title       date  \\\n",
       "0    [AINews] 1/10/2024: All the best papers for AI... 2024-01-11   \n",
       "1    [AINews] 1/11/2024: Mixing Experts vs Merging ... 2024-01-12   \n",
       "2    [AINews] 1/1/2024: How to start with Open Sour... 2024-01-03   \n",
       "3    [AINews] 1/12/2024: Anthropic coins Sleeper Ag... 2024-01-13   \n",
       "4    [AINews] 1/13-14/2024: Don't sleep on #prompt-... 2024-01-16   \n",
       "..                                                 ...        ...   \n",
       "367      [AINews] Welcome Interconnects and OpenRouter 2024-02-27   \n",
       "368                    [AINews] Welcome /r/LocalLlama! 2024-03-21   \n",
       "369                  [AINews] We Solved Hallucinations 2024-07-13   \n",
       "370  [AINews] X.ai Grok 3 and Mira Murati's Thinkin... 2025-02-18   \n",
       "371                     [AINews] Zero to GPT in 1 Year 2024-04-12   \n",
       "\n",
       "             news_period                                            content  \n",
       "0                   None  Table of Contents GitHub - Notes from the Late...  \n",
       "1                   None  Table of Contents Nous Research AI Discord Sum...  \n",
       "2                   None  Table of Contents OpenAI Discord Summary Nous ...  \n",
       "3                   None  Table of Contents Nous Research AI Discord Sum...  \n",
       "4                   None  Table of Contents OpenAI Discord Summary Nous ...  \n",
       "..                   ...                                                ...  \n",
       "367                 None  Table of Contents PART Summary of Summaries of...  \n",
       "368  3/20/2024-3/21/2024  Table of Contents PART AI Twitter Recap PART S...  \n",
       "369  7/11/2024-7/12/2024  Table of Contents AI Twitter Recap AI Reddit R...  \n",
       "370  2/17/2025-2/18/2025  Table of Contents AI Twitter Recap AI Reddit R...  \n",
       "371  4/11/2024-4/12/2024  Table of Contents AI Reddit Recap AI Twitter R...  \n",
       "\n",
       "[372 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text2 = raw_text1.copy()\n",
    "\n",
    "raw_text2['date'] = pd.to_datetime(raw_text2['date'])\n",
    "\n",
    "daymin = raw_text2['date'].min()\n",
    "daymax = raw_text2['date'].max()\n",
    "\n",
    "print(f\"Minimum date: {daymin}\")\n",
    "print(f\"Maximum date: {daymax}\")\n",
    "drange = (daymax-daymin).days\n",
    "print(f'\\nDate findings range from {daymin} to {daymax}, duration = {drange} days.')\n",
    "\n",
    "raw_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8f55a7e-660d-4f26-a4ed-48961c62cd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number texts before duplecates cleaning:  372\n",
      "Number texts after duplecates cleaning:  372\n",
      "tokens sum:  32988704\n"
     ]
    }
   ],
   "source": [
    "# Add token count column\n",
    "def num_tokens_from_string(string, encoding_name):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string, disallowed_special=()))\n",
    "    return num_tokens\n",
    "\n",
    "raw_text2['token_count'] = raw_text2['content'].apply(lambda text:num_tokens_from_string(text, \"cl100k_base\"))\n",
    "print(\"Number texts before duplecates cleaning: \",len(raw_text2))\n",
    "\n",
    "# Drop duplicated posts\n",
    "raw_text3 = raw_text2.drop_duplicates(subset=['title', 'url'])\n",
    "raw_text3 = raw_text3.sort_values(by=['date'], ascending=False)\n",
    "\n",
    "print(\"Number texts after duplecates cleaning: \",len(raw_text3))\n",
    "print(\"tokens sum: \", raw_text3['token_count'].sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "13ff1540-a511-40be-a594-2ec0362cf450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens max:  8978109\n"
     ]
    }
   ],
   "source": [
    "print(\"tokens max: \", raw_text3['token_count'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccbce0-c6bb-4607-948d-9501390fea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_text2.iloc[201]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e0502-8b02-49ba-8f00-bc7a42b619e8",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356d48f-36ce-43b8-b674-c25c8519df6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8aa4a72-4d72-4804-8c0f-771e3cc67120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ainews_2025-04-05.csv uploaded:  2025-04-05\n"
     ]
    }
   ],
   "source": [
    "# Save data \n",
    "file_path = r'C:\\Users\\Denis_Davydov2\\OneDrive - EPAM\\Prophet_AI_docs\\Datasets\\AI_skills\\\\'\n",
    "file_name = f'ainews_{date.today()}.csv'\n",
    "\n",
    "raw_text3.to_csv(file_path + file_name, index=False)\n",
    "print(f\"File {file_name} uploaded: \", date.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
