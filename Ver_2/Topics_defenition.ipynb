{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c552945",
   "metadata": {},
   "source": [
    "An AI/ML skill is a technical ability or expertise that enables individuals to work with artificial intelligence and machine learning technologies effectively. Here are some common AI/ML skills:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a03e81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n",
      "\n",
      "Working directory: c:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\n",
      "C:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\n",
      "\n",
      "Current working directory: C:\\Users\\Denis_Davydov2\\OneDrive\\Scipts\\Py_Scripts\\EPAM\\Prophet\\AI_skills\n",
      "Last run: 2025-11-08\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "import csv\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "print('Python version:', sys.version)\n",
    "print('\\nWorking directory:', os.getcwd())\n",
    "%cd C:\\\\Users\\\\Denis_Davydov2\\\\OneDrive\\\\Scipts\\\\Py_Scripts\\\\EPAM\\\\Prophet\\\\AI_skills\n",
    "print('\\nCurrent working directory:', os.getcwd())\n",
    "print(\"Last run:\", date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0d0e7",
   "metadata": {},
   "source": [
    "# Topics cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8275d27",
   "metadata": {},
   "source": [
    "## Get all topics from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0a47a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: topics_inoreader_gemini25flash_2025-10-30\n",
      "Loaded: topics_inoreader_gpt5mini_2025-10-31\n",
      "Loaded: topics_inoreader_gpt5nano_2025-10-29\n",
      "Loaded: topics_inoreade_claude35_sonnet_2025-11-01\n",
      "Loaded: topics_smol_claude35_sonnet_2025-11-01\n",
      "Loaded: topics_smol_gemini25flash_2025-10-31\n",
      "Loaded: topics_smol_gpt5mini_2025-10-31\n",
      "Loaded: topics_smol_gpt5nano_2025-10-31\n",
      "\n",
      "Loaded dataframes: ['topics_inoreader_gemini25flash_2025-10-30', 'topics_inoreader_gpt5mini_2025-10-31', 'topics_inoreader_gpt5nano_2025-10-29', 'topics_inoreade_claude35_sonnet_2025-11-01', 'topics_smol_claude35_sonnet_2025-11-01', 'topics_smol_gemini25flash_2025-10-31', 'topics_smol_gpt5mini_2025-10-31', 'topics_smol_gpt5nano_2025-10-31']\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'C:\\Users\\Denis_Davydov2\\OneDrive - EPAM\\Prophet_AI_docs\\Datasets\\AI_skills\\All_extracted'\n",
    "\n",
    "# Get list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Create a dictionary to store all dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Read each CSV file into a dataframe\n",
    "for file in csv_files:\n",
    "    # Get the filename without extension as key\n",
    "    df_name = os.path.splitext(file)[0]\n",
    "    # Read the CSV file\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    dfs[df_name] = pd.read_csv(file_path)\n",
    "    print(f\"Loaded: {df_name}\")\n",
    "\n",
    "# Display the names of loaded dataframes\n",
    "print(\"\\nLoaded dataframes:\", list(dfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78cbfb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 12217\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Generative AI, LLM APIs, Prompt Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Artificial General Intelligence, AI resilience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>AI-integrated browsers, face-scanning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Generative AI, AI Assistants, Prompt Engineeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>LLM reasoning, pattern matching, chain-of-thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398.0</td>\n",
       "      <td>LangChain, Prompt Engineering, Retrieval-Augme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399.0</td>\n",
       "      <td>Vector Search, RAG, Prompt Engineering, LangCh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400.0</td>\n",
       "      <td>LangChain, LLM APIs, Prompt Engineering, Agent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401.0</td>\n",
       "      <td>LangChain, Prompt Engineering, LLMs, Reinforce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402.0</td>\n",
       "      <td>RAG, Vector Search, LangChain, LangSmith, Rein...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             topics\n",
       "0      0.0        Generative AI, LLM APIs, Prompt Engineering\n",
       "1      1.0     Artificial General Intelligence, AI resilience\n",
       "2      2.0              AI-integrated browsers, face-scanning\n",
       "3      3.0  Generative AI, AI Assistants, Prompt Engineeri...\n",
       "4      4.0  LLM reasoning, pattern matching, chain-of-thou...\n",
       "..     ...                                                ...\n",
       "398  398.0  LangChain, Prompt Engineering, Retrieval-Augme...\n",
       "399  399.0  Vector Search, RAG, Prompt Engineering, LangCh...\n",
       "400  400.0  LangChain, LLM APIs, Prompt Engineering, Agent...\n",
       "401  401.0  LangChain, Prompt Engineering, LLMs, Reinforce...\n",
       "402  402.0  RAG, Vector Search, LangChain, LangSmith, Rein...\n",
       "\n",
       "[12217 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = pd.concat(dfs.values())\n",
    "print(\"Rows:\", len(topics))\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dad871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total topics: 150618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                        Generative AI\n",
       "0                             LLM APIs\n",
       "0                   Prompt Engineering\n",
       "1      Artificial General Intelligence\n",
       "1                        AI resilience\n",
       "                    ...               \n",
       "402                 Prompt Engineering\n",
       "402                   Prompt Injection\n",
       "402                Multi-Agent Systems\n",
       "402                    Computer Vision\n",
       "402                                NLP\n",
       "Name: topics, Length: 150618, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the topics by comma and explode them into separate rows\n",
    "exploded_topics = topics['topics'].str.split(',').explode().str.strip()\n",
    "print(\"total topics:\", len(exploded_topics))\n",
    "exploded_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a20104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original topics count: 150618\n",
      "Unique topics count: 22190\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates and reset index\n",
    "clean_topics = exploded_topics.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Standardize characters (replace various types of hyphens and dashes with standard hyphen)\n",
    "clean_topics = clean_topics.str.replace('–', '-')  # en dash\n",
    "clean_topics = clean_topics.str.replace('—', '-')  # em dash\n",
    "clean_topics = clean_topics.str.replace('‐', '-')  # hyphen\n",
    "clean_topics = clean_topics.str.replace('\\u2010', '-')  # hyphen\n",
    "clean_topics = clean_topics.str.replace('\\u2011', '-')  # non-breaking hyphen\n",
    "clean_topics = clean_topics.str.replace('\\u2012', '-')  # figure dash\n",
    "clean_topics = clean_topics.str.replace('\\u2013', '-')  # en dash\n",
    "clean_topics = clean_topics.str.replace('\\u2014', '-')  # em dash\n",
    "clean_topics = clean_topics.str.replace('\\u2015', '-')  # horizontal bar\n",
    "clean_topics = clean_topics.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Original topics count: {len(exploded_topics)}\")\n",
    "print(f\"Unique topics count: {len(clean_topics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61def6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics before cleaning: 22190\n",
      "Topics before cleaning: 22187\n",
      "Topics after cleaning: 22187\n",
      "\n",
      "First 10 cleaned topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                          Generative AI\n",
       "1                               LLM APIs\n",
       "2                     Prompt Engineering\n",
       "3        Artificial General Intelligence\n",
       "4                          AI resilience\n",
       "                      ...               \n",
       "22182                 Narrative Planning\n",
       "22183          Tool-Augmented Generation\n",
       "22184             On-Policy Distillation\n",
       "22185         Post-Training Distillation\n",
       "22186                      Cross-Lingual\n",
       "Name: topics, Length: 22187, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove entries that contain only 'nan' or 'None'\n",
    "print(f\"Topics before cleaning: {len(clean_topics)}\")\n",
    "clean_topics = clean_topics[~clean_topics.str.lower().isin(['nan', 'none'])]\n",
    "clean_topics = clean_topics.dropna()\n",
    "\n",
    "# Reset index after filtering\n",
    "clean_topics = clean_topics.reset_index(drop=True)\n",
    "\n",
    "print(f\"Topics before cleaning: {len(clean_topics)}\")\n",
    "print(f\"Topics after cleaning: {len(clean_topics)}\")\n",
    "print(\"\\nFirst 10 cleaned topics:\")\n",
    "clean_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdc8139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics before cleaning: 22187\n",
      "Topics after cleaning: 22178\n",
      "\n",
      "First 10 cleaned topics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                          generative ai\n",
       "1                               llm apis\n",
       "2                     prompt engineering\n",
       "3        artificial general intelligence\n",
       "4                          ai resilience\n",
       "                      ...               \n",
       "22173                 narrative planning\n",
       "22174          tool-augmented generation\n",
       "22175             on-policy distillation\n",
       "22176         post-training distillation\n",
       "22177                      cross-lingual\n",
       "Name: topics, Length: 22178, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove entries that start with 'None '\n",
    "print(f\"Topics before cleaning: {len(clean_topics)}\")\n",
    "clean_topics1 = clean_topics[~clean_topics.str.startswith('None ', na=False)]\n",
    "clean_topics1 = clean_topics1.reset_index(drop=True)\n",
    "\n",
    "print(f\"Topics after cleaning: {len(clean_topics1)}\")\n",
    "print(\"\\nFirst 10 cleaned topics:\")\n",
    "clean_topics1 = clean_topics1.str.lower().str.strip()\n",
    "clean_topics1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06538a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics before prefix removal: 20159\n",
      "Topics after prefix removal: 20159\n",
      "Unique topics after dedup: 20159\n",
      "Duplicates removed: 0\n",
      "\n",
      "Final clean_topics1 count: 20159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                       generative ai\n",
       "1                            llm apis\n",
       "2                  prompt engineering\n",
       "3     artificial general intelligence\n",
       "4                       ai resilience\n",
       "5              ai-integrated browsers\n",
       "6                       face-scanning\n",
       "7                       ai assistants\n",
       "8                     voice synthesis\n",
       "9                    audio generation\n",
       "10                      image editing\n",
       "11                      llm reasoning\n",
       "12                   pattern matching\n",
       "13                   chain-of-thought\n",
       "14             vision-language models\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted prompt-like prefixes from topics (case-insensitive)\n",
    "unwanted_prefixes = [\n",
    "    'artificial intelligence (ai) skills from the text: ',\n",
    "    'here are the ai-related skills explicitly mentioned or strongly implied in the text: ',\n",
    "    'here are the ai-related skills identified from the text: ',\n",
    "    'here are the ai-related skills mentioned in the text: ',\n",
    "    'here are the ai-related skills mentioned or strongly implied in the text: ',\n",
    "    'here are the distinct ai-related skills mentioned in the text: ',\n",
    "    'here are the identified ai-related skills from the text',\n",
    "    'here are the key ai-related skills identified from the text: ',\n",
    "    'here are the key ai-related technical skills mentioned in the text: ',\n",
    "    'here are the relevant ai-related skills: ',\n",
    "    \"here's a comma-separated list of ai-related skills mentioned in the text: \",\n",
    "    \"here are the ai-related skills mentioned or implied in the text: \",\n",
    "    \"here are the ai-related skills mentioned or strongly implied in the text: \",\n",
    "    \"here are the key ai-related skills mentioned in the text: \",\n",
    "    \"here are the key ai-related skills mentioned or implied in the text: \",\n",
    "    \"here are the key ai-related skills mentioned or strongly implied in the text: \",\n",
    "    \"organized in a comma-separated list: \",\n",
    "    \": \"\n",
    "]\n",
    "\n",
    "print(f\"Topics before prefix removal: {len(clean_topics1)}\")\n",
    "\n",
    "# Apply all replacements (case-insensitive)\n",
    "clean_topics1_no_prefix = clean_topics1.copy()\n",
    "for prefix in unwanted_prefixes:\n",
    "    # Use regex with case-insensitive flag to remove prefix if it appears at the start\n",
    "    clean_topics1_no_prefix = clean_topics1_no_prefix.str.replace(\n",
    "        f'^{re.escape(prefix)}', '', regex=True, case=False\n",
    "    )\n",
    "\n",
    "# Strip any leading/trailing whitespace created by removal\n",
    "clean_topics1_no_prefix = clean_topics1_no_prefix.str.strip()\n",
    "\n",
    "# Drop any duplicates created by prefix removal\n",
    "before_dedup = len(clean_topics1_no_prefix)\n",
    "clean_topics1_no_prefix = clean_topics1_no_prefix.drop_duplicates().reset_index(drop=True)\n",
    "after_dedup = len(clean_topics1_no_prefix)\n",
    "\n",
    "print(f\"Topics after prefix removal: {before_dedup}\")\n",
    "print(f\"Unique topics after dedup: {after_dedup}\")\n",
    "print(f\"Duplicates removed: {before_dedup - after_dedup}\")\n",
    "\n",
    "# Show sample of changes (find topics that were modified)\n",
    "changes_sample = []\n",
    "for orig, cleaned in zip(clean_topics1, clean_topics1_no_prefix):\n",
    "    if orig != cleaned and orig in clean_topics1.values:\n",
    "        # Find if this original still exists in cleaned version\n",
    "        idx_orig = clean_topics1[clean_topics1 == orig].index[0] if orig in clean_topics1.values else None\n",
    "        idx_clean = clean_topics1_no_prefix[clean_topics1_no_prefix == cleaned].index[0] if cleaned in clean_topics1_no_prefix.values else None\n",
    "        if idx_orig is not None and idx_clean is not None and idx_orig < len(clean_topics1_no_prefix):\n",
    "            changes_sample.append((orig, clean_topics1_no_prefix.iloc[idx_orig]))\n",
    "            if len(changes_sample) >= 10:\n",
    "                break\n",
    "\n",
    "if changes_sample:\n",
    "    print(\"\\nSample prefix removals (up to 10):\")\n",
    "    for orig, cleaned in changes_sample:\n",
    "        print(f\"  BEFORE: {orig[:100]}...\")\n",
    "        print(f\"  AFTER:  {cleaned[:100]}...\\n\")\n",
    "\n",
    "# Reassign for downstream pipeline\n",
    "clean_topics1 = clean_topics1_no_prefix.copy()\n",
    "print(f\"\\nFinal clean_topics1 count: {len(clean_topics1)}\")\n",
    "clean_topics1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f123cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique topics before normalization: 20159\n",
      "Unique topics after normalization: 20159\n",
      "Sample changed topics (up to 10):\n",
      "  ORIG: humanity’s last exam\n",
      "  NORM: humanity's last exam\n",
      "\n",
      "  ORIG: τ²-bench telecom\n",
      "  NORM: τ2-bench telecom\n",
      "\n",
      "  ORIG: cognition’s devin ai\n",
      "  NORM: cognition's devin ai\n",
      "\n",
      "  ORIG: google’s coding agent jules\n",
      "  NORM: google's coding agent jules\n",
      "\n",
      "  ORIG: cognition’s devin\n",
      "  NORM: cognition's devin\n",
      "\n",
      "  ORIG: patch n’ pack\n",
      "  NORM: patch n' pack\n",
      "\n",
      "  ORIG: google cloud’s dynamic workload scheduler\n",
      "  NORM: google cloud's dynamic workload scheduler\n",
      "\n",
      "  ORIG: google cloud’s ai hypercomputer\n",
      "  NORM: google cloud's ai hypercomputer\n",
      "\n",
      "  ORIG: nvidia’s open-source software stack\n",
      "  NORM: nvidia's open-source software stack\n",
      "\n",
      "  ORIG: aime’24\n",
      "  NORM: aime'24\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                          generative ai\n",
       "1                               llm apis\n",
       "2                     prompt engineering\n",
       "3        artificial general intelligence\n",
       "4                          ai resilience\n",
       "                      ...               \n",
       "20154          memory-augmented learning\n",
       "20155                 narrative planning\n",
       "20156          tool-augmented generation\n",
       "20157         post-training distillation\n",
       "20158                      cross-lingual\n",
       "Name: topics, Length: 20159, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize punctuation, spaces, and general Unicode forms to ensure consistent UTF-8 friendly text\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Start from clean_topics Series produced earlier\n",
    "normalized_topics = clean_topics1.copy()\n",
    "\n",
    "# 1. Unicode normalization (NFKC) to flatten compatibility characters (e.g., full-width forms)\n",
    "normalized_topics = normalized_topics.apply(lambda x: unicodedata.normalize('NFKC', x) if isinstance(x, str) else x)\n",
    "\n",
    "# 2. Replace various space characters with a regular space\n",
    "SPACE_CHARS = [\n",
    "    '\\u00A0',  # no-break space\n",
    "    '\\u1680', '\\u2000', '\\u2001', '\\u2002', '\\u2003', '\\u2004', '\\u2005', '\\u2006',\n",
    "    '\\u2007', '\\u2008', '\\u2009', '\\u200A', '\\u202F', '\\u205F', '\\u3000'\n",
    "]\n",
    "space_pattern = re.compile('|'.join(SPACE_CHARS))\n",
    "normalized_topics = normalized_topics.str.replace(space_pattern, ' ', regex=True)\n",
    "\n",
    "# 3. Standardize punctuation (commas, colons, semicolons, quotes)\n",
    "PUNCT_MAP = {\n",
    "    '，': ',',  # full-width comma\n",
    "    '､': ',',\n",
    "    '﹐': ',',\n",
    "    '：': ':',  # full-width colon\n",
    "    '；': ';',\n",
    "    '﹔': ';',\n",
    "    '﹕': ':',\n",
    "    '“': '\"', '”': '\"', '‟': '\"', '＂': '\"',\n",
    "    '‘': \"'\", '’': \"'\", '‚': \"'\", '‛': \"'\", '＇': \"'\",\n",
    "    '…': '...',\n",
    "}\n",
    "if PUNCT_MAP:\n",
    "    punct_pattern = re.compile('|'.join(map(re.escape, PUNCT_MAP.keys())))\n",
    "    normalized_topics = normalized_topics.str.replace(punct_pattern, lambda m: PUNCT_MAP[m.group(0)], regex=True)\n",
    "\n",
    "# 4. Collapse multiple spaces to single\n",
    "normalized_topics = normalized_topics.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "# 5. Drop duplicates created by normalization\n",
    "normalized_topics = normalized_topics.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Unique topics before normalization: {len(clean_topics1)}\")\n",
    "print(f\"Unique topics after normalization: {len(normalized_topics)}\")\n",
    "\n",
    "# 6. Quick diff sample\n",
    "changes = []\n",
    "for orig, norm in zip(clean_topics1, normalized_topics):\n",
    "    if orig != norm:\n",
    "        changes.append((orig, norm))\n",
    "        if len(changes) >= 10:\n",
    "            break\n",
    "\n",
    "if changes:\n",
    "    print(\"Sample changed topics (up to 10):\")\n",
    "    for o, n in changes:\n",
    "        print(f\"  ORIG: {o}\\n  NORM: {n}\\n\")\n",
    "else:\n",
    "    print(\"No differences detected in sample.\")\n",
    "\n",
    "\n",
    "\n",
    "normalized_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5edd5cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics before prefix removal: 146730\n",
      "Topics after prefix removal: 146730\n",
      "Topics after prefix removal: 146730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics before prefix removal: 146730\n",
      "Topics after prefix removal: 146730\n",
      "Topics after prefix removal: 146730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                        generative ai\n",
       "0                             llm apis\n",
       "0                   prompt engineering\n",
       "1      artificial general intelligence\n",
       "1                        ai resilience\n",
       "                    ...               \n",
       "402                 prompt engineering\n",
       "402                   prompt injection\n",
       "402                multi-agent systems\n",
       "402                    computer vision\n",
       "402                                nlp\n",
       "Name: topics, Length: 146730, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase normalized topics and remove duplicates\n",
    "normalized_topics_lower = normalized_topics.str.lower().str.strip()\n",
    "\n",
    "before_count = len(normalized_topics_lower)\n",
    "normalized_topics_lower = normalized_topics_lower.drop_duplicates().reset_index(drop=True)\n",
    "normalized_topics_lower = normalized_topics_lower.sort_values().reset_index(drop=True)\n",
    "after_count = len(normalized_topics_lower)\n",
    "\n",
    "print(f\"Topics before lowercasing/dedup: {before_count}\")\n",
    "print(f\"Unique topics after lowercasing/dedup: {after_count}\")\n",
    "\n",
    "# Show sample\n",
    "normalized_topics_lower.head(25)clean_topics2 = clean_topics1.copy()    clean_topics2 = clean_topics2.str.replace("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e41ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7606 groups with multiple spelling variants\n",
      "\n",
      "Sample groups with variants (first 20):\n",
      "\n",
      "Group 1: 11 variants\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "  - .net\n",
      "\n",
      "Group 2: 2 variants\n",
      "  - 000hz\n",
      "  - 000hz\n",
      "\n",
      "Group 3: 5 variants\n",
      "  - 000mah\n",
      "  - 000mah\n",
      "  - 000mah\n",
      "  - 000mah\n",
      "  - 000mah\n",
      "\n",
      "Group 4: 2 variants\n",
      "  - 1-bit inference\n",
      "  - 1-bit inference\n",
      "\n",
      "Group 5: 5 variants\n",
      "  - 1-bit llm\n",
      "  - 1-bit llms\n",
      "  - 1-bit llms\n",
      "  - 1-bit llms\n",
      "  - 1-bit llms\n",
      "\n",
      "Group 6: 6 variants\n",
      "  - 1-bit quantization\n",
      "  - 1-bit quantization\n",
      "  - 1-bit quantization\n",
      "  - 1-bit quantization\n",
      "  - 1-bit quantization\n",
      "  - 1-bit quantization\n",
      "\n",
      "Group 7: 4 variants\n",
      "  - 2-bit quantization\n",
      "  - 2-bit quantization\n",
      "  - 2-bit quantization\n",
      "  - 2-bit quantization\n",
      "\n",
      "Group 8: 3 variants\n",
      "  - 2d animation\n",
      "  - 2d animation\n",
      "  - 2d animation\n",
      "\n",
      "Group 9: 2 variants\n",
      "  - 2d-to-3d conversion\n",
      "  - 2d-to-3d conversion\n",
      "\n",
      "Group 10: 3 variants\n",
      "  - 3\n",
      "  - 3\n",
      "  - 3\n",
      "\n",
      "Group 11: 6 variants\n",
      "  - 3d animation\n",
      "  - 3d animation\n",
      "  - 3d animation\n",
      "  - 3d animation\n",
      "  - 3d animation\n",
      "  - 3d animation\n",
      "\n",
      "Group 12: 12 variants\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "  - 3d asset generation\n",
      "\n",
      "Group 13: 2 variants\n",
      "  - 3d avatar animation\n",
      "  - 3d avatar animation\n",
      "\n",
      "Group 14: 3 variants\n",
      "  - 3d avatar generation\n",
      "  - 3d avatar generation\n",
      "  - 3d avatar generation\n",
      "\n",
      "Group 15: 14 variants\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "  - 3d computer vision\n",
      "\n",
      "Group 16: 2 variants\n",
      "  - 3d content creation\n",
      "  - 3d content creation\n",
      "\n",
      "Group 17: 3 variants\n",
      "  - 3d content generation\n",
      "  - 3d content generation\n",
      "  - 3d content generation\n",
      "\n",
      "Group 18: 3 variants\n",
      "  - 3d convolution\n",
      "  - 3d convolution\n",
      "  - 3d convolution\n",
      "\n",
      "Group 19: 3 variants\n",
      "  - 3d deep learning\n",
      "  - 3d deep learning\n",
      "  - 3d deep learning\n",
      "\n",
      "Group 20: 5 variants\n",
      "  - 3d environment generation\n",
      "  - 3d environment generation\n",
      "  - 3d environment generation\n",
      "  - 3d environment generation\n",
      "  - 3d environment generation\n",
      "\n",
      "Total mappings to create: 696\n",
      "\n",
      "Topics before merging: 146730\n",
      "Topics after merging: 146730\n",
      "Reduced by: 0\n",
      "\n",
      "Example merges (first 15):\n",
      "  1-bit llms → 1-bit llm\n",
      "  3d generative modeling → 3d generative models\n",
      "  a2a protocols → a2a protocol\n",
      "  access controls → access control\n",
      "  action agents → action agent\n",
      "  actions → action\n",
      "  activation functions → activation function\n",
      "  adversarial inputs → adversarial input\n",
      "  adversarial prompting → adversarial prompts\n",
      "  agent architectures → agent architecture\n",
      "  agent communication protocols → agent communication protocol\n",
      "  agent development kits → agent development kit\n",
      "  agent frameworks → agent framework\n",
      "  agent loops → agent loop\n",
      "  agent sdks → agent sdk\n",
      "\n",
      "================================================================================\n",
      "Total topics: 146730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                              \n",
       "1                          .net\n",
       "2                          .net\n",
       "3                          .net\n",
       "4                          .net\n",
       "                  ...          \n",
       "146725              zmp control\n",
       "146726          zombie startups\n",
       "146727    zone-based navigation\n",
       "146728                     zoom\n",
       "146729         τ2-bench telecom\n",
       "Name: topics, Length: 146730, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and merge semantically similar topics with spelling variations\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_for_grouping(topic):\n",
    "    \"\"\"Apply aggressive normalization to find similar topics.\"\"\"\n",
    "    if pd.isna(topic) or not isinstance(topic, str):\n",
    "        return \"\"\n",
    "    \n",
    "    s = topic.lower().strip()\n",
    "    \n",
    "    # Remove plural 's' at end of words (but preserve 'oss', 'sass', etc.)\n",
    "    s = re.sub(r'\\b(\\w{3,})s\\b', r'\\1', s)\n",
    "    \n",
    "    # Normalize common verb forms: testing->test, learning->learn, etc.\n",
    "    s = re.sub(r'\\b(\\w+)ing\\b', r'\\1', s)\n",
    "    s = re.sub(r'\\b(\\w+)ed\\b', r'\\1', s)\n",
    "    \n",
    "    # Remove hyphens and slashes for comparison (but keep in display)\n",
    "    # We'll use this for grouping key only\n",
    "    key = s.replace('-', '').replace('/', '').replace('_', '')\n",
    "    key = re.sub(r'\\s+', ' ', key).strip()\n",
    "    \n",
    "    return key\n",
    "\n",
    "# Build a mapping from normalized key to list of original topics\n",
    "topic_groups = defaultdict(list)\n",
    "\n",
    "for topic in clean_topics2:\n",
    "    if pd.notna(topic):\n",
    "        key = normalize_for_grouping(topic)\n",
    "        if key:  # Skip empty keys\n",
    "            topic_groups[key].append(topic)\n",
    "\n",
    "# Find groups with multiple variants\n",
    "multi_variants = {k: v for k, v in topic_groups.items() if len(v) > 1}\n",
    "print(f\"Found {len(multi_variants)} groups with multiple spelling variants\")\n",
    "\n",
    "# Show sample groups\n",
    "print(\"\\nSample groups with variants (first 20):\")\n",
    "for i, (key, variants) in enumerate(sorted(multi_variants.items())[:20]):\n",
    "    print(f\"\\nGroup {i+1}: {len(variants)} variants\")\n",
    "    for v in sorted(variants):\n",
    "        print(f\"  - {v}\")\n",
    "\n",
    "# Create a canonical mapping: choose shortest variant as canonical\n",
    "canonical_map = {}\n",
    "for key, variants in topic_groups.items():\n",
    "    if len(variants) > 1:\n",
    "        # Choose shortest, or alphabetically first if same length\n",
    "        canonical = min(variants, key=lambda x: (len(x), x))\n",
    "        for variant in variants:\n",
    "            if variant != canonical:\n",
    "                canonical_map[variant] = canonical\n",
    "\n",
    "print(f\"\\nTotal mappings to create: {len(canonical_map)}\")\n",
    "\n",
    "# Apply the canonical mapping\n",
    "clean_topics3 = clean_topics2.map(lambda x: canonical_map.get(x, x))\n",
    "clean_topics3 = clean_topics3.sort_values().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTopics before merging: {len(clean_topics2)}\")\n",
    "print(f\"Topics after merging: {len(clean_topics3)}\")\n",
    "print(f\"Reduced by: {len(clean_topics2) - len(clean_topics3)}\")\n",
    "\n",
    "# Show some examples of what was merged\n",
    "print(\"\\nExample merges (first 15):\")\n",
    "for i, (variant, canonical) in enumerate(sorted(canonical_map.items())[:15]):\n",
    "    print(f\"  {variant} → {canonical}\")\n",
    "\n",
    "print(\"\\n================================================================================\")\n",
    "print(\"Total topics:\", len(clean_topics3))\n",
    "clean_topics3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9fba47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics before filtering: 146730\n",
      "Topics after filtering:  146701\n",
      "Removed: 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                              \n",
       "19              1-bit inference\n",
       "20              1-bit inference\n",
       "21                    1-bit llm\n",
       "22                    1-bit llm\n",
       "                  ...          \n",
       "146725              zmp control\n",
       "146726          zombie startups\n",
       "146727    zone-based navigation\n",
       "146728                     zoom\n",
       "146729         τ2-bench telecom\n",
       "Name: topics, Length: 146701, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove topics containing any of the unwanted substrings (case-insensitive)\n",
    "unwanted_substrings = [\n",
    "    \"rather than technical implementation or development skills\",\n",
    "    \"but does not explicitly mention\",\n",
    "    \"and talent management in the entertainment industry\",\n",
    "    \"but does not contain\",\n",
    "    \"it doesn't explicitly\",\n",
    "    \"it focuses on user behavior\",\n",
    "    \"midjourney the list represents skills mentioned explicitly\",\n",
    "    \"these don't constitute\",\n",
    "    \".net\",\n",
    "    \"000hz\",\n",
    "    \"00hz\",\n",
    "    \"000mah\"\n",
    "]\n",
    "\n",
    "# Build a single regex pattern joined by alternation (no inline flags)\n",
    "# Use re.IGNORECASE in str.contains for case-insensitive matching\n",
    "pattern = '|'.join([re.escape(s) for s in unwanted_substrings])\n",
    "\n",
    "before_len = len(clean_topics3)\n",
    "mask_remove = clean_topics3.str.contains(pattern, regex=True, case=False, na=False)\n",
    "filtered_topics = clean_topics3[~mask_remove]\n",
    "after_len = len(filtered_topics)\n",
    "\n",
    "print(f\"Topics before filtering: {before_len}\")\n",
    "print(f\"Topics after filtering:  {after_len}\")\n",
    "print(f\"Removed: {before_len - after_len}\")\n",
    "\n",
    "# Reassign merged_topics to filtered result for downstream cells\n",
    "clean_topics4 = filtered_topics\n",
    "\n",
    "clean_topics4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9aff2a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 146701  topics\n",
      "  Found pair: 'ai' <-> 'artificial intelligence'\n",
      "  Found pair: 'ml' <-> 'machine learning'\n",
      "  Found pair: 'nlp' <-> 'natural language processing'\n",
      "  Found pair: 'cnn' <-> 'convolutional neural network'\n",
      "  Found pair: 'rnn' <-> 'recurrent neural network'\n",
      "  Found pair: 'lstm' <-> 'long short-term memory'\n",
      "  Found pair: 'vae' <-> 'variational autoencoder'\n",
      "  Found pair: 'rag' <-> 'retrieval augmented generation'\n",
      "  Found pair: 'llm' <-> 'large language model'\n",
      "  Found pair: 'asr' <-> 'automatic speech recognition'\n",
      "  Found pair: 'tts' <-> 'text-to-speech'\n",
      "  Found pair: 'ocr' <-> 'optical character recognition'\n",
      "  Found pair: 'mlops' <-> 'machine learning operations'\n",
      "  Found pair: 'aws' <-> 'amazon web services'\n",
      "  Found pair: 'gcp' <-> 'google cloud platform'\n",
      "\n",
      "Detected 349 abbreviation-full form pairs\n",
      "\n",
      "Created 676 merge mappings\n",
      "\n",
      "Sample canonical mappings (first 15):\n",
      "  '128k' → 'long-context llms (128k)'\n",
      "  '4-bit' → 'quantization (4-bit)'\n",
      "  '4-bit quantization' → '4-bit quantization (mxfp4)'\n",
      "  '8-bit' → 'model quantization (8-bit)'\n",
      "  'a2a' → 'agent2agent (a2a)'\n",
      "  'a2i' → 'amazon augmented ai (a2i)'\n",
      "  'accelerated processing kit' → 'accelerated processing kit (xpk)'\n",
      "  'access control' → 'access control (acls)'\n",
      "  'accurate quantized training' → 'accurate quantized training (aqt)'\n",
      "  'acls' → 'access control (acls)'\n",
      "  'acp' → 'agent communication protocol (acp)'\n",
      "  'activation-aware weight quantization' → 'activation-aware weight quantization (awq)'\n",
      "  'active noise cancellation' → 'active noise cancellation (anc)'\n",
      "  'adas' → 'advanced driver assistance systems (adas)'\n",
      "  'adk' → 'agent development kit (adk)'\n",
      "\n",
      "================================================================================\n",
      "Topics before merging semantic duplicates: 146701\n",
      "Topics after merging:                      146701\n",
      "Reduced by:                                 0\n",
      "================================================================================\n",
      "\n",
      "Final clean_topics6 count: 146701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                \n",
       "1                 1-bit inference\n",
       "2                 1-bit inference\n",
       "3                       1-bit llm\n",
       "4                       1-bit llm\n",
       "5                       1-bit llm\n",
       "6                       1-bit llm\n",
       "7                       1-bit llm\n",
       "8           1-bit neural networks\n",
       "9              1-bit quantization\n",
       "10             1-bit quantization\n",
       "11             1-bit quantization\n",
       "12             1-bit quantization\n",
       "13             1-bit quantization\n",
       "14             1-bit quantization\n",
       "15             1-bit transformers\n",
       "16    1.5b-parameter llm backbone\n",
       "17            128k context window\n",
       "18                             1u\n",
       "19             2-bit quantization\n",
       "20             2-bit quantization\n",
       "21             2-bit quantization\n",
       "22             2-bit quantization\n",
       "23                         2.4ghz\n",
       "24            2.5d representation\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify and merge semantic duplicates: abbreviations + full forms\n",
    "# Strategy: detect common AI abbreviation patterns and their expansions\n",
    "clean_topics5 = clean_topics4.copy()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Known abbreviation mappings (expandable)\n",
    "KNOWN_ABBREV_MAP = {\n",
    "    'ai': 'artificial intelligence',\n",
    "    'ml': 'machine learning',\n",
    "    'nlp': 'natural language processing',\n",
    "    'cv': 'computer vision',\n",
    "    'dl': 'deep learning',\n",
    "    'rl': 'reinforcement learning',\n",
    "    'gan': 'generative adversarial network',\n",
    "    'gans': 'generative adversarial networks',\n",
    "    'cnn': 'convolutional neural network',\n",
    "    'cnns': 'convolutional neural networks',\n",
    "    'rnn': 'recurrent neural network',\n",
    "    'rnns': 'recurrent neural networks',\n",
    "    'lstm': 'long short-term memory',\n",
    "    'gru': 'gated recurrent unit',\n",
    "    'bert': 'bidirectional encoder representations from transformers',\n",
    "    'gpt': 'generative pre-trained transformer',\n",
    "    'vae': 'variational autoencoder',\n",
    "    'api': 'application programming interface',\n",
    "    'apis': 'application programming interfaces',\n",
    "    'sdk': 'software development kit',\n",
    "    'rag': 'retrieval augmented generation',\n",
    "    'llm': 'large language model',\n",
    "    'llms': 'large language models',\n",
    "    'asr': 'automatic speech recognition',\n",
    "    'tts': 'text-to-speech',\n",
    "    'ocr': 'optical character recognition',\n",
    "    'roi': 'return on investment',\n",
    "    'kpi': 'key performance indicator',\n",
    "    'kpis': 'key performance indicators',\n",
    "    'mlops': 'machine learning operations',\n",
    "    'devops': 'development operations',\n",
    "    'cicd': 'continuous integration continuous deployment',\n",
    "    'ci/cd': 'continuous integration continuous deployment',\n",
    "    'aws': 'amazon web services',\n",
    "    'gcp': 'google cloud platform',\n",
    "    'sql': 'structured query language',\n",
    "    'nosql': 'non-relational database',\n",
    "    'etl': 'extract transform load',\n",
    "    'ui': 'user interface',\n",
    "    'ux': 'user experience',\n",
    "    'saas': 'software as a service',\n",
    "    'paas': 'platform as a service',\n",
    "    'iaas': 'infrastructure as a service',\n",
    "}\n",
    "\n",
    "print(f\"Starting with {len(clean_topics4)}  topics\")\n",
    "\n",
    "# Build a mapping of detected abbreviation-full form pairs\n",
    "abbrev_to_full = {}\n",
    "full_to_abbrev = {}\n",
    "\n",
    "topics_set = set(clean_topics5)\n",
    "\n",
    "# 1. Check known abbreviations\n",
    "for abbrev, full_form in KNOWN_ABBREV_MAP.items():\n",
    "    abbrev_clean = abbrev.lower().strip()\n",
    "    full_clean = full_form.lower().strip()\n",
    "    \n",
    "    if abbrev_clean in topics_set and full_clean in topics_set:\n",
    "        # Both exist - merge them\n",
    "        abbrev_to_full[abbrev_clean] = full_clean\n",
    "        full_to_abbrev[full_clean] = abbrev_clean\n",
    "        print(f\"  Found pair: '{abbrev_clean}' <-> '{full_clean}'\")\n",
    "    elif abbrev_clean in topics_set:\n",
    "        # Only abbrev exists, but we know the full form - keep abbrev as-is for now\n",
    "        pass\n",
    "    elif full_clean in topics_set:\n",
    "        # Only full form exists - keep it\n",
    "        pass\n",
    "\n",
    "# 2. Detect patterns like \"full form (abbrev)\" or \"abbrev (full form)\" already in data\n",
    "pattern_with_parens = re.compile(r'^(.+?)\\s*\\(([^)]+)\\)$')\n",
    "for topic in topics_set:\n",
    "    match = pattern_with_parens.match(topic)\n",
    "    if match:\n",
    "        part1 = match.group(1).strip().lower()\n",
    "        part2 = match.group(2).strip().lower()\n",
    "        \n",
    "        # Heuristic: shorter part is likely abbreviation\n",
    "        if len(part2) <= 5 and len(part1) > len(part2):\n",
    "            # part2 is abbreviation\n",
    "            if part2 in topics_set or part1 in topics_set:\n",
    "                abbrev_to_full[part2] = part1\n",
    "                full_to_abbrev[part1] = part2\n",
    "        elif len(part1) <= 5 and len(part2) > len(part1):\n",
    "            # part1 is abbreviation\n",
    "            if part1 in topics_set or part2 in topics_set:\n",
    "                abbrev_to_full[part1] = part2\n",
    "                full_to_abbrev[part2] = part1\n",
    "\n",
    "print(f\"\\nDetected {len(abbrev_to_full)} abbreviation-full form pairs\")\n",
    "\n",
    "# 3. Create canonical mapping: merge both into \"full form (abbrev)\"\n",
    "canonical_map = {}\n",
    "\n",
    "for abbrev, full in abbrev_to_full.items():\n",
    "    canonical = f\"{full} ({abbrev})\"\n",
    "    # Map both abbreviation and full form to canonical\n",
    "    canonical_map[abbrev] = canonical\n",
    "    canonical_map[full] = canonical\n",
    "    \n",
    "print(f\"\\nCreated {len(canonical_map)} merge mappings\")\n",
    "\n",
    "# Sample mappings\n",
    "print(\"\\nSample canonical mappings (first 15):\")\n",
    "for i, (orig, canon) in enumerate(sorted(canonical_map.items())[:15]):\n",
    "    print(f\"  '{orig}' → '{canon}'\")\n",
    "\n",
    "# 4. Apply canonical mapping to topic_items\n",
    "before_count = len(clean_topics5)\n",
    "clean_topics6 = clean_topics5.map(lambda x: canonical_map.get(x.lower().strip(), x) if pd.notna(x) else x)\n",
    "clean_topics6 = clean_topics6.sort_values().reset_index(drop=True)\n",
    "after_count = len(clean_topics6)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Topics before merging semantic duplicates: {before_count}\")\n",
    "print(f\"Topics after merging:                      {after_count}\")\n",
    "print(f\"Reduced by:                                 {before_count - after_count}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Show examples of what changed\n",
    "merged_examples = []\n",
    "for orig in clean_topics6.head(100):\n",
    "    if pd.notna(orig):\n",
    "        canonical = canonical_map.get(orig.lower().strip())\n",
    "        if canonical and canonical != orig:\n",
    "            merged_examples.append((orig, canonical))\n",
    "            if len(merged_examples) >= 10:\n",
    "                break\n",
    "\n",
    "if merged_examples:\n",
    "    print(\"\\nExample merges (up to 10):\")\n",
    "    for orig, merged in merged_examples:\n",
    "        print(f\"  '{orig}' → '{merged}'\")\n",
    "\n",
    "\n",
    "print(f\"\\nFinal clean_topics6 count: {len(clean_topics6)}\")\n",
    "clean_topics6.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8247b71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame with 146701 topics\n",
      "Rows after removing empty topics: 146700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-bit inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-bit inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146695</th>\n",
       "      <td>zmp control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146696</th>\n",
       "      <td>zombie startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146697</th>\n",
       "      <td>zone-based navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146698</th>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146699</th>\n",
       "      <td>τ2-bench telecom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        topic\n",
       "0             1-bit inference\n",
       "1             1-bit inference\n",
       "2                   1-bit llm\n",
       "3                   1-bit llm\n",
       "4                   1-bit llm\n",
       "...                       ...\n",
       "146695            zmp control\n",
       "146696        zombie startups\n",
       "146697  zone-based navigation\n",
       "146698                   zoom\n",
       "146699       τ2-bench telecom\n",
       "\n",
       "[146700 rows x 1 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove topics containing any of the unwanted substrings (case-insensitive)\n",
    "unwanted_substrings = [\n",
    "    \"rather than technical implementation or development skills\",\n",
    "    \"but does not explicitly mention\",\n",
    "    \"and talent management in the entertainment industry\",\n",
    "    \"but does not contain\",\n",
    "    \"it doesn't explicitly\",\n",
    "    \"it focuses on user behavior\",\n",
    "    \"midjourney the list represents skills mentioned explicitly\",\n",
    "    \"these don't constitute\"\n",
    "]\n",
    "\n",
    "# Build a single regex pattern joined by alternation (no inline flags)\n",
    "# Use re.IGNORECASE in str.contains for case-insensitive matching\n",
    "pattern = '|'.join([re.escape(s) for s in unwanted_substrings])\n",
    "\n",
    "before_len = len(merged_topics)\n",
    "mask_remove = merged_topics.str.contains(pattern, regex=True, case=False, na=False)\n",
    "filtered_topics = merged_topics[~mask_remove]\n",
    "after_len = len(filtered_topics)\n",
    "\n",
    "print(f\"Topics before filtering: {before_len}\")\n",
    "print(f\"Topics after filtering:  {after_len}\")\n",
    "print(f\"Removed: {before_len - after_len}\")\n",
    "\n",
    "# Show removed samples (if any)\n",
    "removed = merged_topics[mask_remove]\n",
    "if len(removed):\n",
    "    print(\"\\nRemoved topics (up to 15):\")\n",
    "    for t in removed.head(15):\n",
    "        print(\" -\", t)\n",
    "else:\n",
    "    print(\"No topics matched removal criteria.\")\n",
    "\n",
    "# Reassign merged_topics to filtered result for downstream cells\n",
    "merged_topics = filtered_topics.reset_index(drop=True)\n",
    "\n",
    "# Recompute multiword_topics after filtering (keep threshold consistent)\n",
    "words = 4\n",
    "multiword_topics = (\n",
    "    merged_topics\n",
    "        .dropna()\n",
    "        .loc[merged_topics.str.strip().str.split().str.len() > words]\n",
    "        .sort_values()\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "print(f\"\\nRecomputed multiword topics (> {words} words): {len(multiword_topics)}\")\n",
    "\n",
    "merged_topics.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0020a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique topics: 19011\n",
      "\n",
      "Top 20 topics by frequency:\n",
      "\n",
      " 1. prompt engineering  -> 3255\n",
      " 2. natural language processing (nlp)  -> 2996\n",
      " 3. computer vision  -> 2611\n",
      " 4. large language model (llm)  -> 2569\n",
      " 5. llm api  -> 2445\n",
      " 6. retrieval-augmented generation (rag)  -> 2180\n",
      " 7. vector search  -> 1585\n",
      " 8. reinforcement learning (ppo)  -> 1401\n",
      " 9. finetuning  -> 1390\n",
      "10. generative ai (image)  -> 1244\n",
      "11. langchain  -> 1164\n",
      "12. image generation  -> 1024\n",
      "13. pytorch  -> 994\n",
      "14. quantization (int8)  -> 958\n",
      "15. machine learning (ml)  -> 890\n",
      "16. code generation  -> 844\n",
      "17. conversational ai  -> 778\n",
      "18. ai agent  -> 765\n",
      "19. memory-efficient training  -> 749\n",
      "20. low-rank adaptation (lora)  -> 724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique topics: 19011\n",
      "\n",
      "Top 20 topics by frequency:\n",
      "\n",
      " 1. prompt engineering  -> 3255\n",
      " 2. natural language processing (nlp)  -> 2996\n",
      " 3. computer vision  -> 2611\n",
      " 4. large language model (llm)  -> 2569\n",
      " 5. llm api  -> 2445\n",
      " 6. retrieval-augmented generation (rag)  -> 2180\n",
      " 7. vector search  -> 1585\n",
      " 8. reinforcement learning (ppo)  -> 1401\n",
      " 9. finetuning  -> 1390\n",
      "10. generative ai (image)  -> 1244\n",
      "11. langchain  -> 1164\n",
      "12. image generation  -> 1024\n",
      "13. pytorch  -> 994\n",
      "14. quantization (int8)  -> 958\n",
      "15. machine learning (ml)  -> 890\n",
      "16. code generation  -> 844\n",
      "17. conversational ai  -> 778\n",
      "18. ai agent  -> 765\n",
      "19. memory-efficient training  -> 749\n",
      "20. low-rank adaptation (lora)  -> 724\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 coverage of all occurrences: 20.84%\n"
     ]
    }
   ],
   "source": [
    "# Frequency analysis of cleaned topics (top 20 + histogram)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if 'df_all_items' not in globals():\n",
    "    raise RuntimeError(\"DataFrame 'df_all_items' not found. Ensure previous cell creating it has run.\")\n",
    "if 'topic' not in df_all_items.columns:\n",
    "    raise ValueError(\"Expected column 'topic' in df_all_items.\")\n",
    "\n",
    "# Compute frequencies\n",
    "freq_series = df_all_items['topic'].value_counts()\n",
    "\n",
    "print(f\"Total unique topics: {len(freq_series)}\")\n",
    "print(\"\\nTop 20 topics by frequency:\\n\")\n",
    "Top20 = freq_series.head(20).reset_index()\n",
    "Top20.columns = ['topic','count']\n",
    "for i, row in Top20.iterrows():\n",
    "    print(f\"{i+1:2d}. {row['topic']}  -> {row['count']}\")\n",
    "\n",
    "# Display DataFrame of top 20\n",
    "Top20\n",
    "\n",
    "# Histogram of frequency distribution (log scale on y for skewed counts)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(freq_series.values, binwidth=10)\n",
    "plt.title('Topic Frequency Distribution')\n",
    "plt.xlabel('Occurrences per topic')\n",
    "plt.ylabel('Count of topics')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: cumulative coverage of top N\n",
    "total = freq_series.sum()\n",
    "cumulative = freq_series.head(20).sum()\n",
    "print(f\"\\nTop 20 coverage of all occurrences: {cumulative/total:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbb14fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total topics: 19452\n",
      "Topics with >4 words: 263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         advanced data analysis (code interpreter)\n",
       "1         advanced driver assistance systems (adas)\n",
       "2                     agent to agent (a2a) protocol\n",
       "3                            agentic ai / ai agents\n",
       "4                ai in domain specific applications\n",
       "                           ...                     \n",
       "258           web application development (with ai)\n",
       "259    web application firewall (waf) configuration\n",
       "260                web crawling for llm pretraining\n",
       "261                     web ui development (for ai)\n",
       "262            zero-shot chain of thought prompting\n",
       "Name: topics, Length: 263, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List topics consisting of more than X words)\n",
    "words = 4\n",
    "multiword_topics = (\n",
    "    merged_topics\n",
    "        .dropna()\n",
    "        .loc[merged_topics.str.strip().str.split().str.len() > words]\n",
    "        .sort_values()\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "print(f\"Total topics: {len(merged_topics)}\")\n",
    "print(f\"Topics with >{words} words: {len(multiword_topics)}\")\n",
    "multiword_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3ffb1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-bit inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-bit inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146695</th>\n",
       "      <td>zmp control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146696</th>\n",
       "      <td>zombie startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146697</th>\n",
       "      <td>zone-based navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146698</th>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146699</th>\n",
       "      <td>τ2-bench telecom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        topic\n",
       "0             1-bit inference\n",
       "1             1-bit inference\n",
       "2                   1-bit llm\n",
       "3                   1-bit llm\n",
       "4                   1-bit llm\n",
       "...                       ...\n",
       "146695            zmp control\n",
       "146696        zombie startups\n",
       "146697  zone-based navigation\n",
       "146698                   zoom\n",
       "146699       τ2-bench telecom\n",
       "\n",
       "[146700 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ee9b0",
   "metadata": {},
   "source": [
    "## Filter f >=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de016627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering topics with frequency < 2...\n",
      "Rows removed: 11553\n",
      "Unique topics removed: 11553\n",
      "Remaining rows: 135147\n",
      "Remaining unique topics: 7458\n",
      "\n",
      "Top 20 topics after filtering (freq>=2):\n",
      "\n",
      " 1. prompt engineering  -> 3255\n",
      " 2. natural language processing (nlp)  -> 2996\n",
      " 3. computer vision  -> 2611\n",
      " 4. large language model (llm)  -> 2569\n",
      " 5. llm api  -> 2445\n",
      " 6. retrieval-augmented generation (rag)  -> 2180\n",
      " 7. vector search  -> 1585\n",
      " 8. reinforcement learning (ppo)  -> 1401\n",
      " 9. finetuning  -> 1390\n",
      "10. generative ai (image)  -> 1244\n",
      "11. langchain  -> 1164\n",
      "12. image generation  -> 1024\n",
      "13. pytorch  -> 994\n",
      "14. quantization (int8)  -> 958\n",
      "15. machine learning (ml)  -> 890\n",
      "16. code generation  -> 844\n",
      "17. conversational ai  -> 778\n",
      "18. ai agent  -> 765\n",
      "19. memory-efficient training  -> 749\n",
      "20. low-rank adaptation (lora)  -> 724\n",
      "21. multi-agent system  -> 713\n",
      "22. model deployment  -> 673\n",
      "23. video generation  -> 672\n",
      "24. stable diffusion (sdxl)  -> 662\n",
      "25. diffusion model  -> 649\n",
      "26. multimodal ai  -> 647\n",
      "27. gpu programming (cuda)  -> 645\n",
      "28. machine learning operations (mlops)  -> 629\n",
      "29. model evaluation  -> 628\n",
      "30. embedding  -> 623\n",
      "31. model quantization (qlora)  -> 574\n",
      "32. transformer  -> 546\n",
      "33. multimodal model  -> 527\n",
      "34. ai safety  -> 526\n",
      "35. hugging face (hf)  -> 523\n",
      "36. text-to-speech (t2s)  -> 513\n",
      "37. distributed training  -> 492\n",
      "38. langgraph  -> 485\n",
      "39. speech recognition  -> 481\n",
      "40. edge ai  -> 467\n",
      "41. ai regulation focus  -> 466\n",
      "42. ai regulation balance  -> 466\n",
      "43. ai regulation alignment  -> 465\n",
      "44. robotics  -> 462\n",
      "45. llamaindex  -> 460\n",
      "46. vision-language model  -> 456\n",
      "47. gpu programming (rocm)  -> 442\n",
      "48. deep learning (audio)  -> 442\n",
      "49. optical character recognition (ocr)  -> 439\n",
      "50. model training  -> 422\n",
      "51. api integration  -> 422\n",
      "52. inference optimization  -> 415\n",
      "53. vllm  -> 402\n",
      "54. ai ethics  -> 387\n",
      "55. python  -> 381\n",
      "56. benchmarks  -> 377\n",
      "57. model format conversion (gguf)  -> 356\n",
      "58. image classification  -> 353\n",
      "59. tensorflow  -> 353\n",
      "60. llama.cpp  -> 351\n",
      "61. reinforcement learning from human feedback (rlhf)  -> 329\n",
      "62. model optimization  -> 320\n",
      "63. tokenization  -> 317\n",
      "64. function calling  -> 317\n",
      "65. semantic search  -> 306\n",
      "66. information retrieval  -> 305\n",
      "67. gpu optimization  -> 304\n",
      "68. object detection (yolo)  -> 303\n",
      "69. attention mechanism  -> 296\n",
      "70. synthetic data generation  -> 292\n",
      "71. agentic ai  -> 279\n",
      "72. model compression  -> 278\n",
      "73. transformer architecture  -> 276\n",
      "74. ai governance  -> 275\n",
      "75. vector database  -> 272\n",
      "76. rag (retrieval-augmented generation)  -> 267\n",
      "77. model serving  -> 265\n",
      "78. neural network  -> 265\n",
      "79. foundation model  -> 246\n",
      "80. mixture of experts (moe)  -> 246\n",
      "81. text-to-video (t2v)  -> 242\n",
      "82. mixture-of-experts (moe)  -> 240\n",
      "83. comfyui  -> 233\n",
      "84. agent development  -> 233\n",
      "85. mixture of experts  -> 233\n",
      "86. model distillation  -> 230\n",
      "87. amazon bedrock  -> 229\n",
      "88. image editing  -> 227\n",
      "89. explainable ai (xai)  -> 224\n",
      "90. multimodal  -> 222\n",
      "91. data engineering  -> 221\n",
      "92. long-context models  -> 213\n",
      "93. ollama  -> 212\n",
      "94. triton  -> 212\n",
      "95. automatic speech recognition (asr)  -> 209\n",
      "96. autonomous agents  -> 208\n",
      "97. model inference  -> 205\n",
      "98. chatgpt  -> 204\n",
      "99. voice cloning  -> 203\n",
      "100. tool use  -> 200\n",
      "101. content moderation  -> 199\n",
      "102. docker  -> 195\n",
      "103. instruction tuning  -> 193\n",
      "104. openai api  -> 193\n",
      "105. model finetuning  -> 193\n",
      "106. ai security  -> 192\n",
      "107. text-to-image (t2i)  -> 191\n",
      "108. on-device ai  -> 191\n",
      "109. apple's ml framework (mlx)  -> 190\n",
      "110. personalization  -> 190\n",
      "111. human-in-the-loop (hitl)  -> 188\n",
      "112. agent orchestration  -> 187\n",
      "113. chain-of-thought  -> 180\n",
      "114. speech synthesis  -> 179\n",
      "115. on-device inference  -> 178\n",
      "116. responsible ai  -> 178\n",
      "117. pretraining  -> 177\n",
      "118. llama-3 (llama)  -> 177\n",
      "119. text generation  -> 176\n",
      "120. controlnet  -> 176\n",
      "121. reasoning  -> 175\n",
      "122. sensor fusion  -> 174\n",
      "123. audio processing  -> 173\n",
      "124. text-to-image generation  -> 172\n",
      "125. model benchmarking  -> 170\n",
      "126. chatbot development  -> 170\n",
      "127. anomaly detection  -> 170\n",
      "128. dataset curation  -> 168\n",
      "129. gemini  -> 167\n",
      "130. knowledge graph  -> 163\n",
      "131. speech-to-text (s2t)  -> 163\n",
      "132. model monitoring  -> 161\n",
      "133. llm evaluation  -> 160\n",
      "134. dall·e  -> 159\n",
      "135. ai alignment  -> 159\n",
      "136. image processing  -> 156\n",
      "137. audio generation  -> 152\n",
      "138. midjourney  -> 152\n",
      "139. vertex ai  -> 151\n",
      "140. data curation (drps)  -> 148\n",
      "141. kubernetes (gke)  -> 147\n",
      "142. speculative decoding  -> 146\n",
      "143. multilingual nlp  -> 146\n",
      "144. hardware acceleration (gpu)  -> 144\n",
      "145. document understanding  -> 144\n",
      "146. recommender systems  -> 143\n",
      "147. gpu acceleration (h100)  -> 143\n",
      "148. gpu computing  -> 141\n",
      "149. tool integration  -> 140\n",
      "150. multimodal learning  -> 139\n",
      "151. text summarization  -> 139\n",
      "152. context engineering  -> 138\n",
      "153. monitoring (tpu)  -> 138\n",
      "154. flashattention  -> 137\n",
      "155. text-to-video generation  -> 136\n",
      "156. flash attention  -> 135\n",
      "157. observability (ai/ml)  -> 135\n",
      "158. chain-of-thought prompting  -> 134\n",
      "159. summarization  -> 134\n",
      "160. realtime inference  -> 133\n",
      "161. image-to-video (i2v)  -> 133\n",
      "162. video understanding  -> 133\n",
      "163. webgpu  -> 132\n",
      "164. information extraction  -> 131\n",
      "165. recommendation system  -> 131\n",
      "166. knowledge distillation  -> 130\n",
      "167. web scraping  -> 129\n",
      "168. machine translation (mt)  -> 129\n",
      "169. supervised finetuning  -> 128\n",
      "170. data governance  -> 128\n",
      "171. dspy  -> 128\n",
      "172. performance optimization  -> 124\n",
      "173. model (clip)  -> 123\n",
      "174. programming language (mojo)  -> 122\n",
      "175. kserve  -> 120\n",
      "176. data privacy  -> 120\n",
      "177. language model  -> 120\n",
      "178. predictive model  -> 118\n",
      "179. hugging face transformers  -> 118\n",
      "180. hallucination mitigation  -> 118\n",
      "181. data analysis  -> 118\n",
      "182. embedded systems  -> 117\n",
      "183. ai infrastructure  -> 117\n",
      "184. tensor parallelism (tp)  -> 116\n",
      "185. llm training  -> 116\n",
      "186. rerank  -> 115\n",
      "187. reasoning and acting (react)  -> 115\n",
      "188. text-to-speech (tts)  -> 115\n",
      "189. data preprocessing  -> 115\n",
      "190. tool calls  -> 114\n",
      "191. red teaming  -> 114\n",
      "192. model context protocol (mcp)  -> 112\n",
      "193. cloud computing (azure)  -> 112\n",
      "194. zero-shot learning  -> 111\n",
      "195. natural language understanding (nlu)  -> 111\n",
      "196. sentiment analysis  -> 111\n",
      "197. long-context llms (128k)  -> 110\n",
      "198. on-device machine learning  -> 109\n",
      "199. model merging  -> 109\n",
      "200. agent framework  -> 108\n",
      "201. data visualization  -> 106\n",
      "202. few-shot learning  -> 106\n",
      "203. model parallelism  -> 105\n",
      "204. generative models  -> 105\n",
      "205. reward model  -> 104\n",
      "206. jax  -> 103\n",
      "207. langsmith  -> 103\n",
      "208. multi-gpu training  -> 101\n",
      "209. image captioning  -> 101\n",
      "210. model conversion (onnx)  -> 100\n",
      "211. numpy  -> 100\n",
      "212. music generation  -> 99\n",
      "213. keras  -> 99\n",
      "214. terminal usage (ai)  -> 98\n",
      "215. image segmentation  -> 98\n",
      "216. chatbot  -> 98\n",
      "217. llm finetuning  -> 97\n",
      "218. inference  -> 97\n",
      "219. time series analysis  -> 97\n",
      "220. amazon sagemaker  -> 97\n",
      "221. aws lambda  -> 96\n",
      "222. feature engineering  -> 96\n",
      "223. api development  -> 95\n",
      "224. ai agent development  -> 95\n",
      "225. hyperparameter tuning  -> 94\n",
      "226. context window management  -> 94\n",
      "227. video processing  -> 94\n",
      "228. quantization (fp8)  -> 94\n",
      "229. lm studio  -> 93\n",
      "230. natural language generation (nlg)  -> 93\n",
      "231. google gemini  -> 92\n",
      "232. llm inference  -> 92\n",
      "233. gradio  -> 92\n",
      "234. question answering  -> 91\n",
      "235. high-performance computing  -> 91\n",
      "236. deepfake detection  -> 90\n",
      "237. autonomous driving  -> 90\n",
      "238. text classification  -> 89\n",
      "239. faiss  -> 88\n",
      "240. qdrant  -> 88\n",
      "241. context management  -> 88\n",
      "242. gpt-4  -> 87\n",
      "243. time series forecasting  -> 87\n",
      "244. memory management  -> 87\n",
      "245. workflow orchestration  -> 87\n",
      "246. local llm deployment  -> 85\n",
      "247. distributed systems  -> 85\n",
      "248. data science  -> 85\n",
      "249. anthropic claude  -> 85\n",
      "250. llm integration  -> 85\n",
      "251. predictive analytics  -> 85\n",
      "252. self-supervised learning (ssl)  -> 84\n",
      "253. hybrid search  -> 84\n",
      "254. style transfer  -> 84\n",
      "255. workflow automation  -> 83\n",
      "256. mixed precision training  -> 83\n",
      "257. audio signal processing  -> 83\n",
      "258. voice ai  -> 82\n",
      "259. autoregressive models  -> 82\n",
      "260. moe (mixture of experts)  -> 81\n",
      "261. llm agents  -> 81\n",
      "262. 4-bit quantization (mxfp4)  -> 81\n",
      "263. model context protocol  -> 81\n",
      "264. chain-of-thought reasoning  -> 81\n",
      "265. a/b testing  -> 80\n",
      "266. data augmentation  -> 80\n",
      "267. in-context learning  -> 80\n",
      "268. transformer models  -> 79\n",
      "269. claude  -> 79\n",
      "270. transfer learning  -> 79\n",
      "271. embodied ai  -> 79\n",
      "272. prompt injection  -> 78\n",
      "273. memory optimization  -> 78\n",
      "274. cuda programming  -> 78\n",
      "275. world model  -> 78\n",
      "276. ai reasoning  -> 78\n",
      "277. artificial intelligence  -> 77\n",
      "278. model scaling  -> 77\n",
      "279. autonomous systems  -> 77\n",
      "280. dialogue systems  -> 77\n",
      "281. quantization-aware training (qat)  -> 77\n",
      "282. vector embeddings  -> 77\n",
      "283. model interpretability  -> 77\n",
      "284. classification  -> 77\n",
      "285. vram optimization  -> 76\n",
      "286. amazon s3  -> 76\n",
      "287. supervised finetuning (sft)  -> 76\n",
      "288. vision transformer (vit)  -> 74\n",
      "289. structured output (json)  -> 72\n",
      "290. state space models (ssm)  -> 72\n",
      "291. sql  -> 72\n",
      "292. deepspeed  -> 71\n",
      "293. federated learning  -> 71\n",
      "294. data integration  -> 71\n",
      "295. data labeling  -> 71\n",
      "296. mixed precision (bf16)  -> 71\n",
      "297. whisper (model)  -> 71\n",
      "298. mlflow  -> 69\n",
      "299. localization & mapping (slam)  -> 69\n",
      "300. vision-language model (vlm)  -> 69\n",
      "301. facial recognition  -> 68\n",
      "302. distributed inference  -> 68\n",
      "303. convolutional neural network  -> 68\n",
      "304. text-to-sql  -> 67\n",
      "305. document processing  -> 67\n",
      "306. fastapi  -> 67\n",
      "307. privacy-preserving machine learning  -> 67\n",
      "308. ai hardware  -> 67\n",
      "309. monte carlo tree search (mcts)  -> 67\n",
      "310. ci/cd  -> 66\n",
      "311. parameter efficient fine-tuning (peft)  -> 65\n",
      "312. differential privacy  -> 65\n",
      "313. bm25  -> 65\n",
      "314. bias mitigation  -> 65\n",
      "315. model architecture (bark)  -> 65\n",
      "316. streamlit  -> 64\n",
      "317. deepfake  -> 64\n",
      "318. pandas  -> 63\n",
      "319. llm development  -> 63\n",
      "320. mathematical reasoning  -> 63\n",
      "321. ai assistant  -> 63\n",
      "322. agent  -> 62\n",
      "323. aws iam  -> 62\n",
      "324. ai policy  -> 62\n",
      "325. program synthesis  -> 61\n",
      "326. visual question answering (vqa)  -> 61\n",
      "327. video analytics  -> 61\n",
      "328. browser automation  -> 61\n",
      "329. embedding model  -> 61\n",
      "330. instruction following  -> 60\n",
      "331. tensorrt  -> 60\n",
      "332. named entity recognition (ner)  -> 60\n",
      "333. model control protocol (mcp)  -> 60\n",
      "334. parameter-efficient finetuning  -> 60\n",
      "335. sparse attention  -> 59\n",
      "336. text embedding  -> 59\n",
      "337. augmented reality (ar)  -> 59\n",
      "338. tinygrad  -> 59\n",
      "339. generative adversarial networks (gan)  -> 59\n",
      "340. opentelemetry  -> 59\n",
      "341. pipeline parallelism  -> 58\n",
      "342. graph neural networks (gnn)  -> 58\n",
      "343. token management  -> 58\n",
      "344. image-to-video generation  -> 57\n",
      "345. hallucination detection  -> 57\n",
      "346. path planning  -> 57\n",
      "347. mechanistic interpretability  -> 57\n",
      "348. real-time ai  -> 57\n",
      "349. continual learning  -> 56\n",
      "350. long short-term memory (lstm)  -> 56\n",
      "351. domain adaptation  -> 56\n",
      "352. reinforcement learning (rl)  -> 56\n",
      "353. inpaint  -> 56\n",
      "354. object tracking  -> 56\n",
      "355. game ai  -> 56\n",
      "356. model alignment  -> 55\n",
      "357. scalability  -> 55\n",
      "358. huggingface  -> 55\n",
      "359. recurrent neural networks (rnn)  -> 55\n",
      "360. control systems  -> 55\n",
      "361. data pipeline  -> 55\n",
      "362. bias detection  -> 55\n",
      "363. fully sharded data parallelism (fsdp)  -> 54\n",
      "364. local llm  -> 54\n",
      "365. model pruning  -> 54\n",
      "366. llm deployment  -> 54\n",
      "367. variational autoencoder (vae)  -> 54\n",
      "368. multilingual models  -> 54\n",
      "369. pattern recognition  -> 54\n",
      "370. crewai  -> 54\n",
      "371. batch inference  -> 54\n",
      "372. sagemaker  -> 54\n",
      "373. prompt caching  -> 53\n",
      "374. internet of things (iot)  -> 53\n",
      "375. diffusers  -> 53\n",
      "376. interpretability  -> 53\n",
      "377. group proximal policy optimization (grpo)  -> 53\n",
      "378. matplotlib  -> 53\n",
      "379. speech-to-speech (s2s)  -> 52\n",
      "380. fraud detection  -> 52\n",
      "381. big data  -> 52\n",
      "382. scikit-learn  -> 52\n",
      "383. edge computing  -> 51\n",
      "384. artificial general intelligence (agi)  -> 51\n",
      "385. multimodal llm  -> 51\n",
      "386. simulation  -> 51\n",
      "387. llm reasoning  -> 51\n",
      "388. synthetic media  -> 51\n",
      "389. unsloth  -> 50\n",
      "390. containerization  -> 50\n",
      "391. web search  -> 50\n",
      "392. model auditing  -> 50\n",
      "393. local inference  -> 50\n",
      "394. gpt-5  -> 49\n",
      "395. model (gpt)  -> 49\n",
      "396. cybersecurity  -> 49\n",
      "397. representation learning  -> 49\n",
      "398. motion planning  -> 49\n",
      "399. weaviate  -> 49\n",
      "400. deepfake generation  -> 49\n",
      "401. sentence transformers (sbert)  -> 49\n",
      "402. kv cache  -> 48\n",
      "403. convolutional neural networks (cnn)  -> 48\n",
      "404. debugging  -> 48\n",
      "405. constitutional ai (cai)  -> 48\n",
      "406. document parsing  -> 48\n",
      "407. direct policy optimization (dpo)  -> 48\n",
      "408. few-shot prompts  -> 48\n",
      "409. github copilot  -> 48\n",
      "410. chain of thought  -> 48\n",
      "411. open-source ai  -> 48\n",
      "412. adversarial testing  -> 48\n",
      "413. vulkan  -> 48\n",
      "414. direct preference optimization (dpo)  -> 47\n",
      "415. model governance  -> 47\n",
      "416. automation  -> 47\n",
      "417. model routing  -> 47\n",
      "418. model selection  -> 47\n",
      "419. ai integration  -> 47\n",
      "420. face recognition  -> 47\n",
      "421. document ai  -> 47\n",
      "422. content generation  -> 47\n",
      "423. kernel optimization  -> 47\n",
      "424. 3d reconstruction  -> 47\n",
      "425. gemini api  -> 46\n",
      "426. bert  -> 46\n",
      "427. open-source llm  -> 46\n",
      "428. signal processing  -> 46\n",
      "429. mistral  -> 46\n",
      "430. supervised learning  -> 46\n",
      "431. llm inference optimization  -> 46\n",
      "432. batch processing  -> 45\n",
      "433. activation-aware weight quantization (awq)  -> 45\n",
      "434. amazon web services (aws)  -> 45\n",
      "435. google cloud platform (gcp)  -> 45\n",
      "436. prompt injection mitigation  -> 45\n",
      "437. ai chatbot  -> 45\n",
      "438. sglang  -> 45\n",
      "439. hardware optimization  -> 45\n",
      "440. human-computer interaction (hci)  -> 44\n",
      "441. distributed computing  -> 44\n",
      "442. ai inference  -> 44\n",
      "443. model orchestration  -> 44\n",
      "444. typescript  -> 44\n",
      "445. optimization  -> 44\n",
      "446. gradient descent  -> 44\n",
      "447. autogen  -> 43\n",
      "448. code execution (repl)  -> 43\n",
      "449. gptq  -> 43\n",
      "450. video analysis  -> 43\n",
      "451. lora (low-rank adaptation)  -> 43\n",
      "452. human-ai interaction  -> 43\n",
      "453. prompt optimization  -> 43\n",
      "454. dall-e  -> 43\n",
      "455. dynamic quantization  -> 43\n",
      "456. robotic process automation (rpa)  -> 43\n",
      "457. dataset creation  -> 42\n",
      "458. healthcare ai  -> 42\n",
      "459. self-attention  -> 42\n",
      "460. voice assistant  -> 42\n",
      "461. model evaluation and benchmarking  -> 42\n",
      "462. efficient inference  -> 42\n",
      "463. multihead attention  -> 42\n",
      "464. ai research  -> 42\n",
      "465. neural rendering  -> 42\n",
      "466. fp8 training  -> 42\n",
      "467. nvidia collective communications library (nccl)  -> 41\n",
      "468. system prompt  -> 41\n",
      "469. small language models (slm)  -> 41\n",
      "470. agentic system  -> 41\n",
      "471. medical imaging  -> 41\n",
      "472. vector store  -> 41\n",
      "473. computational photography  -> 40\n",
      "474. 3d modeling  -> 40\n",
      "475. distillation  -> 40\n",
      "476. qwen2.5-vl (qwen)  -> 40\n",
      "477. multi-token prediction (mtp)  -> 40\n",
      "478. adversarial machine learning  -> 40\n",
      "479. version control (git)  -> 40\n",
      "480. parallel computing  -> 40\n",
      "481. sparse autoencoder  -> 40\n",
      "482. scaling laws  -> 40\n",
      "483. pinecone  -> 40\n",
      "484. llm optimization  -> 40\n",
      "485. etl  -> 40\n",
      "486. mixed-precision training  -> 40\n",
      "487. gpt-4o  -> 39\n",
      "488. gesture recognition  -> 39\n",
      "489. ai risk management  -> 39\n",
      "490. evaluation (evals)  -> 39\n",
      "491. data cleaning  -> 39\n",
      "492. pydantic  -> 39\n",
      "493. brain-computer interface (bci)  -> 39\n",
      "494. llm orchestration  -> 39\n",
      "495. lidar  -> 39\n",
      "496. agentic workflow  -> 39\n",
      "497. large-scale model training  -> 39\n",
      "498. rest api  -> 39\n",
      "499. nvidia gpus  -> 39\n",
      "500. data annotation  -> 39\n",
      "501. data quality  -> 39\n",
      "502. clustering  -> 39\n",
      "503. bigquery  -> 39\n",
      "504. chroma  -> 38\n",
      "505. perception  -> 38\n",
      "506. cpu inference  -> 38\n",
      "507. optimization algorithm  -> 38\n",
      "508. ai model training  -> 38\n",
      "509. boto3  -> 38\n",
      "510. visual reasoning  -> 38\n",
      "511. statistical modeling  -> 38\n",
      "512. retrieval  -> 38\n",
      "513. cosine similarity  -> 38\n",
      "514. autonomous navigation  -> 37\n",
      "515. planning  -> 37\n",
      "516. data parallelism  -> 37\n",
      "517. experiment tracking  -> 37\n",
      "518. jupyter notebook  -> 37\n",
      "519. reinforcement learning from human feedback (rhlf)  -> 37\n",
      "520. mixed-precision (fp16)  -> 37\n",
      "521. cutlass  -> 37\n",
      "522. reasoning model  -> 37\n",
      "523. humanoid robotics  -> 37\n",
      "524. gpu kernel optimization  -> 37\n",
      "525. sequence models  -> 37\n",
      "526. tensorrt-llm  -> 37\n",
      "527. real-time systems  -> 36\n",
      "528. openrouter  -> 36\n",
      "529. aws bedrock  -> 36\n",
      "530. on-device ml  -> 36\n",
      "531. image inpainting  -> 36\n",
      "532. data ingestion  -> 36\n",
      "533. similarity search  -> 36\n",
      "534. multistep reasoning  -> 36\n",
      "535. open-source models  -> 36\n",
      "536. model architecture design  -> 36\n",
      "537. speech enhancement  -> 36\n",
      "538. low-latency inference  -> 35\n",
      "539. mobile ai  -> 35\n",
      "540. rotary positional embedding (rope)  -> 35\n",
      "541. chain-of-thought (cot)  -> 35\n",
      "542. multilingual ai  -> 35\n",
      "543. document retrieval  -> 35\n",
      "544. medical ai  -> 35\n",
      "545. adversarial robustness  -> 35\n",
      "546. code completion  -> 35\n",
      "547. ai-assisted coding  -> 35\n",
      "548. cost optimization  -> 35\n",
      "549. axolotl  -> 35\n",
      "550. linear attention  -> 35\n",
      "551. torch.compile  -> 35\n",
      "552. regulatory compliance  -> 34\n",
      "553. audio synthesis  -> 34\n",
      "554. fp8 quantization  -> 34\n",
      "555. pose estimation  -> 34\n",
      "556. open source ai  -> 34\n",
      "557. depth estimation (cv)  -> 34\n",
      "558. knowledge base  -> 34\n",
      "559. checkpointing  -> 34\n",
      "560. gradient accumulation  -> 34\n",
      "561. sentencetransformer  -> 34\n",
      "562. speech processing  -> 34\n",
      "563. logistic regression  -> 34\n",
      "564. llm-as-a-judge  -> 34\n",
      "565. high-performance computing (hpc)  -> 34\n",
      "566. statistical analysis  -> 34\n",
      "567. guardrails  -> 33\n",
      "568. video synthesis  -> 33\n",
      "569. amazon elasticache (redis)  -> 33\n",
      "570. data collection  -> 33\n",
      "571. evaluation metrics  -> 33\n",
      "572. role-based access control (rbac)  -> 33\n",
      "573. latency optimization  -> 33\n",
      "574. system integration  -> 33\n",
      "575. video editing  -> 33\n",
      "576. protein structure prediction  -> 33\n",
      "577. edge deployment  -> 33\n",
      "578. llm architecture  -> 33\n",
      "579. cloud infrastructure  -> 33\n",
      "580. voice assistant integration  -> 33\n",
      "581. memory-augmented models  -> 33\n",
      "582. graph database  -> 33\n",
      "583. data security  -> 32\n",
      "584. gpu inference  -> 32\n",
      "585. state management  -> 32\n",
      "586. tool-augmented llms  -> 32\n",
      "587. openai  -> 32\n",
      "588. gpu training  -> 32\n",
      "589. weights & biases (w&b)  -> 32\n",
      "590. notebooklm  -> 32\n",
      "591. policy optimization  -> 32\n",
      "592. ai strategy  -> 32\n",
      "593. model versioning  -> 32\n",
      "594. amazon nova  -> 32\n",
      "595. vision language model  -> 32\n",
      "596. bioinformatics  -> 32\n",
      "597. ai-assisted development  -> 32\n",
      "598. linear regression  -> 32\n",
      "599. active noise cancellation (anc)  -> 32\n",
      "600. conversational memory  -> 32\n",
      "601. voice synthesis  -> 31\n",
      "602. voice user interface (vui)  -> 31\n",
      "603. ai search  -> 31\n",
      "604. direct preference optimization  -> 31\n",
      "605. kv cache optimization  -> 31\n",
      "606. neural architecture search (nas)  -> 31\n",
      "607. data management  -> 31\n",
      "608. local model deployment  -> 31\n",
      "609. orchestration  -> 31\n",
      "610. ai model evaluation  -> 31\n",
      "611. threat intelligence  -> 31\n",
      "612. ai model  -> 31\n",
      "613. causal inference  -> 31\n",
      "614. human-in-the-loop ai  -> 31\n",
      "615. hybrid retrieval  -> 31\n",
      "616. image understanding  -> 31\n",
      "617. contrastive learning  -> 31\n",
      "618. amazon cloudwatch  -> 31\n",
      "619. symbolic reasoning  -> 31\n",
      "620. ai training  -> 31\n",
      "621. identity and access management (iam)  -> 31\n",
      "622. model evaluation & benchmarks  -> 31\n",
      "623. google vertex ai  -> 31\n",
      "624. automated tests  -> 31\n",
      "625. zero-shot prompting  -> 31\n",
      "626. transformer.js  -> 31\n",
      "627. ethical ai  -> 30\n",
      "628. autonomous vehicles  -> 30\n",
      "629. automl  -> 30\n",
      "630. enterprise ai  -> 30\n",
      "631. graphrag  -> 30\n",
      "632. predictive maintenance  -> 30\n",
      "633. agent development kit (adk)  -> 30\n",
      "634. backpropagation  -> 30\n",
      "635. data analytics  -> 30\n",
      "636. model validation  -> 30\n",
      "637. knowledge management  -> 30\n",
      "638. visual language models (vlm)  -> 30\n",
      "639. user modeling  -> 30\n",
      "640. dataset management  -> 30\n",
      "641. chromadb  -> 30\n",
      "642. image recognition  -> 29\n",
      "643. multimodal machine learning  -> 29\n",
      "644. access control (acls)  -> 29\n",
      "645. context window optimization  -> 29\n",
      "646. model registry  -> 29\n",
      "647. imitation learning  -> 29\n",
      "648. ai benchmarking  -> 29\n",
      "649. real-time data processing  -> 29\n",
      "650. aws cli  -> 29\n",
      "651. ai application development  -> 29\n",
      "652. postgresql  -> 29\n",
      "653. kv caching  -> 29\n",
      "654. pii detection  -> 29\n",
      "655. evolutionary algorithm  -> 29\n",
      "656. multimodal ml  -> 29\n",
      "657. motion detection  -> 29\n",
      "658. data extraction  -> 28\n",
      "659. memory  -> 28\n",
      "660. computer graphics (ai in)  -> 28\n",
      "661. mobile machine learning  -> 28\n",
      "662. speaker diarization  -> 28\n",
      "663. api security  -> 28\n",
      "664. training optimization  -> 28\n",
      "665. bitsandbytes (bnb)  -> 28\n",
      "666. face swapping  -> 28\n",
      "667. neo4j  -> 28\n",
      "668. computational biology  -> 28\n",
      "669. localization  -> 28\n",
      "670. strands agent  -> 28\n",
      "671. alignment  -> 28\n",
      "672. 3d generation  -> 28\n",
      "673. streaming inference  -> 28\n",
      "674. state space models (mamba)  -> 28\n",
      "675. smart home integration  -> 28\n",
      "676. emotion recognition  -> 28\n",
      "677. ai deployment  -> 28\n",
      "678. ai engineering  -> 28\n",
      "679. web automation  -> 28\n",
      "680. neural network architecture  -> 28\n",
      "681. adamw  -> 28\n",
      "682. model sharding  -> 28\n",
      "683. model inference optimization  -> 28\n",
      "684. model retraining  -> 28\n",
      "685. token processing  -> 28\n",
      "686. ai planning  -> 28\n",
      "687. adversarial training  -> 28\n",
      "688. websocket  -> 27\n",
      "689. voice activity detection (vad)  -> 27\n",
      "690. formal verification  -> 27\n",
      "691. api  -> 27\n",
      "692. javascript  -> 27\n",
      "693. anthropic api  -> 27\n",
      "694. quantum computing  -> 27\n",
      "695. code analysis  -> 27\n",
      "696. high performance computing (hpc)  -> 27\n",
      "697. nvlink  -> 27\n",
      "698. flow matching  -> 27\n",
      "699. task automation  -> 27\n",
      "700. privacy-preserving ai  -> 27\n",
      "701. handwriting recognition  -> 27\n",
      "702. ai video generation  -> 27\n",
      "703. openapi  -> 27\n",
      "704. indexing  -> 27\n",
      "705. chunking  -> 27\n",
      "706. fairness  -> 27\n",
      "707. gradient checkpointing  -> 27\n",
      "708. llm benchmarking  -> 27\n",
      "709. hyperparameter optimization  -> 27\n",
      "710. regression  -> 27\n",
      "711. synthetic data  -> 27\n",
      "712. aws step functions  -> 26\n",
      "713. deployment  -> 26\n",
      "714. autoscaling  -> 26\n",
      "715. lora finetuning  -> 26\n",
      "716. clinical nlp  -> 26\n",
      "717. principal component analysis (pca)  -> 26\n",
      "718. model offloading  -> 26\n",
      "719. knowledge base integration  -> 26\n",
      "720. parameter-efficient fine-tuning (peft)  -> 26\n",
      "721. agi research  -> 26\n",
      "722. llama 3  -> 26\n",
      "723. image-to-image  -> 26\n",
      "724. toxicity detection  -> 26\n",
      "725. aws sagemaker  -> 26\n",
      "726. colbert  -> 26\n",
      "727. digital twin  -> 26\n",
      "728. llm tooling  -> 26\n",
      "729. token generation  -> 26\n",
      "730. memory-efficient inference  -> 26\n",
      "731. benchmarking and evaluation  -> 26\n",
      "732. ensemble methods  -> 26\n",
      "733. enterprise search  -> 26\n",
      "734. online learning  -> 26\n",
      "735. approximate nearest neighbor (ann)  -> 26\n",
      "736. asynchronous programming  -> 25\n",
      "737. oauth  -> 25\n",
      "738. function calling (llm)  -> 25\n",
      "739. python programming  -> 25\n",
      "740. ai evaluation  -> 25\n",
      "741. amazon eks  -> 25\n",
      "742. intent recognition  -> 25\n",
      "743. programming language (rust)  -> 25\n",
      "744. transformer reinforcement learning (trl)  -> 25\n",
      "745. ai development  -> 25\n",
      "746. zero  -> 25\n",
      "747. web search integration  -> 25\n",
      "748. ai automation  -> 25\n",
      "749. google colab  -> 25\n",
      "750. post-training  -> 25\n",
      "751. privacy-preserving ml  -> 25\n",
      "752. nvidia h100  -> 25\n",
      "753. feature extraction  -> 25\n",
      "754. ai system design  -> 25\n",
      "755. elasticsearch  -> 25\n",
      "756. reasoning (ai)  -> 25\n",
      "757. torchtune  -> 25\n",
      "758. caching  -> 25\n",
      "759. knowledge retrieval  -> 25\n",
      "760. super-resolution  -> 25\n",
      "761. multimodal reasoning  -> 25\n",
      "762. dialogue management  -> 24\n",
      "763. image analysis  -> 24\n",
      "764. bfloat16  -> 24\n",
      "765. supervised fine-tuning (sft)  -> 24\n",
      "766. vision models  -> 24\n",
      "767. cloud ai platforms  -> 24\n",
      "768. ml infrastructure  -> 24\n",
      "769. decoding strategies (top-k)  -> 24\n",
      "770. logging  -> 24\n",
      "771. llm serving  -> 24\n",
      "772. autoencoder  -> 24\n",
      "773. positional encoding  -> 24\n",
      "774. sandbox  -> 24\n",
      "775. data provenance  -> 24\n",
      "776. agent-based ai  -> 24\n",
      "777. mcp (model context protocol)  -> 24\n",
      "778. neural radiance fields (nerf)  -> 24\n",
      "779. pdf parsing  -> 24\n",
      "780. voice recognition  -> 24\n",
      "781. iot integration  -> 24\n",
      "782. cloud run  -> 23\n",
      "783. active learning  -> 23\n",
      "784. long context  -> 23\n",
      "785. algorithmic fairness  -> 23\n",
      "786. hardware acceleration (npu)  -> 23\n",
      "787. sparse models  -> 23\n",
      "788. dense retrieval  -> 23\n",
      "789. model integration  -> 23\n",
      "790. optimizer  -> 23\n",
      "791. alphafold  -> 23\n",
      "792. prompt  -> 23\n",
      "793. low-precision training  -> 23\n",
      "794. safety engineering  -> 23\n",
      "795. aiops  -> 23\n",
      "796. aws cloudformation  -> 23\n",
      "797. document chunking  -> 23\n",
      "798. explainability  -> 23\n",
      "799. meta-learning  -> 23\n",
      "800. torchao  -> 23\n",
      "801. gemma  -> 23\n",
      "802. kmeans clustering  -> 23\n",
      "803. unsupervised learning  -> 23\n",
      "804. feed-forward networks (mlp)  -> 23\n",
      "805. ai hardware acceleration  -> 23\n",
      "806. ai model development  -> 23\n",
      "807. system design  -> 23\n",
      "808. content filtering  -> 23\n",
      "809. person detection  -> 23\n",
      "810. tool use (llm)  -> 23\n",
      "811. image synthesis  -> 23\n",
      "812. mlir  -> 23\n",
      "813. ssml and text-to-speech (tts)  -> 23\n",
      "814. affective computing  -> 23\n",
      "815. gguf quantization  -> 23\n",
      "816. groq  -> 23\n",
      "817. long-horizon planning  -> 22\n",
      "818. code interpreter  -> 22\n",
      "819. machine learning engineering  -> 22\n",
      "820. code generation (ai)  -> 22\n",
      "821. pruning  -> 22\n",
      "822. deepseek  -> 22\n",
      "823. model management  -> 22\n",
      "824. spatial audio  -> 22\n",
      "825. codex  -> 22\n",
      "826. aws cdk  -> 22\n",
      "827. model customization  -> 22\n",
      "828. binary classification  -> 22\n",
      "829. video diffusion  -> 22\n",
      "830. on-premise deployment  -> 22\n",
      "831. real-time analytics  -> 22\n",
      "832. amazon cognito  -> 22\n",
      "833. dimensionality reduction  -> 22\n",
      "834. serverless architecture  -> 22\n",
      "835. shap  -> 22\n",
      "836. image super-resolution  -> 22\n",
      "837. audit logging  -> 22\n",
      "838. github  -> 22\n",
      "839. web crawling  -> 22\n",
      "840. geospatial analysis  -> 22\n",
      "841. behavioral analytics  -> 22\n",
      "842. activity recognition  -> 22\n",
      "843. multimodal embedding  -> 22\n",
      "844. model calibration  -> 21\n",
      "845. xla  -> 21\n",
      "846. low-bit quantization  -> 21\n",
      "847. retrieval systems  -> 21\n",
      "848. devops  -> 21\n",
      "849. software engineer  -> 21\n",
      "850. automated theorem proving  -> 21\n",
      "851. aws glue  -> 21\n",
      "852. hugging face hub  -> 21\n",
      "853. multimodality  -> 21\n",
      "854. self-play  -> 21\n",
      "855. vision-language (v+l)  -> 21\n",
      "856. context window engineering  -> 21\n",
      "857. multimodal retrieval  -> 21\n",
      "858. amazon ecr  -> 21\n",
      "859. safetensors  -> 21\n",
      "860. sft (supervised fine-tuning)  -> 21\n",
      "861. semantic kernel  -> 21\n",
      "862. image-to-image translation  -> 21\n",
      "863. server-sent events (sse)  -> 21\n",
      "864. semantic similarity  -> 21\n",
      "865. event-driven architecture  -> 21\n",
      "866. resnet  -> 21\n",
      "867. uncertainty quantification  -> 21\n",
      "868. frame interpolation  -> 21\n",
      "869. apache spark  -> 21\n",
      "870. llm security  -> 21\n",
      "871. performance benchmarking  -> 21\n",
      "872. recurrent neural network  -> 21\n",
      "873. memory-augmented ai  -> 21\n",
      "874. generative video  -> 21\n",
      "875. curriculum learning  -> 20\n",
      "876. visual effects (vfx)  -> 20\n",
      "877. int8 quantization  -> 20\n",
      "878. reinforcement learning from ai feedback (rlaif)  -> 20\n",
      "879. llm pretraining  -> 20\n",
      "880. copilot  -> 20\n",
      "881. adversarial attacks  -> 20\n",
      "882. coding  -> 20\n",
      "883. unit testing  -> 20\n",
      "884. oauth 2.0  -> 20\n",
      "885. rdma  -> 20\n",
      "886. ai compliance  -> 20\n",
      "887. reproducibility  -> 20\n",
      "888. matrix multiplication  -> 20\n",
      "889. loss function  -> 20\n",
      "890. knowledge representation  -> 20\n",
      "891. chip design  -> 20\n",
      "892. seaborn  -> 20\n",
      "893. threat detection  -> 20\n",
      "894. scipy  -> 20\n",
      "895. vram management  -> 20\n",
      "896. expert parallelism (ep)  -> 20\n",
      "897. ml engineer  -> 20\n",
      "898. open-source ai development  -> 20\n",
      "899. session management  -> 20\n",
      "900. mongodb  -> 20\n",
      "901. ai regulation  -> 20\n",
      "902. xgboost  -> 20\n",
      "903. ggml  -> 20\n",
      "904. ai auditing  -> 20\n",
      "905. ipadapter  -> 20\n",
      "906. amazon api gateway  -> 19\n",
      "907. table extraction  -> 19\n",
      "908. ptx  -> 19\n",
      "909. spatial computing  -> 19\n",
      "910. obstacle avoidance  -> 19\n",
      "911. playwright  -> 19\n",
      "912. static analysis  -> 19\n",
      "913. kernel fusion  -> 19\n",
      "914. node.js  -> 19\n",
      "915. sagemaker hyperpod  -> 19\n",
      "916. google cloud  -> 19\n",
      "917. accelerate  -> 19\n",
      "918. neuromorphic computing  -> 19\n",
      "919. image relighting  -> 19\n",
      "920. sequence modeling (rwkv)  -> 19\n",
      "921. llava  -> 19\n",
      "922. image upscaling  -> 19\n",
      "923. intelligent document processing (idp)  -> 19\n",
      "924. uncertainty estimation  -> 19\n",
      "925. kl divergence (in rl)  -> 19\n",
      "926. model ensembling  -> 19\n",
      "927. langfuse  -> 19\n",
      "928. webassembly (wasm)  -> 19\n",
      "929. long-term memory (ltm)  -> 19\n",
      "930. attention  -> 19\n",
      "931. tensor operations  -> 19\n",
      "932. ai model deployment  -> 19\n",
      "933. ide integration  -> 19\n",
      "934. web browsing  -> 19\n",
      "935. agent architecture  -> 19\n",
      "936. web retrieval  -> 19\n",
      "937. infrastructure as code (iac)  -> 19\n",
      "938. llm application development  -> 19\n",
      "939. hugging face datasets  -> 19\n",
      "940. sliding window attention  -> 19\n",
      "941. aws trainium  -> 19\n",
      "942. contextual ai  -> 19\n",
      "943. visual search  -> 19\n",
      "944. amazon dynamodb  -> 19\n",
      "945. realtime audio processing  -> 18\n",
      "946. performance profiling  -> 18\n",
      "947. cloud deployment  -> 18\n",
      "948. generative adversarial networks (gans)  -> 18\n",
      "949. group-query attention  -> 18\n",
      "950. cloudwatch  -> 18\n",
      "951. text chunking  -> 18\n",
      "952. gpu cluster management  -> 18\n",
      "953. hardware-software co-design  -> 18\n",
      "954. markov decision process (mdp)  -> 18\n",
      "955. ai chip design  -> 18\n",
      "956. opencv  -> 18\n",
      "957. error handling  -> 18\n",
      "958. cpu offload  -> 18\n",
      "959. ai tools  -> 18\n",
      "960. embedded machine learning  -> 18\n",
      "961. preference optimization (tpo)  -> 18\n",
      "962. cuda optimization  -> 18\n",
      "963. cuda graphs  -> 18\n",
      "964. algorithm development  -> 18\n",
      "965. rate limiting  -> 18\n",
      "966. exllama  -> 18\n",
      "967. hugging face spaces  -> 18\n",
      "968. ragas  -> 18\n",
      "969. kernel development  -> 18\n",
      "970. telemetry  -> 18\n",
      "971. feature store  -> 18\n",
      "972. ranking algorithms  -> 18\n",
      "973. model security  -> 18\n",
      "974. hierarchical navigable small world (hnsw)  -> 18\n",
      "975. probabilistic models  -> 18\n",
      "976. misinformation detection  -> 18\n",
      "977. transcription  -> 18\n",
      "978. 8-bit quantization  -> 18\n",
      "979. word embeddings  -> 18\n",
      "980. kv-cache optimization  -> 18\n",
      "981. data validation  -> 18\n",
      "982. generative ai (genai)  -> 18\n",
      "983. grok  -> 18\n",
      "984. virtual reality (vr)  -> 18\n",
      "985. vector indexing  -> 18\n",
      "986. evaluation and benchmarking  -> 18\n",
      "987. physics simulation  -> 18\n",
      "988. cross-attention  -> 18\n",
      "989. token optimization  -> 18\n",
      "990. continuous learning  -> 18\n",
      "991. virtual assistant  -> 18\n",
      "992. image restoration  -> 18\n",
      "993. k-nearest neighbors (knn)  -> 17\n",
      "994. code llms  -> 17\n",
      "995. text-to-audio  -> 17\n",
      "996. code review  -> 17\n",
      "997. cloud security  -> 17\n",
      "998. point cloud processing  -> 17\n",
      "999. gemm optimization  -> 17\n",
      "1000. robotics simulation  -> 17\n",
      "1001. source attribution  -> 17\n",
      "1002. schema validation  -> 17\n",
      "1003. for ml (java)  -> 17\n",
      "1004. long context models  -> 17\n",
      "1005. ai accelerator  -> 17\n",
      "1006. model hosting  -> 17\n",
      "1007. sora  -> 17\n",
      "1008. mixed reality (mr)  -> 17\n",
      "1009. data processing  -> 17\n",
      "1010. model pretraining  -> 17\n",
      "1011. performance tuning  -> 17\n",
      "1012. c++  -> 17\n",
      "1013. music information retrieval  -> 17\n",
      "1014. model debugging  -> 17\n",
      "1015. spatial reasoning  -> 17\n",
      "1016. fact-checking  -> 17\n",
      "1017. ai orchestration  -> 17\n",
      "1018. metadata filtering  -> 17\n",
      "1019. proximal policy optimization (ppo)  -> 17\n",
      "1020. lime  -> 17\n",
      "1021. data center operations  -> 17\n",
      "1022. intelligent automation  -> 17\n",
      "1023. instruction finetuning  -> 17\n",
      "1024. int4 quantization  -> 17\n",
      "1025. human-robot interaction (hri)  -> 17\n",
      "1026. continual pretraining  -> 17\n",
      "1027. video captioning  -> 17\n",
      "1028. cross-encoder  -> 17\n",
      "1029. cublas  -> 17\n",
      "1030. crm integration  -> 17\n",
      "1031. microservices  -> 17\n",
      "1032. ai phone  -> 17\n",
      "1033. vision encoder  -> 17\n",
      "1034. batch normalization  -> 17\n",
      "1035. openai embeddings  -> 17\n",
      "1036. video summarization  -> 17\n",
      "1037. image enhancement  -> 17\n",
      "1038. agent systems  -> 17\n",
      "1039. cross-entropy loss  -> 17\n",
      "1040. github actions  -> 17\n",
      "1041. google ai studio  -> 17\n",
      "1042. gpu architecture  -> 16\n",
      "1043. adaptive learning  -> 16\n",
      "1044. webrtc  -> 16\n",
      "1045. claude code  -> 16\n",
      "1046. robotic manipulation  -> 16\n",
      "1047. code understanding  -> 16\n",
      "1048. speech translation  -> 16\n",
      "1049. retrieval augmented generation  -> 16\n",
      "1050. resource management  -> 16\n",
      "1051. opencl  -> 16\n",
      "1052. imagen  -> 16\n",
      "1053. tool orchestration  -> 16\n",
      "1054. demand forecasting  -> 16\n",
      "1055. prompt template  -> 16\n",
      "1056. contextual understanding  -> 16\n",
      "1057. incident response  -> 16\n",
      "1058. cuda kernel optimization  -> 16\n",
      "1059. multi-gpu inference  -> 16\n",
      "1060. ai upscaling  -> 16\n",
      "1061. entity extraction  -> 16\n",
      "1062. energy-efficient ai  -> 16\n",
      "1063. throughput optimization  -> 16\n",
      "1064. load balancing  -> 16\n",
      "1065. tensor cores  -> 16\n",
      "1066. json-rpc  -> 16\n",
      "1067. prometheus  -> 16\n",
      "1068. model development  -> 16\n",
      "1069. ai music generation  -> 16\n",
      "1070. document summarization  -> 16\n",
      "1071. voice conversion (rvc)  -> 16\n",
      "1072. document generation  -> 16\n",
      "1073. aws s3  -> 16\n",
      "1074. vector quantization  -> 16\n",
      "1075. training data management  -> 16\n",
      "1076. large-scale training  -> 16\n",
      "1077. ai in healthcare  -> 16\n",
      "1078. ai image generation  -> 16\n",
      "1079. exploratory data analysis (eda)  -> 16\n",
      "1080. agent-based systems  -> 16\n",
      "1081. lipsync  -> 16\n",
      "1082. sampling methods  -> 16\n",
      "1083. theorem proving  -> 16\n",
      "1084. rl finetuning  -> 16\n",
      "1085. data preparation  -> 16\n",
      "1086. mobile ai development  -> 16\n",
      "1087. gguf format  -> 16\n",
      "1088. parallel processing  -> 16\n",
      "1089. keyword search  -> 16\n",
      "1090. ml pipeline  -> 16\n",
      "1091. beam search  -> 16\n",
      "1092. benchmarking (mmlu)  -> 16\n",
      "1093. microsoft copilot  -> 16\n",
      "1094. blockchain  -> 16\n",
      "1095. bitnet  -> 16\n",
      "1096. onnx runtime  -> 16\n",
      "1097. ai monitoring  -> 16\n",
      "1098. regularization  -> 16\n",
      "1099. drift detection  -> 15\n",
      "1100. llamaparse  -> 15\n",
      "1101. litellm  -> 15\n",
      "1102. object recognition  -> 15\n",
      "1103. kubeflow  -> 15\n",
      "1104. natural language toolkit (nltk)  -> 15\n",
      "1105. long context processing  -> 15\n",
      "1106. quantization (ai)  -> 15\n",
      "1107. databricks  -> 15\n",
      "1108. text-to-3d  -> 15\n",
      "1109. distributed tracing  -> 15\n",
      "1110. translation  -> 15\n",
      "1111. learning rate scheduling  -> 15\n",
      "1112. fill-in-the-middle (fim)  -> 15\n",
      "1113. outpainting  -> 15\n",
      "1114. secret management  -> 15\n",
      "1115. encoder-decoder architecture  -> 15\n",
      "1116. lip sync  -> 15\n",
      "1117. aider  -> 15\n",
      "1118. embedded ai  -> 15\n",
      "1119. image retrieval  -> 15\n",
      "1120. real-time processing  -> 15\n",
      "1121. bigquery ml  -> 15\n",
      "1122. real-time video processing  -> 15\n",
      "1123. regression analysis  -> 15\n",
      "1124. multi-query attention (mqa)  -> 15\n",
      "1125. azure openai  -> 15\n",
      "1126. ai system  -> 15\n",
      "1127. video-to-video  -> 15\n",
      "1128. foundational models  -> 15\n",
      "1129. kv cache management  -> 15\n",
      "1130. noise cancellation  -> 15\n",
      "1131. ai accelerator design  -> 15\n",
      "1132. gaussian splatting  -> 15\n",
      "1133. apple intelligence  -> 15\n",
      "1134. json schema  -> 15\n",
      "1135. model robustness  -> 15\n",
      "1136. dynamic analysis  -> 15\n",
      "1137. llm api integration  -> 15\n",
      "1138. document analysis  -> 15\n",
      "1139. fault tolerance  -> 15\n",
      "1140. voice assistant development  -> 15\n",
      "1141. structured data extraction  -> 15\n",
      "1142. llm function calling  -> 15\n",
      "1143. experimental design  -> 15\n",
      "1144. face detection  -> 15\n",
      "1145. ai guardrails  -> 15\n",
      "1146. feature scaling  -> 15\n",
      "1147. metal  -> 15\n",
      "1148. metadata management  -> 15\n",
      "1149. amazon bedrock knowledge bases  -> 15\n",
      "1150. aws sdk  -> 15\n",
      "1151. voice interface  -> 15\n",
      "1152. amazon bedrock agentcore  -> 15\n",
      "1153. triton inference server  -> 15\n",
      "1154. neural processing unit (npu)  -> 15\n",
      "1155. post-training quantization (ptq)  -> 15\n",
      "1156. code search  -> 15\n",
      "1157. sparse retrieval  -> 15\n",
      "1158. model checkpoints  -> 15\n",
      "1159. model card  -> 15\n",
      "1160. asic design  -> 15\n",
      "1161. ml observability  -> 15\n",
      "1162. plugin development  -> 15\n",
      "1163. nlp (natural language processing)  -> 15\n",
      "1164. no-code ai  -> 15\n",
      "1165. rlhf (reinforcement learning from human feedback)  -> 15\n",
      "1166. topic modeling  -> 15\n",
      "1167. cpu optimization  -> 15\n",
      "1168. structured output generation  -> 15\n",
      "1169. data poisoning  -> 15\n",
      "1170. ui automation  -> 15\n",
      "1171. data transformation  -> 15\n",
      "1172. data versioning (dvc)  -> 15\n",
      "1173. pagedattention  -> 14\n",
      "1174. adversarial ai  -> 14\n",
      "1175. audio analysis  -> 14\n",
      "1176. google assistant  -> 14\n",
      "1177. asyncio  -> 14\n",
      "1178. age verification  -> 14\n",
      "1179. adversarial ml  -> 14\n",
      "1180. robot manipulation  -> 14\n",
      "1181. test-time scaling  -> 14\n",
      "1182. sagemaker studio  -> 14\n",
      "1183. policy gradient  -> 14\n",
      "1184. tf-idf  -> 14\n",
      "1185. agent evaluation  -> 14\n",
      "1186. data lineage  -> 14\n",
      "1187. data licensing  -> 14\n",
      "1188. koboldcpp  -> 14\n",
      "1189. model compilation  -> 14\n",
      "1190. opensearch  -> 14\n",
      "1191. elastic fabric adapter (efa)  -> 14\n",
      "1192. api management  -> 14\n",
      "1193. ai-assisted code generation  -> 14\n",
      "1194. software development  -> 14\n",
      "1195. ai assistant development  -> 14\n",
      "1196. jupyterlab  -> 14\n",
      "1197. forecasting  -> 14\n",
      "1198. xformers  -> 14\n",
      "1199. facial animation  -> 14\n",
      "1200. fact checking  -> 14\n",
      "1201. medical image analysis  -> 14\n",
      "1202. biometric authentication  -> 14\n",
      "1203. container orchestration  -> 14\n",
      "1204. train  -> 14\n",
      "1205. streaming apis  -> 14\n",
      "1206. llm memory  -> 14\n",
      "1207. llm tool integration  -> 14\n",
      "1208. statsmodels  -> 14\n",
      "1209. flask  -> 14\n",
      "1210. sdk development  -> 14\n",
      "1211. remote sensing  -> 14\n",
      "1212. production ml  -> 14\n",
      "1213. tactile sensing  -> 14\n",
      "1214. data anonymization  -> 14\n",
      "1215. model tuning  -> 14\n",
      "1216. human evaluation  -> 14\n",
      "1217. protein language model  -> 14\n",
      "1218. slurm  -> 14\n",
      "1219. ai interpretability  -> 14\n",
      "1220. multi-agent orchestration  -> 14\n",
      "1221. search algorithms  -> 14\n",
      "1222. veo  -> 14\n",
      "1223. real-time rendering  -> 14\n",
      "1224. dora  -> 14\n",
      "1225. pgvector  -> 14\n",
      "1226. motion capture  -> 14\n",
      "1227. drug discovery  -> 14\n",
      "1228. edge inference  -> 14\n",
      "1229. prompt tuning  -> 14\n",
      "1230. encryption  -> 14\n",
      "1231. text extraction  -> 14\n",
      "1232. 3d computer vision  -> 14\n",
      "1233. text generation inference (tgi)  -> 14\n",
      "1234. advanced driver assistance systems (adas)  -> 14\n",
      "1235. code refactoring  -> 14\n",
      "1236. object localization  -> 14\n",
      "1237. opensource development  -> 14\n",
      "1238. image embedding  -> 14\n",
      "1239. vision language model (vlm)  -> 14\n",
      "1240. ai regulatory compliance  -> 14\n",
      "1241. symbolic ai  -> 14\n",
      "1242. ai product development  -> 14\n",
      "1243. bedrock  -> 13\n",
      "1244. grafana  -> 13\n",
      "1245. root cause analysis (rca)  -> 13\n",
      "1246. parallel decoding  -> 13\n",
      "1247. gpu offload  -> 13\n",
      "1248. neurosymbolic ai  -> 13\n",
      "1249. speech-to-text (stt)  -> 13\n",
      "1250. data normalization  -> 13\n",
      "1251. trustworthy ai  -> 13\n",
      "1252. gemini cli  -> 13\n",
      "1253. mamba architecture  -> 13\n",
      "1254. ai detection  -> 13\n",
      "1255. multivector retrieval  -> 13\n",
      "1256. hipaa compliance  -> 13\n",
      "1257. linear algebra  -> 13\n",
      "1258. diffusion transformer  -> 13\n",
      "1259. state-space models (ssms)  -> 13\n",
      "1260. perplexity  -> 13\n",
      "1261. softmax  -> 13\n",
      "1262. document classification  -> 13\n",
      "1263. hugging face accelerate  -> 13\n",
      "1264. human-in-the-loop systems  -> 13\n",
      "1265. intent classification  -> 13\n",
      "1266. amazon bedrock agents  -> 13\n",
      "1267. amazon bedrock guardrails  -> 13\n",
      "1268. proximal policy optimization  -> 13\n",
      "1269. customer segmentation  -> 13\n",
      "1270. visual grounding  -> 13\n",
      "1271. semantic chunking  -> 13\n",
      "1272. rejection sampling  -> 13\n",
      "1273. grouped-query attention (gqa)  -> 13\n",
      "1274. tree of thought (tot)  -> 13\n",
      "1275. dataset preparation  -> 13\n",
      "1276. code editing  -> 13\n",
      "1277. sampling techniques  -> 13\n",
      "1278. context window extension  -> 13\n",
      "1279. benchmarking (ai)  -> 13\n",
      "1280. tracing  -> 13\n",
      "1281. azure ai  -> 13\n",
      "1282. llmops  -> 13\n",
      "1283. multimodal generation  -> 13\n",
      "1284. ai model optimization  -> 13\n",
      "1285. context caching  -> 13\n",
      "1286. openvino  -> 13\n",
      "1287. dynamic pricing  -> 13\n",
      "1288. dropout  -> 13\n",
      "1289. multi-hop reasoning  -> 13\n",
      "1290. stream processing  -> 13\n",
      "1291. dpo (direct preference optimization)  -> 13\n",
      "1292. document ingestion  -> 13\n",
      "1293. cursor  -> 13\n",
      "1294. sensor data processing  -> 13\n",
      "1295. ai product management  -> 13\n",
      "1296. procedural content generation  -> 13\n",
      "1297. time-series forecasting  -> 13\n",
      "1298. semantic segmentation  -> 13\n",
      "1299. continued pretraining  -> 13\n",
      "1300. context-aware ai  -> 13\n",
      "1301. video models  -> 13\n",
      "1302. scientific machine learning  -> 13\n",
      "1303. compliance  -> 13\n",
      "1304. query rewriting  -> 13\n",
      "1305. json web token (jwt)  -> 13\n",
      "1306. sparsity  -> 13\n",
      "1307. efficient training  -> 13\n",
      "1308. api design  -> 13\n",
      "1309. api gateway  -> 13\n",
      "1310. kvcache  -> 13\n",
      "1311. parallelization  -> 13\n",
      "1312. coding agent  -> 13\n",
      "1313. chain of thought (cot)  -> 13\n",
      "1314. robustness testing  -> 13\n",
      "1315. noise reduction  -> 13\n",
      "1316. speech recognition (asr)  -> 13\n",
      "1317. quantization aware training  -> 13\n",
      "1318. ai for cybersecurity  -> 12\n",
      "1319. json processing  -> 12\n",
      "1320. algorithm  -> 12\n",
      "1321. unstructured data processing  -> 12\n",
      "1322. batching  -> 12\n",
      "1323. prompt chaining  -> 12\n",
      "1324. dreambooth  -> 12\n",
      "1325. security  -> 12\n",
      "1326. ai for software development  -> 12\n",
      "1327. biosignal processing  -> 12\n",
      "1328. k-means  -> 12\n",
      "1329. dataset engineering  -> 12\n",
      "1330. knowledge base management  -> 12\n",
      "1331. snowflake  -> 12\n",
      "1332. chain of thought reasoning (cot)  -> 12\n",
      "1333. sagemaker pipelines  -> 12\n",
      "1334. text splitting  -> 12\n",
      "1335. genomics  -> 12\n",
      "1336. data synthesis  -> 12\n",
      "1337. ai video editing  -> 12\n",
      "1338. image-to-text  -> 12\n",
      "1339. text analysis  -> 12\n",
      "1340. data modeling  -> 12\n",
      "1341. amazon eventbridge  -> 12\n",
      "1342. iterative refinement  -> 12\n",
      "1343. activation function  -> 12\n",
      "1344. node classification  -> 12\n",
      "1345. delta lake  -> 12\n",
      "1346. cryptography  -> 12\n",
      "1347. deep learning frameworks  -> 12\n",
      "1348. ai observability  -> 12\n",
      "1349. milvus  -> 12\n",
      "1350. mindspore  -> 12\n",
      "1351. multihead latent attention  -> 12\n",
      "1352. physics-informed machine learning  -> 12\n",
      "1353. obstacle detection  -> 12\n",
      "1354. gated recurrent unit (gru)  -> 12\n",
      "1355. instance segmentation  -> 12\n",
      "1356. serverless inference  -> 12\n",
      "1357. overfitting  -> 12\n",
      "1358. android development  -> 12\n",
      "1359. group query attention  -> 12\n",
      "1360. data wrangling  -> 12\n",
      "1361. error analysis  -> 12\n",
      "1362. data loss prevention (dlp)  -> 12\n",
      "1363. knowledge graph construction  -> 12\n",
      "1364. model testing  -> 12\n",
      "1365. pillow (pil)  -> 12\n",
      "1366. local llm inference  -> 12\n",
      "1367. metrics  -> 12\n",
      "1368. fleet management  -> 12\n",
      "1369. fine-tuning llms  -> 12\n",
      "1370. llm observability  -> 12\n",
      "1371. context window  -> 12\n",
      "1372. gpu infrastructure  -> 12\n",
      "1373. 3d asset generation  -> 12\n",
      "1374. img2img  -> 12\n",
      "1375. cluster management  -> 12\n",
      "1376. preference models  -> 12\n",
      "1377. agent programming  -> 12\n",
      "1378. classifier-free guidance (cfg)  -> 12\n",
      "1379. supply chain optimization  -> 12\n",
      "1380. agent sdk  -> 12\n",
      "1381. agent memory  -> 12\n",
      "1382. robot navigation  -> 12\n",
      "1383. scalable ai  -> 12\n",
      "1384. gemm  -> 12\n",
      "1385. wake word detection  -> 12\n",
      "1386. go  -> 12\n",
      "1387. google adk  -> 12\n",
      "1388. llm safety  -> 12\n",
      "1389. helm  -> 12\n",
      "1390. multimodal fusion  -> 12\n",
      "1391. nvidia nemo  -> 12\n",
      "1392. cohere  -> 12\n",
      "1393. voice agents  -> 12\n",
      "1394. ai literacy  -> 12\n",
      "1395. cross-validation  -> 12\n",
      "1396. scene understanding  -> 12\n",
      "1397. bias detection and mitigation  -> 12\n",
      "1398. tokenizer  -> 12\n",
      "1399. megatron-lm  -> 12\n",
      "1400. agentcore  -> 12\n",
      "1401. gpt models  -> 12\n",
      "1402. 3d scene generation  -> 12\n",
      "1403. google kubernetes engine (gke)  -> 12\n",
      "1404. digital signal processing (dsp)  -> 12\n",
      "1405. next-token prediction  -> 12\n",
      "1406. ad targeting  -> 12\n",
      "1407. policy enforcement  -> 12\n",
      "1408. reinforcement fine-tuning (rft)  -> 12\n",
      "1409. neural processing unit  -> 12\n",
      "1410. threat modeling  -> 12\n",
      "1411. model safety  -> 11\n",
      "1412. automated evaluation  -> 11\n",
      "1413. autogpt  -> 11\n",
      "1414. parquet  -> 11\n",
      "1415. ai workflow automation  -> 11\n",
      "1416. reward shaping  -> 11\n",
      "1417. amazon ec2  -> 11\n",
      "1418. amazon ecs  -> 11\n",
      "1419. distilbert  -> 11\n",
      "1420. genetic algorithm  -> 11\n",
      "1421. domain-specific ai  -> 11\n",
      "1422. fp4  -> 11\n",
      "1423. ai hardware optimization  -> 11\n",
      "1424. inference serving  -> 11\n",
      "1425. algorithm design  -> 11\n",
      "1426. denoising  -> 11\n",
      "1427. human-ai collaboration  -> 11\n",
      "1428. real-time monitoring  -> 11\n",
      "1429. microsoft 365 copilot  -> 11\n",
      "1430. test-time training  -> 11\n",
      "1431. chatgpt api  -> 11\n",
      "1432. memory systems  -> 11\n",
      "1433. agentic rag  -> 11\n",
      "1434. sagemaker model registry  -> 11\n",
      "1435. cli development  -> 11\n",
      "1436. speech-to-text (asr)  -> 11\n",
      "1437. tts (text-to-speech)  -> 11\n",
      "1438. agent2agent (a2a)  -> 11\n",
      "1439. embedding generation  -> 11\n",
      "1440. monte carlo methods  -> 11\n",
      "1441. hypernetwork  -> 11\n",
      "1442. latent diffusion  -> 11\n",
      "1443. self-reflection  -> 11\n",
      "1444. image manipulation  -> 11\n",
      "1445. openai agents sdk  -> 11\n",
      "1446. automated planning  -> 11\n",
      "1447. audio understanding  -> 11\n",
      "1448. pytorch geometric  -> 11\n",
      "1449. sparse embeddings  -> 11\n",
      "1450. deep learning optimization  -> 11\n",
      "1451. microsoft azure  -> 11\n",
      "1452. open source models  -> 11\n",
      "1453. audio ai  -> 11\n",
      "1454. fairness in ai  -> 11\n",
      "1455. core ml  -> 11\n",
      "1456. behavior trees  -> 11\n",
      "1457. security automation  -> 11\n",
      "1458. hybrid reasoning  -> 11\n",
      "1459. ai content detection  -> 11\n",
      "1460. object removal (video)  -> 11\n",
      "1461. agent engineering  -> 11\n",
      "1462. local deployment  -> 11\n",
      "1463. media forensics  -> 11\n",
      "1464. unet  -> 11\n",
      "1465. recall  -> 11\n",
      "1466. monitoring and observability  -> 11\n",
      "1467. apple silicon optimization  -> 11\n",
      "1468. trust and safety  -> 11\n",
      "1469. token embedding  -> 11\n",
      "1470. n8n  -> 11\n",
      "1471. system architecture  -> 11\n",
      "1472. context compression  -> 11\n",
      "1473. sim-to-real transfer  -> 11\n",
      "1474. openwebui  -> 11\n",
      "1475. watermarking  -> 11\n",
      "1476. hip  -> 11\n",
      "1477. image forensics  -> 11\n",
      "1478. time-series analysis  -> 11\n",
      "1479. ai risk assessment  -> 11\n",
      "1480. multilingual llms  -> 11\n",
      "1481. performance monitoring  -> 11\n",
      "1482. fsdp (fully sharded data parallel)  -> 11\n",
      "1483. visual programming  -> 11\n",
      "1484. diffusion  -> 11\n",
      "1485. log analysis  -> 11\n",
      "1486. avatar generation  -> 11\n",
      "1487. process automation  -> 11\n",
      "1488. jailbreak  -> 11\n",
      "1489. text processing  -> 11\n",
      "1490. gpu memory optimization  -> 11\n",
      "1491. gradient boosting  -> 11\n",
      "1492. gradient compression  -> 11\n",
      "1493. adam optimizer  -> 11\n",
      "1494. speech-to-video (s2v)  -> 11\n",
      "1495. video segmentation  -> 11\n",
      "1496. activation checkpointing  -> 11\n",
      "1497. novel view synthesis  -> 11\n",
      "1498. data pipeline engineering  -> 11\n",
      "1499. adapters  -> 11\n",
      "1500. route optimization  -> 10\n",
      "1501. automated reasoning  -> 10\n",
      "1502. audio transcription  -> 10\n",
      "1503. rope scaling  -> 10\n",
      "1504. robustness  -> 10\n",
      "1505. spiking neural networks  -> 10\n",
      "1506. ktransformer  -> 10\n",
      "1507. kubernetes manifests (yaml)  -> 10\n",
      "1508. eks  -> 10\n",
      "1509. serverless  -> 10\n",
      "1510. serverless computing  -> 10\n",
      "1511. wearable ai  -> 10\n",
      "1512. agent design  -> 10\n",
      "1513. natural language interface  -> 10\n",
      "1514. tool-using agents  -> 10\n",
      "1515. gpt-2  -> 10\n",
      "1516. canary deployment  -> 10\n",
      "1517. machine learning research  -> 10\n",
      "1518. precision  -> 10\n",
      "1519. zero-knowledge proofs  -> 10\n",
      "1520. gradient clipping  -> 10\n",
      "1521. 3d vision  -> 10\n",
      "1522. ablation studies  -> 10\n",
      "1523. gpu performance optimization  -> 10\n",
      "1524. gpu profiling  -> 10\n",
      "1525. gpu memory management  -> 10\n",
      "1526. random forest  -> 10\n",
      "1527. social media analytics  -> 10\n",
      "1528. markov chain monte carlo (mcmc)  -> 10\n",
      "1529. hate speech detection  -> 10\n",
      "1530. layer normalization  -> 10\n",
      "1531. hypothesis testing  -> 10\n",
      "1532. regression testing  -> 10\n",
      "1533. background removal  -> 10\n",
      "1534. online reinforcement learning  -> 10\n",
      "1535. ai inference optimization  -> 10\n",
      "1536. profiling  -> 10\n",
      "1537. program analysis  -> 10\n",
      "1538. tokenizer development  -> 10\n",
      "1539. long-context reasoning  -> 10\n",
      "1540. pymupdf  -> 10\n",
      "1541. pdf processing  -> 10\n",
      "1542. autonomous ai  -> 10\n",
      "1543. automatic1111  -> 10\n",
      "1544. red-teaming  -> 10\n",
      "1545. min-max scaling  -> 10\n",
      "1546. static code analysis  -> 10\n",
      "1547. ai platform  -> 10\n",
      "1548. resource optimization  -> 10\n",
      "1549. t5  -> 10\n",
      "1550. confidential computing  -> 10\n",
      "1551. scalable ai systems  -> 10\n",
      "1552. fuzzing  -> 10\n",
      "1553. confusion matrix  -> 10\n",
      "1554. natural language query  -> 10\n",
      "1555. physics-informed neural networks (pinns)  -> 10\n",
      "1556. mcp server  -> 10\n",
      "1557. matrix operations  -> 10\n",
      "1558. eye tracking  -> 10\n",
      "1559. self-correction  -> 10\n",
      "1560. sharding  -> 10\n",
      "1561. asr (automatic speech recognition)  -> 10\n",
      "1562. unreal engine  -> 10\n",
      "1563. openpose  -> 10\n",
      "1564. speaker recognition  -> 10\n",
      "1565. deep learning super sampling (dlss)  -> 10\n",
      "1566. real-time translation  -> 10\n",
      "1567. scientific computing  -> 10\n",
      "1568. homomorphic encryption (he)  -> 10\n",
      "1569. flux  -> 10\n",
      "1570. amazon athena  -> 10\n",
      "1571. image search  -> 10\n",
      "1572. data deduplication  -> 10\n",
      "1573. pathfinding  -> 10\n",
      "1574. ai safety and alignment  -> 10\n",
      "1575. multi-turn dialogue  -> 10\n",
      "1576. audio classification  -> 10\n",
      "1577. parameter tuning  -> 10\n",
      "1578. encoder-decoder models  -> 10\n",
      "1579. math reasoning  -> 10\n",
      "1580. agentic coding  -> 10\n",
      "1581. optimizer tuning  -> 10\n",
      "1582. anthropic  -> 10\n",
      "1583. llama 2  -> 10\n",
      "1584. llama3  -> 10\n",
      "1585. streaming  -> 10\n",
      "1586. tpu programming  -> 10\n",
      "1587. fairness and bias mitigation  -> 10\n",
      "1588. bedrock agentcore  -> 10\n",
      "1589. fastmcp  -> 10\n",
      "1590. support vector machine (svm)  -> 10\n",
      "1591. sustainable ai  -> 10\n",
      "1592. search  -> 10\n",
      "1593. llm (large language model)  -> 10\n",
      "1594. ai architecture  -> 10\n",
      "1595. fully sharded data parallel (fsdp2)  -> 10\n",
      "1596. foundation model training  -> 10\n",
      "1597. speech-to-speech translation  -> 10\n",
      "1598. pattern matching  -> 10\n",
      "1599. parameter-efficient training  -> 10\n",
      "1600. data lake  -> 10\n",
      "1601. mixtral  -> 10\n",
      "1602. knowledge base construction  -> 10\n",
      "1603. dense embeddings  -> 10\n",
      "1604. allreduce  -> 10\n",
      "1605. amazon q business  -> 10\n",
      "1606. document loader  -> 10\n",
      "1607. data imputation  -> 10\n",
      "1608. open-weight model  -> 10\n",
      "1609. multi-gpu  -> 10\n",
      "1610. multi-gpu programming  -> 10\n",
      "1611. long context window  -> 10\n",
      "1612. runway  -> 10\n",
      "1613. runwayml  -> 10\n",
      "1614. cloud storage  -> 10\n",
      "1615. google cloud storage  -> 10\n",
      "1616. neural machine translation (nmt)  -> 10\n",
      "1617. neural decoding  -> 10\n",
      "1618. runpod  -> 10\n",
      "1619. chain of thought prompting  -> 10\n",
      "1620. generalized self-play optimization (gspo)  -> 10\n",
      "1621. generative design  -> 10\n",
      "1622. chatml  -> 10\n",
      "1623. privacy (in ai)  -> 10\n",
      "1624. generative image models  -> 10\n",
      "1625. gui automation  -> 10\n",
      "1626. blender  -> 10\n",
      "1627. ai frameworks  -> 10\n",
      "1628. ai application  -> 10\n",
      "1629. keyword extraction  -> 10\n",
      "1630. model export  -> 10\n",
      "1631. prompt management  -> 10\n",
      "1632. bayesian inference  -> 10\n",
      "1633. beamforming  -> 10\n",
      "1634. search engine  -> 10\n",
      "1635. controllable generation  -> 10\n",
      "1636. financial ai  -> 10\n",
      "1637. toolcalling  -> 10\n",
      "1638. gpt-3  -> 10\n",
      "1639. gpu kernels  -> 10\n",
      "1640. logit bias  -> 9\n",
      "1641. devsecops  -> 9\n",
      "1642. tensor processing  -> 9\n",
      "1643. tensorboard  -> 9\n",
      "1644. preference learning  -> 9\n",
      "1645. robot control  -> 9\n",
      "1646. ci/cd for ml  -> 9\n",
      "1647. text-to-audio generation  -> 9\n",
      "1648. neural network training  -> 9\n",
      "1649. low-bit training  -> 9\n",
      "1650. react framework  -> 9\n",
      "1651. ray  -> 9\n",
      "1652. code debugging  -> 9\n",
      "1653. test generation  -> 9\n",
      "1654. spam detection  -> 9\n",
      "1655. radar  -> 9\n",
      "1656. digital watermarking  -> 9\n",
      "1657. model explainability  -> 9\n",
      "1658. algorithmic auditing  -> 9\n",
      "1659. visual understanding  -> 9\n",
      "1660. torchvision  -> 9\n",
      "1661. bot detection  -> 9\n",
      "1662. token prediction  -> 9\n",
      "1663. deepeval  -> 9\n",
      "1664. single sign-on (sso)  -> 9\n",
      "1665. skypilot  -> 9\n",
      "1666. ai-powered search  -> 9\n",
      "1667. ai-powered obstacle detection  -> 9\n",
      "1668. llm alignment  -> 9\n",
      "1669. llm application  -> 9\n",
      "1670. llm cost optimization  -> 9\n",
      "1671. tool use (ai)  -> 9\n",
      "1672. flan-t5  -> 9\n",
      "1673. 3d generative models  -> 9\n",
      "1674. zero trust  -> 9\n",
      "1675. rouge  -> 9\n",
      "1676. interoperability  -> 9\n",
      "1677. http  -> 9\n",
      "1678. tool-augmented agents  -> 9\n",
      "1679. creative ai  -> 9\n",
      "1680. llamacloud  -> 9\n",
      "1681. content moderation (ai)  -> 9\n",
      "1682. structured prompting (xml)  -> 9\n",
      "1683. ai for coding  -> 9\n",
      "1684. ai model benchmarking  -> 9\n",
      "1685. on-policy reinforcement learning  -> 9\n",
      "1686. context window processing  -> 9\n",
      "1687. context length optimization  -> 9\n",
      "1688. ffmpeg  -> 9\n",
      "1689. flax  -> 9\n",
      "1690. ai for drug discovery  -> 9\n",
      "1691. amazon fsx for lustre  -> 9\n",
      "1692. vectorization  -> 9\n",
      "1693. amazon alexa  -> 9\n",
      "1694. data drift detection  -> 9\n",
      "1695. sequence parallelism  -> 9\n",
      "1696. automated program repair  -> 9\n",
      "1697. multi-object tracking  -> 9\n",
      "1698. image preprocessing  -> 9\n",
      "1699. data generation  -> 9\n",
      "1700. ai transparency  -> 9\n",
      "1701. transformer optimization  -> 9\n",
      "1702. custom model development  -> 9\n",
      "1703. data center infrastructure  -> 9\n",
      "1704. openai codex  -> 9\n",
      "1705. data filtering  -> 9\n",
      "1706. temporal reasoning  -> 9\n",
      "1707. model efficiency  -> 9\n",
      "1708. decentralized ai  -> 9\n",
      "1709. duckdb  -> 9\n",
      "1710. dynamic programming  -> 9\n",
      "1711. moe models  -> 9\n",
      "1712. bleu  -> 9\n",
      "1713. collaborative filtering  -> 9\n",
      "1714. compiler optimization  -> 9\n",
      "1715. llvm  -> 9\n",
      "1716. agent-to-agent (a2a) protocol  -> 9\n",
      "1717. agent-to-agent communication  -> 9\n",
      "1718. business intelligence (bi)  -> 9\n",
      "1719. byte-level models  -> 9\n",
      "1720. speech synthesis (tts)  -> 9\n",
      "1721. speech generation  -> 9\n",
      "1722. f1 score  -> 9\n",
      "1723. inference engineering  -> 9\n",
      "1724. realtime api  -> 9\n",
      "1725. overfitting mitigation  -> 9\n",
      "1726. deep reinforcement learning  -> 9\n",
      "1727. apple metal  -> 9\n",
      "1728. document extraction  -> 9\n",
      "1729. intent detection  -> 9\n",
      "1730. image augmentation  -> 9\n",
      "1731. ai red teaming  -> 9\n",
      "1732. event detection  -> 9\n",
      "1733. semantic parsing  -> 9\n",
      "1734. entity resolution  -> 9\n",
      "1735. hardware acceleration (ai)  -> 9\n",
      "1736. local ai deployment  -> 9\n",
      "1737. gdpr compliance  -> 9\n",
      "1738. teleoperation  -> 9\n",
      "1739. regular expressions  -> 9\n",
      "1740. reinforce  -> 9\n",
      "1741. statistics  -> 9\n",
      "1742. vision-language-action models  -> 9\n",
      "1743. cudnn  -> 9\n",
      "1744. visual studio code  -> 9\n",
      "1745. vpc  -> 9\n",
      "1746. memory management for llms  -> 9\n",
      "1747. negative prompts  -> 9\n",
      "1748. task decomposition  -> 9\n",
      "1749. bf16 training  -> 9\n",
      "1750. context pruning  -> 9\n",
      "1751. code generation with llms  -> 9\n",
      "1752. preprocessed  -> 9\n",
      "1753. calibration  -> 9\n",
      "1754. code reasoning  -> 9\n",
      "1755. image-to-image generation  -> 9\n",
      "1756. efficient ai  -> 9\n",
      "1757. pretrained models  -> 9\n",
      "1758. database integration  -> 9\n",
      "1759. mlc-llm  -> 9\n",
      "1760. gpu kernel development  -> 9\n",
      "1761. trusted execution environment  -> 9\n",
      "1762. tsne  -> 9\n",
      "1763. data mining  -> 9\n",
      "1764. llm context management  -> 9\n",
      "1765. fine-tuning (llm)  -> 9\n",
      "1766. gpu management  -> 9\n",
      "1767. agent2agent protocol  -> 9\n",
      "1768. serverless deployment  -> 9\n",
      "1769. authentication  -> 9\n",
      "1770. audio-visual synchronization  -> 9\n",
      "1771. q-learning  -> 9\n",
      "1772. npu programming  -> 9\n",
      "1773. graph traversal  -> 9\n",
      "1774. kv cache quantization  -> 9\n",
      "1775. rmsnorm  -> 9\n",
      "1776. graph algorithms  -> 9\n",
      "1777. text-to-text generation  -> 9\n",
      "1778. age estimation  -> 9\n",
      "1779. neural architecture design  -> 9\n",
      "1780. neural network architecture design  -> 9\n",
      "1781. text splitter  -> 8\n",
      "1782. cohere api  -> 8\n",
      "1783. rag evaluation  -> 8\n",
      "1784. gpt-3.5  -> 8\n",
      "1785. graph convolutional network  -> 8\n",
      "1786. s3  -> 8\n",
      "1787. clinical decision support  -> 8\n",
      "1788. software architecture  -> 8\n",
      "1789. cloud ai  -> 8\n",
      "1790. graph of thoughts  -> 8\n",
      "1791. agent security  -> 8\n",
      "1792. graphql  -> 8\n",
      "1793. safety  -> 8\n",
      "1794. video search  -> 8\n",
      "1795. efficient attention  -> 8\n",
      "1796. elevenlabs  -> 8\n",
      "1797. kubectl  -> 8\n",
      "1798. kv-cache management  -> 8\n",
      "1799. whisper.cpp  -> 8\n",
      "1800. swiglu  -> 8\n",
      "1801. memory-augmented neural networks  -> 8\n",
      "1802. lambda  -> 8\n",
      "1803. data warehousing  -> 8\n",
      "1804. data quality management  -> 8\n",
      "1805. data privacy (ai)  -> 8\n",
      "1806. efficient transformers  -> 8\n",
      "1807. video reasoning  -> 8\n",
      "1808. video retrieval  -> 8\n",
      "1809. malware detection  -> 8\n",
      "1810. mapping  -> 8\n",
      "1811. agent tools  -> 8\n",
      "1812. reward engineering  -> 8\n",
      "1813. generative art  -> 8\n",
      "1814. chain-of-thought (cot) prompting  -> 8\n",
      "1815. navigation  -> 8\n",
      "1816. task planning  -> 8\n",
      "1817. biometrics  -> 8\n",
      "1818. context parallelism  -> 8\n",
      "1819. health informatics  -> 8\n",
      "1820. scalable machine learning  -> 8\n",
      "1821. llm system design  -> 8\n",
      "1822. head tracking  -> 8\n",
      "1823. frontend development  -> 8\n",
      "1824. memory management (ai)  -> 8\n",
      "1825. vlm (vision-language model)  -> 8\n",
      "1826. exllamav2  -> 8\n",
      "1827. aws cloudtrail  -> 8\n",
      "1828. aws cloudwatch  -> 8\n",
      "1829. aws ec2  -> 8\n",
      "1830. protein design  -> 8\n",
      "1831. protein folding  -> 8\n",
      "1832. open source development  -> 8\n",
      "1833. aws secrets manager  -> 8\n",
      "1834. aws neuron  -> 8\n",
      "1835. custom kernels  -> 8\n",
      "1836. cutedsl  -> 8\n",
      "1837. load testing  -> 8\n",
      "1838. computational drug discovery  -> 8\n",
      "1839. computational efficiency  -> 8\n",
      "1840. sampling strategies (llms)  -> 8\n",
      "1841. vulnerability detection  -> 8\n",
      "1842. hallucination  -> 8\n",
      "1843. gated attention  -> 8\n",
      "1844. game theory  -> 8\n",
      "1845. natural language search  -> 8\n",
      "1846. natural language to sql  -> 8\n",
      "1847. ocr (optical character recognition)  -> 8\n",
      "1848. computational neuroscience  -> 8\n",
      "1849. self-correction (ai)  -> 8\n",
      "1850. ai optimization  -> 8\n",
      "1851. penetration testing  -> 8\n",
      "1852. semantic retrieval  -> 8\n",
      "1853. training stability  -> 8\n",
      "1854. large-scale pretraining  -> 8\n",
      "1855. autonomous ai agents  -> 8\n",
      "1856. automated test generation  -> 8\n",
      "1857. retriever  -> 8\n",
      "1858. optimizer design  -> 8\n",
      "1859. animatediff  -> 8\n",
      "1860. veo 3  -> 8\n",
      "1861. paged attention  -> 8\n",
      "1862. singular value decomposition (svd)  -> 8\n",
      "1863. docker compose  -> 8\n",
      "1864. real-time machine learning  -> 8\n",
      "1865. package detection  -> 8\n",
      "1866. spacy  -> 8\n",
      "1867. relu  -> 8\n",
      "1868. ai code generation  -> 8\n",
      "1869. ai content generation  -> 8\n",
      "1870. streaming data processing  -> 8\n",
      "1871. inference engine  -> 8\n",
      "1872. monocular depth estimation  -> 8\n",
      "1873. openid connect (oidc)  -> 8\n",
      "1874. inference acceleration  -> 8\n",
      "1875. kernel programming  -> 8\n",
      "1876. self-hosting  -> 8\n",
      "1877. exl2  -> 8\n",
      "1878. self-consistency  -> 8\n",
      "1879. stochastic gradient descent (sgd)  -> 8\n",
      "1880. grounding  -> 8\n",
      "1881. long-context processing  -> 8\n",
      "1882. nvidia nim  -> 8\n",
      "1883. agent-based models  -> 8\n",
      "1884. c  -> 8\n",
      "1885. object segmentation  -> 8\n",
      "1886. mathematical reasoning (ai)  -> 8\n",
      "1887. masked language models  -> 8\n",
      "1888. dtensor  -> 8\n",
      "1889. dynamic memory compression (dmc)  -> 8\n",
      "1890. ecg analysis  -> 8\n",
      "1891. early stopping  -> 8\n",
      "1892. edge ml  -> 8\n",
      "1893. quantized inference  -> 8\n",
      "1894. audio models  -> 8\n",
      "1895. multi-agent ai  -> 8\n",
      "1896. multi-agent reinforcement learning  -> 8\n",
      "1897. data lakehouse  -> 8\n",
      "1898. red teaming (ai)  -> 8\n",
      "1899. standardscaler  -> 8\n",
      "1900. openai gpt  -> 8\n",
      "1901. automated code review  -> 8\n",
      "1902. video upscaling  -> 8\n",
      "1903. ai system architecture  -> 8\n",
      "1904. large context windows  -> 8\n",
      "1905. cognitive modeling  -> 8\n",
      "1906. cann  -> 8\n",
      "1907. character consistency  -> 8\n",
      "1908. distributed ai  -> 8\n",
      "1909. distributed reinforcement learning  -> 8\n",
      "1910. amazon opensearch service  -> 8\n",
      "1911. interactive ai  -> 8\n",
      "1912. query optimization  -> 8\n",
      "1913. amazon nova canvas  -> 8\n",
      "1914. amazon sns  -> 8\n",
      "1915. token streaming  -> 8\n",
      "1916. llm-based evaluation  -> 8\n",
      "1917. sdk  -> 8\n",
      "1918. ai chips  -> 8\n",
      "1919. high-performance networking  -> 8\n",
      "1920. high-throughput inference  -> 8\n",
      "1921. on-device deployment  -> 8\n",
      "1922. face tracking  -> 8\n",
      "1923. cpu  -> 8\n",
      "1924. cost optimization (ai)  -> 8\n",
      "1925. supply chain security  -> 8\n",
      "1926. support vector machines  -> 8\n",
      "1927. copyright compliance  -> 8\n",
      "1928. security operations (soc)  -> 8\n",
      "1929. multimodal rag  -> 8\n",
      "1930. reinforcement learning from verifiable rewards (rlvr)  -> 8\n",
      "1931. on-premise ai deployment  -> 8\n",
      "1932. liquid neural networks  -> 8\n",
      "1933. multimodal processing  -> 8\n",
      "1934. metal performance shaders (mps)  -> 8\n",
      "1935. 3d scanning  -> 8\n",
      "1936. top-k sampling  -> 8\n",
      "1937. scripting (bash)  -> 8\n",
      "1938. human activity recognition  -> 8\n",
      "1939. json parsing  -> 8\n",
      "1940. jupyter  -> 8\n",
      "1941. decision trees  -> 8\n",
      "1942. input sanitization  -> 8\n",
      "1943. information theory  -> 8\n",
      "1944. scientific ai  -> 8\n",
      "1945. spark  -> 8\n",
      "1946. radar signal processing  -> 8\n",
      "1947. agent-to-agent protocol  -> 8\n",
      "1948. directml  -> 8\n",
      "1949. dinov2  -> 8\n",
      "1950. differential testing  -> 8\n",
      "1951. jailbreak detection  -> 8\n",
      "1952. robotic control  -> 8\n",
      "1953. materials informatics  -> 8\n",
      "1954. webgl  -> 8\n",
      "1955. nvidia dynamo  -> 8\n",
      "1956. adaptive ai  -> 8\n",
      "1957. gpt-oss  -> 8\n",
      "1958. 4-bit quantization (int4)  -> 8\n",
      "1959. postprocessing  -> 8\n",
      "1960. cloud functions  -> 8\n",
      "1961. biomedical signal processing  -> 8\n",
      "1962. photogrammetry  -> 8\n",
      "1963. persistent memory  -> 8\n",
      "1964. financial analysis  -> 8\n",
      "1965. tvm  -> 8\n",
      "1966. cerebras  -> 8\n",
      "1967. model observability  -> 8\n",
      "1968. ios/macos ml (swift)  -> 8\n",
      "1969. robotaxi  -> 7\n",
      "1970. rslora  -> 7\n",
      "1971. next.js  -> 7\n",
      "1972. adversarial prompts  -> 7\n",
      "1973. text preprocessing  -> 7\n",
      "1974. text encoder  -> 7\n",
      "1975. post-quantum cryptography  -> 7\n",
      "1976. low-precision inference  -> 7\n",
      "1977. positional embeddings  -> 7\n",
      "1978. cloudflare workers  -> 7\n",
      "1979. grad-cam  -> 7\n",
      "1980. gpt4all  -> 7\n",
      "1981. adam  -> 7\n",
      "1982. 3d graphics  -> 7\n",
      "1983. accuracy  -> 7\n",
      "1984. numerical precision  -> 7\n",
      "1985. nvidia blackwell  -> 7\n",
      "1986. node embedding  -> 7\n",
      "1987. robot learning  -> 7\n",
      "1988. audio tokenization  -> 7\n",
      "1989. data parsing  -> 7\n",
      "1990. sqlite  -> 7\n",
      "1991. kv cache compression  -> 7\n",
      "1992. in-browser inference  -> 7\n",
      "1993. efficient fine-tuning  -> 7\n",
      "1994. ai-assisted debugging  -> 7\n",
      "1995. sports analytics  -> 7\n",
      "1996. umap  -> 7\n",
      "1997. data standardization  -> 7\n",
      "1998. splade  -> 7\n",
      "1999. database management  -> 7\n",
      "2000. parallelism  -> 7\n",
      "2001. ml security  -> 7\n",
      "2002. ml monitoring  -> 7\n",
      "2003. tree-of-thought  -> 7\n",
      "2004. automated debugging  -> 7\n",
      "2005. ai testing  -> 7\n",
      "2006. openai gym  -> 7\n",
      "2007. semiconductor manufacturing  -> 7\n",
      "2008. sensitive data protection  -> 7\n",
      "2009. sensor integration  -> 7\n",
      "2010. tree search  -> 7\n",
      "2011. data fabric  -> 7\n",
      "2012. pytorch lightning  -> 7\n",
      "2013. transformer engine  -> 7\n",
      "2014. open weights  -> 7\n",
      "2015. open-source ai models  -> 7\n",
      "2016. energy-efficient training  -> 7\n",
      "2017. ai tool development  -> 7\n",
      "2018. data infrastructure  -> 7\n",
      "2019. langchain4j  -> 7\n",
      "2020. language translation  -> 7\n",
      "2021. dynamodb  -> 7\n",
      "2022. econometrics  -> 7\n",
      "2023. vibe coding  -> 7\n",
      "2024. video ai  -> 7\n",
      "2025. mojo (programming language)  -> 7\n",
      "2026. monitoring & observability  -> 7\n",
      "2027. upscaling  -> 7\n",
      "2028. application load balancer  -> 7\n",
      "2029. data-centric ai  -> 7\n",
      "2030. entity recognition  -> 7\n",
      "2031. identity verification  -> 7\n",
      "2032. automatic differentiation  -> 7\n",
      "2033. transformer training  -> 7\n",
      "2034. latency  -> 7\n",
      "2035. vision fine-tuning  -> 7\n",
      "2036. self-verification  -> 7\n",
      "2037. reflection  -> 7\n",
      "2038. evaluation framework  -> 7\n",
      "2039. learning-to-rank  -> 7\n",
      "2040. performance engineering  -> 7\n",
      "2041. cypher  -> 7\n",
      "2042. training efficiency  -> 7\n",
      "2043. multimodal finetuning  -> 7\n",
      "2044. event sourcing  -> 7\n",
      "2045. multilingual processing  -> 7\n",
      "2046. open source ai development  -> 7\n",
      "2047. aws kms  -> 7\n",
      "2048. story generation  -> 7\n",
      "2049. aws waf  -> 7\n",
      "2050. tpu training  -> 7\n",
      "2051. executorch  -> 7\n",
      "2052. evolution strategies  -> 7\n",
      "2053. semantic caching  -> 7\n",
      "2054. decentralized training  -> 7\n",
      "2055. model diffing  -> 7\n",
      "2056. model caching  -> 7\n",
      "2057. async programming  -> 7\n",
      "2058. moe (mixture-of-experts)  -> 7\n",
      "2059. real-time transcription  -> 7\n",
      "2060. algorithmic trading  -> 7\n",
      "2061. deep learning architectures  -> 7\n",
      "2062. sparse training  -> 7\n",
      "2063. kalman filter  -> 7\n",
      "2064. meta-prompting  -> 7\n",
      "2065. structured data generation  -> 7\n",
      "2066. structured generation  -> 7\n",
      "2067. link prediction  -> 7\n",
      "2068. multimodal search  -> 7\n",
      "2069. one-hot encoding  -> 7\n",
      "2070. security auditing  -> 7\n",
      "2071. relation extraction (re)  -> 7\n",
      "2072. face synthesis  -> 7\n",
      "2073. fairness in machine learning  -> 7\n",
      "2074. ai memory  -> 7\n",
      "2075. ai memory management  -> 7\n",
      "2076. voice processing  -> 7\n",
      "2077. prompt injection defense  -> 7\n",
      "2078. prompt testing  -> 7\n",
      "2079. prompt versioning  -> 7\n",
      "2080. cross-entropy  -> 7\n",
      "2081. ai animation  -> 7\n",
      "2082. fairness in ml  -> 7\n",
      "2083. feature importance  -> 7\n",
      "2084. hybrid ai architectures  -> 7\n",
      "2085. jit compilation  -> 7\n",
      "2086. arima  -> 7\n",
      "2087. algorithmic reasoning  -> 7\n",
      "2088. video classification  -> 7\n",
      "2089. infiniband  -> 7\n",
      "2090. infrastructure management  -> 7\n",
      "2091. deepseek-r1  -> 7\n",
      "2092. deepfake creation  -> 7\n",
      "2093. deepfake technology  -> 7\n",
      "2094. flashinfer  -> 7\n",
      "2095. superintelligence  -> 7\n",
      "2096. conversational agents  -> 7\n",
      "2097. conversational analytics  -> 7\n",
      "2098. llm engineering  -> 7\n",
      "2099. human pose estimation  -> 7\n",
      "2100. hugging face inference endpoints  -> 7\n",
      "2101. human-centered ai  -> 7\n",
      "2102. huggingface transformers  -> 7\n",
      "2103. continuous batching  -> 7\n",
      "2104. control theory  -> 7\n",
      "2105. llm code generation  -> 7\n",
      "2106. context window management (llm)  -> 7\n",
      "2107. medical nlp  -> 7\n",
      "2108. on-device llm  -> 7\n",
      "2109. natural language inference (nli)  -> 7\n",
      "2110. context summarization  -> 7\n",
      "2111. llm quantization  -> 7\n",
      "2112. physics-based simulation  -> 7\n",
      "2113. blip-2  -> 7\n",
      "2114. ai agent frameworks  -> 7\n",
      "2115. ai avatar  -> 7\n",
      "2116. full-text search  -> 7\n",
      "2117. fully sharded data parallel (fsdp)  -> 7\n",
      "2118. ai debugging  -> 7\n",
      "2119. sparse moe  -> 7\n",
      "2120. smart contracts  -> 7\n",
      "2121. smart home automation  -> 7\n",
      "2122. sliding-window attention  -> 7\n",
      "2123. amazon bedrock agentcore runtime  -> 7\n",
      "2124. intelligent tutoring systems  -> 7\n",
      "2125. amazon personalize  -> 7\n",
      "2126. optimizer development  -> 7\n",
      "2127. model steering  -> 7\n",
      "2128. animation  -> 7\n",
      "2129. physical ai  -> 7\n",
      "2130. synthetic media detection  -> 7\n",
      "2131. constrained decoding  -> 7\n",
      "2132. token classification  -> 7\n",
      "2133. llm tool use  -> 7\n",
      "2134. requirement engineering  -> 7\n",
      "2135. framework (nemo)  -> 7\n",
      "2136. vpn  -> 7\n",
      "2137. biomedical ai  -> 7\n",
      "2138. network security  -> 7\n",
      "2139. hardware-aware optimization  -> 7\n",
      "2140. scalability (ai)  -> 7\n",
      "2141. group relative policy optimization (grpo)  -> 7\n",
      "2142. retrieval pipelines  -> 7\n",
      "2143. retrievalqa  -> 7\n",
      "2144. hardware-software integration  -> 7\n",
      "2145. process reward model  -> 7\n",
      "2146. long-context handling  -> 7\n",
      "2147. markov chains  -> 7\n",
      "2148. markov decision processes  -> 7\n",
      "2149. browser extension development  -> 7\n",
      "2150. causal reasoning  -> 7\n",
      "2151. byte-level tokenization  -> 7\n",
      "2152. long-context techniques (yarn)  -> 7\n",
      "2153. long context llms  -> 7\n",
      "2154. neural odes  -> 7\n",
      "2155. query expansion  -> 7\n",
      "2156. amazon quicksight  -> 7\n",
      "2157. alloydb  -> 7\n",
      "2158. amazon kendra  -> 7\n",
      "2159. integration testing  -> 7\n",
      "2160. model risk management  -> 7\n",
      "2161. codeact  -> 7\n",
      "2162. ternary quantization  -> 7\n",
      "2163. terraform  -> 7\n",
      "2164. cgi  -> 7\n",
      "2165. churn prediction  -> 7\n",
      "2166. ring attention  -> 7\n",
      "2167. sagemaker endpoint  -> 7\n",
      "2168. generative audio  -> 7\n",
      "2169. low-code development  -> 7\n",
      "2170. lora training  -> 7\n",
      "2171. privacy engineering  -> 7\n",
      "2172. chatgpt integration  -> 7\n",
      "2173. agent planning  -> 7\n",
      "2174. genomic ai  -> 7\n",
      "2175. graphsage  -> 7\n",
      "2176. greedy decoding  -> 7\n",
      "2177. logical reasoning  -> 7\n",
      "2178. no-code ai development  -> 7\n",
      "2179. plotly  -> 7\n",
      "2180. mathematics  -> 7\n",
      "2181. matrix multiplication optimization  -> 7\n",
      "2182. jailbreak mitigation  -> 7\n",
      "2183. document layout analysis  -> 7\n",
      "2184. social network analysis  -> 7\n",
      "2185. soar  -> 7\n",
      "2186. soc design  -> 7\n",
      "2187. ios development  -> 7\n",
      "2188. inventory optimization  -> 7\n",
      "2189. inverted file index (ivf)  -> 7\n",
      "2190. vae (variational autoencoder)  -> 7\n",
      "2191. amazon redshift  -> 7\n",
      "2192. ray tracing  -> 7\n",
      "2193. amazon textract  -> 6\n",
      "2194. 3d animation  -> 6\n",
      "2195. amazon sqs  -> 6\n",
      "2196. gpu clusters  -> 6\n",
      "2197. npu optimization  -> 6\n",
      "2198. noise suppression  -> 6\n",
      "2199. gpu inference optimization  -> 6\n",
      "2200. numerical optimization  -> 6\n",
      "2201. npc ai  -> 6\n",
      "2202. software-defined vehicles  -> 6\n",
      "2203. nvidia a100  -> 6\n",
      "2204. advantage estimation (rl)  -> 6\n",
      "2205. rotary positional encoding  -> 6\n",
      "2206. workload scheduling  -> 6\n",
      "2207. 1-bit quantization  -> 6\n",
      "2208. cli  -> 6\n",
      "2209. adversarial examples  -> 6\n",
      "2210. long context understanding  -> 6\n",
      "2211. reward hacking  -> 6\n",
      "2212. google maps api  -> 6\n",
      "2213. agent communication protocol (acp)  -> 6\n",
      "2214. privacy-enhancing technologies  -> 6\n",
      "2215. smt solvers  -> 6\n",
      "2216. vector storage  -> 6\n",
      "2217. amazon vpc  -> 6\n",
      "2218. amazon nova pro  -> 6\n",
      "2219. neural audio codec  -> 6\n",
      "2220. google cloud ai  -> 6\n",
      "2221. gmail api  -> 6\n",
      "2222. google cloud vertex ai  -> 6\n",
      "2223. iterated distillation and amplification (ida)  -> 6\n",
      "2224. isolation forest  -> 6\n",
      "2225. graph classification  -> 6\n",
      "2226. roberta  -> 6\n",
      "2227. no-code development  -> 6\n",
      "2228. web navigation  -> 6\n",
      "2229. web agents  -> 6\n",
      "2230. markdown  -> 6\n",
      "2231. graph-of-thought  -> 6\n",
      "2232. test case generation  -> 6\n",
      "2233. test-time adaptation  -> 6\n",
      "2234. agent memory management  -> 6\n",
      "2235. byte pair encoding (bpe)  -> 6\n",
      "2236. test automation  -> 6\n",
      "2237. time series models  -> 6\n",
      "2238. group relative policy optimization  -> 6\n",
      "2239. collaborative ai  -> 6\n",
      "2240. temporal-difference learning  -> 6\n",
      "2241. arm optimization  -> 6\n",
      "2242. analysis of variance (anova)  -> 6\n",
      "2243. amazon cloudfront  -> 6\n",
      "2244. vector representation  -> 6\n",
      "2245. query decomposition  -> 6\n",
      "2246. document qa  -> 6\n",
      "2247. model serialization  -> 6\n",
      "2248. amazon sagemaker hyperpod  -> 6\n",
      "2249. declarative ai programming  -> 6\n",
      "2250. amazon opensearch  -> 6\n",
      "2251. amazon opensearch serverless  -> 6\n",
      "2252. amazon q  -> 6\n",
      "2253. model weights  -> 6\n",
      "2254. generative ui  -> 6\n",
      "2255. coding assistant  -> 6\n",
      "2256. retry logic  -> 6\n",
      "2257. timm  -> 6\n",
      "2258. long-context  -> 6\n",
      "2259. risk assessment  -> 6\n",
      "2260. temporal modeling  -> 6\n",
      "2261. masked image modeling  -> 6\n",
      "2262. agentkit  -> 6\n",
      "2263. rest  -> 6\n",
      "2264. temperature scaling  -> 6\n",
      "2265. oauth 2.1  -> 6\n",
      "2266. long context handling  -> 6\n",
      "2267. color correction  -> 6\n",
      "2268. compute optimization  -> 6\n",
      "2269. temporal consistency  -> 6\n",
      "2270. compute  -> 6\n",
      "2271. system prompt design  -> 6\n",
      "2272. membership inference attacks  -> 6\n",
      "2273. physiological signal processing  -> 6\n",
      "2274. retrieval-augmented fine-tuning (raft)  -> 6\n",
      "2275. haystack  -> 6\n",
      "2276. hdbscan  -> 6\n",
      "2277. content safety  -> 6\n",
      "2278. job scheduling  -> 6\n",
      "2279. decoder-only models  -> 6\n",
      "2280. ai-generated video  -> 6\n",
      "2281. vertex ai model garden  -> 6\n",
      "2282. sparse vectors  -> 6\n",
      "2283. sparsity (ai)  -> 6\n",
      "2284. argo workflows  -> 6\n",
      "2285. kl regularization  -> 6\n",
      "2286. model verification  -> 6\n",
      "2287. deep neural networks (dnn)  -> 6\n",
      "2288. anthropic models  -> 6\n",
      "2289. user behavior modeling  -> 6\n",
      "2290. vulnerability assessment  -> 6\n",
      "2291. confidence scoring  -> 6\n",
      "2292. hierarchical clustering  -> 6\n",
      "2293. game development  -> 6\n",
      "2294. token efficiency  -> 6\n",
      "2295. pii redaction  -> 6\n",
      "2296. pipeline development  -> 6\n",
      "2297. matter  -> 6\n",
      "2298. maximum likelihood estimation  -> 6\n",
      "2299. vs code  -> 6\n",
      "2300. vs code extension  -> 6\n",
      "2301. scaling laws (ai)  -> 6\n",
      "2302. programmatic advertising  -> 6\n",
      "2303. production deployment  -> 6\n",
      "2304. hdr imaging  -> 6\n",
      "2305. vulnerability scanning  -> 6\n",
      "2306. speech editing  -> 6\n",
      "2307. sim-to-real  -> 6\n",
      "2308. kotlin  -> 6\n",
      "2309. ai-powered features  -> 6\n",
      "2310. ai-generated content detection  -> 6\n",
      "2311. alexa skill development  -> 6\n",
      "2312. unsupervised fine-tuning  -> 6\n",
      "2313. browser-based ai  -> 6\n",
      "2314. scann  -> 6\n",
      "2315. scalable systems  -> 6\n",
      "2316. content classification  -> 6\n",
      "2317. heterogeneous computing  -> 6\n",
      "2318. health data analytics  -> 6\n",
      "2319. meta llama  -> 6\n",
      "2320. personalized ai  -> 6\n",
      "2321. persona design  -> 6\n",
      "2322. persona modeling  -> 6\n",
      "2323. tool-use  -> 6\n",
      "2324. hqq quantization  -> 6\n",
      "2325. home automation  -> 6\n",
      "2326. render  -> 6\n",
      "2327. llamacpp  -> 6\n",
      "2328. ai adoption  -> 6\n",
      "2329. agi (artificial general intelligence)  -> 6\n",
      "2330. ai art generation  -> 6\n",
      "2331. token sampling  -> 6\n",
      "2332. ai content moderation  -> 6\n",
      "2333. ai control  -> 6\n",
      "2334. benchmarking & evaluation  -> 6\n",
      "2335. report generation  -> 6\n",
      "2336. conversational search  -> 6\n",
      "2337. azure ai foundry  -> 6\n",
      "2338. baseten  -> 6\n",
      "2339. context offloading  -> 6\n",
      "2340. flexattention  -> 6\n",
      "2341. supercomputing  -> 6\n",
      "2342. mlc llm  -> 6\n",
      "2343. reciprocal rank fusion (rrf)  -> 6\n",
      "2344. dataflow  -> 6\n",
      "2345. dataset annotation  -> 6\n",
      "2346. real-time streaming  -> 6\n",
      "2347. knowledge graph generation  -> 6\n",
      "2348. datadog  -> 6\n",
      "2349. openmp  -> 6\n",
      "2350. openpangu  -> 6\n",
      "2351. outlier detection  -> 6\n",
      "2352. vgg  -> 6\n",
      "2353. inference api  -> 6\n",
      "2354. meeting summarization  -> 6\n",
      "2355. memory efficiency  -> 6\n",
      "2356. symbolic planning  -> 6\n",
      "2357. swarm intelligence  -> 6\n",
      "2358. cpu inference optimization  -> 6\n",
      "2359. prompt security  -> 6\n",
      "2360. prompt injection detection  -> 6\n",
      "2361. phi-3  -> 6\n",
      "2362. memory architecture  -> 6\n",
      "2363. voice generation  -> 6\n",
      "2364. ai fairness  -> 6\n",
      "2365. copilotkit  -> 6\n",
      "2366. in-memory computing  -> 6\n",
      "2367. quantization (ai models)  -> 6\n",
      "2368. video llm  -> 6\n",
      "2369. elt  -> 6\n",
      "2370. mpi  -> 6\n",
      "2371. ueba  -> 6\n",
      "2372. ui development  -> 6\n",
      "2373. moe routing  -> 6\n",
      "2374. mojo programming  -> 6\n",
      "2375. financial modeling  -> 6\n",
      "2376. search engine development  -> 6\n",
      "2377. search indexing  -> 6\n",
      "2378. vlm (vision language models)  -> 6\n",
      "2379. tools  -> 6\n",
      "2380. bertopic  -> 6\n",
      "2381. multimodal interfaces  -> 6\n",
      "2382. ai in gaming  -> 6\n",
      "2383. search ranking  -> 6\n",
      "2384. secure enclave  -> 6\n",
      "2385. secure ai  -> 6\n",
      "2386. human-centered design  -> 6\n",
      "2387. hybrid architecture  -> 6\n",
      "2388. microservices architecture  -> 6\n",
      "2389. http apis  -> 6\n",
      "2390. hugging face (platform)  -> 6\n",
      "2391. ai app development  -> 6\n",
      "2392. behavioral modeling  -> 6\n",
      "2393. torch.distributed (gloo)  -> 6\n",
      "2394. secure coding  -> 6\n",
      "2395. faithfulness evaluation  -> 6\n",
      "2396. aws fargate  -> 6\n",
      "2397. beautifulsoup  -> 6\n",
      "2398. human-in-the-loop evaluation  -> 6\n",
      "2399. lexical semantics  -> 6\n",
      "2400. video-to-audio (v2a)  -> 6\n",
      "2401. automated code generation  -> 6\n",
      "2402. automated decision systems  -> 6\n",
      "2403. mixture of agents (moa)  -> 6\n",
      "2404. large context models  -> 6\n",
      "2405. data handling  -> 6\n",
      "2406. data sharing  -> 6\n",
      "2407. lambda functions  -> 6\n",
      "2408. language identification (lid)  -> 6\n",
      "2409. typeddict  -> 6\n",
      "2410. multitask learning  -> 6\n",
      "2411. aws iam identity center  -> 6\n",
      "2412. aws identity and access management  -> 6\n",
      "2413. crisis detection  -> 6\n",
      "2414. critical thinking  -> 6\n",
      "2415. microsoft copilot studio  -> 6\n",
      "2416. microphone array processing  -> 6\n",
      "2417. lemmatization  -> 6\n",
      "2418. large language model optimization (llmo)  -> 6\n",
      "2419. large model training  -> 6\n",
      "2420. minilm  -> 6\n",
      "2421. ai pair programming  -> 6\n",
      "2422. layout analysis  -> 6\n",
      "2423. self-hosted llms  -> 6\n",
      "2424. performance testing  -> 6\n",
      "2425. step functions  -> 6\n",
      "2426. cuda kernel development  -> 6\n",
      "2427. cuda kernels  -> 6\n",
      "2428. puppeteer  -> 6\n",
      "2429. pypdf  -> 6\n",
      "2430. data analysis (ai)  -> 6\n",
      "2431. transformers (architecture)  -> 6\n",
      "2432. latent reasoning  -> 6\n",
      "2433. ai software development  -> 6\n",
      "2434. data center architecture  -> 6\n",
      "2435. sensor data analysis  -> 6\n",
      "2436. data encryption  -> 6\n",
      "2437. data exploration  -> 6\n",
      "2438. standardization  -> 6\n",
      "2439. mobile deployment  -> 6\n",
      "2440. sentence embeddings  -> 6\n",
      "2441. data classification  -> 6\n",
      "2442. multi-hop retrieval  -> 6\n",
      "2443. multi-model orchestration  -> 6\n",
      "2444. mobile ml  -> 6\n",
      "2445. regex  -> 6\n",
      "2446. external memory  -> 6\n",
      "2447. evaluation & benchmarking  -> 6\n",
      "2448. multimodal agents  -> 6\n",
      "2449. aws inferentia  -> 6\n",
      "2450. aws strands  -> 6\n",
      "2451. multicloud  -> 6\n",
      "2452. ibm watsonx  -> 6\n",
      "2453. hypothetical document embeddings (hyde)  -> 6\n",
      "2454. troubleshooting  -> 6\n",
      "2455. ontology engineering  -> 6\n",
      "2456. multilingual embeddings  -> 6\n",
      "2457. openai evals  -> 6\n",
      "2458. refactoring  -> 6\n",
      "2459. image animation  -> 6\n",
      "2460. pyspark  -> 6\n",
      "2461. enterprise ai integration  -> 6\n",
      "2462. ai scaling laws  -> 6\n",
      "2463. training pipeline  -> 6\n",
      "2464. image compositing  -> 6\n",
      "2465. semantic layer  -> 6\n",
      "2466. encoder-decoder  -> 6\n",
      "2467. ai personalization  -> 6\n",
      "2468. semantic understanding  -> 6\n",
      "2469. multi-turn conversation  -> 6\n",
      "2470. value function estimation  -> 6\n",
      "2471. ux design  -> 6\n",
      "2472. intersection over union (iou)  -> 6\n",
      "2473. ranking  -> 6\n",
      "2474. discrete cosine transform (dct)  -> 6\n",
      "2475. xr development  -> 6\n",
      "2476. predictive ai  -> 6\n",
      "2477. jina  -> 6\n",
      "2478. deterministic inference  -> 6\n",
      "2479. text-to-image models  -> 6\n",
      "2480. text-to-lora  -> 6\n",
      "2481. graph attention network  -> 6\n",
      "2482. claude api  -> 6\n",
      "2483. webllm  -> 6\n",
      "2484. weight decay  -> 6\n",
      "2485. accessibility  -> 6\n",
      "2486. window attention  -> 6\n",
      "2487. acoustic modeling  -> 6\n",
      "2488. yfinance  -> 6\n",
      "2489. 3d mesh generation  -> 6\n",
      "2490. amazon titan text embeddings v2  -> 5\n",
      "2491. action recognition  -> 5\n",
      "2492. 3d gaussian splatting  -> 5\n",
      "2493. 3d pose estimation  -> 5\n",
      "2494. 3d environment generation  -> 5\n",
      "2495. adobe firefly  -> 5\n",
      "2496. nvidia dlss  -> 5\n",
      "2497. code agents  -> 5\n",
      "2498. code audits  -> 5\n",
      "2499. cloud computing (ai)  -> 5\n",
      "2500. clinical validation  -> 5\n",
      "2501. machine learning algorithms  -> 5\n",
      "2502. long-term memory for llms  -> 5\n",
      "2503. low-bit inference  -> 5\n",
      "2504. policy iteration  -> 5\n",
      "2505. density estimation  -> 5\n",
      "2506. dependency injection  -> 5\n",
      "2507. dependency management  -> 5\n",
      "2508. dense models  -> 5\n",
      "2509. question generation  -> 5\n",
      "2510. amazon neptune  -> 5\n",
      "2511. sageattention  -> 5\n",
      "2512. geofencing  -> 5\n",
      "2513. gnnexplainer  -> 5\n",
      "2514. ipfs  -> 5\n",
      "2515. amazon ses  -> 5\n",
      "2516. amazon simple storage service  -> 5\n",
      "2517. amd gpus  -> 5\n",
      "2518. amd ryzen ai  -> 5\n",
      "2519. amazon rds  -> 5\n",
      "2520. amazon nova lite  -> 5\n",
      "2521. wearable device development  -> 5\n",
      "2522. wearable sensor data processing  -> 5\n",
      "2523. malware analysis  -> 5\n",
      "2524. graph rag  -> 5\n",
      "2525. safety tests  -> 5\n",
      "2526. neurotechnology  -> 5\n",
      "2527. no-code ai platforms  -> 5\n",
      "2528. neural architecture  -> 5\n",
      "2529. marketing automation  -> 5\n",
      "2530. text2sql  -> 5\n",
      "2531. test-time reinforcement learning  -> 5\n",
      "2532. code embedding  -> 5\n",
      "2533. code interpretation  -> 5\n",
      "2534. agent deployment  -> 5\n",
      "2535. agent platforms  -> 5\n",
      "2536. web application firewall (waf)  -> 5\n",
      "2537. patch embedding  -> 5\n",
      "2538. parental control  -> 5\n",
      "2539. ml ops  -> 5\n",
      "2540. ml model deployment  -> 5\n",
      "2541. multilingual asr  -> 5\n",
      "2542. training data curation  -> 5\n",
      "2543. customer support automation  -> 5\n",
      "2544. ethics in ai  -> 5\n",
      "2545. semantic modeling  -> 5\n",
      "2546. entity linking  -> 5\n",
      "2547. ai privacy  -> 5\n",
      "2548. ai software engineer  -> 5\n",
      "2549. ai studio  -> 5\n",
      "2550. semantic web  -> 5\n",
      "2551. stable diffusion xl (sdxl)  -> 5\n",
      "2552. lakehouse  -> 5\n",
      "2553. ai reliability  -> 5\n",
      "2554. virtual try-on  -> 5\n",
      "2555. multi-tenant architecture  -> 5\n",
      "2556. trajectory planning  -> 5\n",
      "2557. avatar animation  -> 5\n",
      "2558. image editing (ai)  -> 5\n",
      "2559. semantic deduplication  -> 5\n",
      "2560. semantic embedding  -> 5\n",
      "2561. data leakage prevention  -> 5\n",
      "2562. data connectors  -> 5\n",
      "2563. reference-free evaluation  -> 5\n",
      "2564. recursive reasoning  -> 5\n",
      "2565. end-to-end encryption (e2ee)  -> 5\n",
      "2566. energy efficiency  -> 5\n",
      "2567. semiconductor fabrication  -> 5\n",
      "2568. ai infrastructure management  -> 5\n",
      "2569. dashboards  -> 5\n",
      "2570. mixture-of-transformers (mot)  -> 5\n",
      "2571. multi-objective optimization  -> 5\n",
      "2572. large-scale data processing  -> 5\n",
      "2573. latent space  -> 5\n",
      "2574. late interaction  -> 5\n",
      "2575. pypdfloader  -> 5\n",
      "2576. pydantic ai  -> 5\n",
      "2577. open-source model development  -> 5\n",
      "2578. open webui  -> 5\n",
      "2579. ai safety & alignment  -> 5\n",
      "2580. ai scaling  -> 5\n",
      "2581. transparency  -> 5\n",
      "2582. data center engineering  -> 5\n",
      "2583. ensemble models  -> 5\n",
      "2584. energy-based models  -> 5\n",
      "2585. mobile app development  -> 5\n",
      "2586. authorization  -> 5\n",
      "2587. sentencepiece  -> 5\n",
      "2588. sequence classification  -> 5\n",
      "2589. data center networking  -> 5\n",
      "2590. data compression  -> 5\n",
      "2591. data enrichment  -> 5\n",
      "2592. data ethics  -> 5\n",
      "2593. euclidean distance  -> 5\n",
      "2594. state tracking  -> 5\n",
      "2595. stateful agents  -> 5\n",
      "2596. data catalog  -> 5\n",
      "2597. image stylization  -> 5\n",
      "2598. open-weight llms  -> 5\n",
      "2599. multi-head self-attention  -> 5\n",
      "2600. mobile ai integration  -> 5\n",
      "2601. memory offloading  -> 5\n",
      "2602. hybrid cloud  -> 5\n",
      "2603. multimodal systems  -> 5\n",
      "2604. multimodal training  -> 5\n",
      "2605. multimodal prompting  -> 5\n",
      "2606. multimodal transformers  -> 5\n",
      "2607. multimodal understanding  -> 5\n",
      "2608. llama-server  -> 5\n",
      "2609. ai model inference  -> 5\n",
      "2610. custom kernel development  -> 5\n",
      "2611. cybersecurity ai  -> 5\n",
      "2612. legal ai  -> 5\n",
      "2613. learning to rank  -> 5\n",
      "2614. structured data  -> 5\n",
      "2615. structured logging  -> 5\n",
      "2616. cross-modal retrieval  -> 5\n",
      "2617. security testing  -> 5\n",
      "2618. self-healing systems  -> 5\n",
      "2619. experimentation  -> 5\n",
      "2620. ai in drug discovery  -> 5\n",
      "2621. performance metrics  -> 5\n",
      "2622. performance optimization (ai)  -> 5\n",
      "2623. perplexity api  -> 5\n",
      "2624. minmaxscaler  -> 5\n",
      "2625. ai in software development  -> 5\n",
      "2626. ai marketing  -> 5\n",
      "2627. azure openai service  -> 5\n",
      "2628. bag-of-words  -> 5\n",
      "2629. cross-region inference  -> 5\n",
      "2630. evidence synthesis  -> 5\n",
      "2631. self-querying retrieval  -> 5\n",
      "2632. selenium  -> 5\n",
      "2633. online rl  -> 5\n",
      "2634. fairness audits  -> 5\n",
      "2635. segmentation  -> 5\n",
      "2636. strands  -> 5\n",
      "2637. strands agents sdk  -> 5\n",
      "2638. linear programming  -> 5\n",
      "2639. license plate recognition (anpr)  -> 5\n",
      "2640. bandit algorithms  -> 5\n",
      "2641. video-to-video generation  -> 5\n",
      "2642. video surveillance  -> 5\n",
      "2643. video tracking  -> 5\n",
      "2644. automated fact-checking  -> 5\n",
      "2645. emotional ai  -> 5\n",
      "2646. embedding fine-tuning  -> 5\n",
      "2647. image similarity  -> 5\n",
      "2648. oneapi  -> 5\n",
      "2649. parametric design  -> 5\n",
      "2650. data privacy and compliance (hipaa)  -> 5\n",
      "2651. speech-to-speech processing  -> 5\n",
      "2652. data residency  -> 5\n",
      "2653. langchain.js  -> 5\n",
      "2654. large action models (lam)  -> 5\n",
      "2655. language detection  -> 5\n",
      "2656. data leakage  -> 5\n",
      "2657. aws glue data catalog  -> 5\n",
      "2658. umls  -> 5\n",
      "2659. mujoco  -> 5\n",
      "2660. openclip  -> 5\n",
      "2661. opengl  -> 5\n",
      "2662. audit trails  -> 5\n",
      "2663. auditability  -> 5\n",
      "2664. parsing  -> 5\n",
      "2665. hugging face diffusers  -> 5\n",
      "2666. hugging face ecosystem  -> 5\n",
      "2667. feedback loop  -> 5\n",
      "2668. search engine optimization (seo)  -> 5\n",
      "2669. prompt templating  -> 5\n",
      "2670. promptfoo  -> 5\n",
      "2671. motion synthesis  -> 5\n",
      "2672. motion tracking  -> 5\n",
      "2673. memory tuning  -> 5\n",
      "2674. train-test split  -> 5\n",
      "2675. tpu optimization  -> 5\n",
      "2676. ai hardware design  -> 5\n",
      "2677. ai for software engineering  -> 5\n",
      "2678. tool use (ai agents)  -> 5\n",
      "2679. tool/function calling  -> 5\n",
      "2680. tool-integrated reasoning  -> 5\n",
      "2681. voice control  -> 5\n",
      "2682. ai image editing  -> 5\n",
      "2683. humaneval  -> 5\n",
      "2684. humanoid robots  -> 5\n",
      "2685. security analytics  -> 5\n",
      "2686. security and compliance  -> 5\n",
      "2687. secure ai deployment  -> 5\n",
      "2688. memory optimization (ai)  -> 5\n",
      "2689. aws privatelink  -> 5\n",
      "2690. bayesian modeling  -> 5\n",
      "2691. torch compile  -> 5\n",
      "2692. behavior cloning  -> 5\n",
      "2693. behavioral cloning  -> 5\n",
      "2694. torchscript  -> 5\n",
      "2695. feature selection  -> 5\n",
      "2696. ai analytics  -> 5\n",
      "2697. torchserve  -> 5\n",
      "2698. conversation memory  -> 5\n",
      "2699. copilot studio  -> 5\n",
      "2700. lip-sync generation  -> 5\n",
      "2701. photorealistic image synthesis  -> 5\n",
      "2702. memory bandwidth optimization  -> 5\n",
      "2703. sycl  -> 5\n",
      "2704. high-performance computing (hpc) for ai  -> 5\n",
      "2705. efficiency optimization  -> 5\n",
      "2706. emotion detection  -> 5\n",
      "2707. efficient attention mechanisms  -> 5\n",
      "2708. data sanitization  -> 5\n",
      "2709. data strategy  -> 5\n",
      "2710. voice search  -> 5\n",
      "2711. ai education  -> 5\n",
      "2712. ai for science  -> 5\n",
      "2713. q4km  -> 5\n",
      "2714. sql generation  -> 5\n",
      "2715. sql query generation  -> 5\n",
      "2716. parameter efficient training  -> 5\n",
      "2717. openai responses api  -> 5\n",
      "2718. ai validation  -> 5\n",
      "2719. ai-generated  -> 5\n",
      "2720. imagedatagenerator  -> 5\n",
      "2721. moe architecture  -> 5\n",
      "2722. molecular design  -> 5\n",
      "2723. video frame interpolation (vfi)  -> 5\n",
      "2724. edge detection  -> 5\n",
      "2725. recall@k  -> 5\n",
      "2726. qdora  -> 5\n",
      "2727. label smoothing  -> 5\n",
      "2728. quality assurance (qa)  -> 5\n",
      "2729. quantization (4-bit)  -> 5\n",
      "2730. knowledge grounding  -> 5\n",
      "2731. knowledge integration  -> 5\n",
      "2732. recommendation engine  -> 5\n",
      "2733. reasoning ai  -> 5\n",
      "2734. finite element analysis  -> 5\n",
      "2735. finite state machines  -> 5\n",
      "2736. firmware development  -> 5\n",
      "2737. knowledge graph integration  -> 5\n",
      "2738. dataset  -> 5\n",
      "2739. model armor  -> 5\n",
      "2740. autoawq  -> 5\n",
      "2741. parallel programming  -> 5\n",
      "2742. parameter optimization  -> 5\n",
      "2743. mlx-lm  -> 5\n",
      "2744. qknorm  -> 5\n",
      "2745. finetuning (ai models)  -> 5\n",
      "2746. simclr  -> 5\n",
      "2747. simd  -> 5\n",
      "2748. siem  -> 5\n",
      "2749. inductive moment matching (imm)  -> 5\n",
      "2750. industrial iot (iiot)  -> 5\n",
      "2751. siglip  -> 5\n",
      "2752. shapley value  -> 5\n",
      "2753. high-performance inference  -> 5\n",
      "2754. network optimization  -> 5\n",
      "2755. muon optimizer  -> 5\n",
      "2756. nanogpt  -> 5\n",
      "2757. ai coding  -> 5\n",
      "2758. ai coding assistant  -> 5\n",
      "2759. backdoor detection  -> 5\n",
      "2760. bayesian optimization  -> 5\n",
      "2761. llm streaming  -> 5\n",
      "2762. content provenance  -> 5\n",
      "2763. health ai  -> 5\n",
      "2764. hallucination reduction  -> 5\n",
      "2765. hand tracking  -> 5\n",
      "2766. tls  -> 5\n",
      "2767. browser integration  -> 5\n",
      "2768. scalable ml systems  -> 5\n",
      "2769. replicate  -> 5\n",
      "2770. continuous evaluation  -> 5\n",
      "2771. memory mechanisms  -> 5\n",
      "2772. browser-based inference  -> 5\n",
      "2773. buffer of thoughts (bot)  -> 5\n",
      "2774. bring your own container (byoc)  -> 5\n",
      "2775. llm-as-judge  -> 5\n",
      "2776. llm-assisted code generation  -> 5\n",
      "2777. bellman equation  -> 5\n",
      "2778. binary quantization  -> 5\n",
      "2779. big data analytics  -> 5\n",
      "2780. formal reasoning  -> 5\n",
      "2781. warehouse automation  -> 5\n",
      "2782. ai architecture design  -> 5\n",
      "2783. high-throughput screening  -> 5\n",
      "2784. high-bandwidth memory (hbm)  -> 5\n",
      "2785. flashattention2  -> 5\n",
      "2786. llm customization  -> 5\n",
      "2787. suicide risk detection  -> 5\n",
      "2788. azure ml  -> 5\n",
      "2789. batch api  -> 5\n",
      "2790. llm planning  -> 5\n",
      "2791. context management (llm)  -> 5\n",
      "2792. contextual bandits  -> 5\n",
      "2793. sign language translation  -> 5\n",
      "2794. fp8 precision  -> 5\n",
      "2795. full fine-tuning  -> 5\n",
      "2796. reproducible research  -> 5\n",
      "2797. headless browser automation  -> 5\n",
      "2798. vq-vae  -> 5\n",
      "2799. vr development  -> 5\n",
      "2800. vs code extension development  -> 5\n",
      "2801. opensearch serverless  -> 5\n",
      "2802. model comparison  -> 5\n",
      "2803. model configuration  -> 5\n",
      "2804. audio processing (ai)  -> 5\n",
      "2805. asynchronous processing  -> 5\n",
      "2806. spatial-temporal reasoning  -> 5\n",
      "2807. spatiotemporal modeling  -> 5\n",
      "2808. shadow testing  -> 5\n",
      "2809. ai-powered tool  -> 5\n",
      "2810. speaker embedding  -> 5\n",
      "2811. ddos mitigation  -> 5\n",
      "2812. speaker verification  -> 5\n",
      "2813. kolmogorov-arnold networks (kans)  -> 5\n",
      "2814. model documentation  -> 5\n",
      "2815. model editing  -> 5\n",
      "2816. model fusion  -> 5\n",
      "2817. alexa  -> 5\n",
      "2818. vertex ai search  -> 5\n",
      "2819. argilla  -> 5\n",
      "2820. document stores  -> 5\n",
      "2821. dynamic few-shot prompting  -> 5\n",
      "2822. real-time simulation  -> 5\n",
      "2823. inference scaling  -> 5\n",
      "2824. input validation  -> 5\n",
      "2825. kahneman-tversky optimization (kto)  -> 5\n",
      "2826. jira  -> 5\n",
      "2827. jlama  -> 5\n",
      "2828. joint embedding predictive architecture (jepa)  -> 5\n",
      "2829. airflow  -> 5\n",
      "2830. hardware integration  -> 5\n",
      "2831. hardware optimization (ai)  -> 5\n",
      "2832. resnet50  -> 5\n",
      "2833. aot compilation  -> 5\n",
      "2834. model provenance  -> 5\n",
      "2835. ordinary least squares (ols)  -> 5\n",
      "2836. decision making  -> 5\n",
      "2837. sparse transformers  -> 5\n",
      "2838. sparsification  -> 5\n",
      "2839. model parallelization  -> 5\n",
      "2840. out-of-distribution detection  -> 5\n",
      "2841. generalization  -> 5\n",
      "2842. real-time data integration  -> 5\n",
      "2843. real-time image processing  -> 5\n",
      "2844. sleep stage classification  -> 5\n",
      "2845. django  -> 5\n",
      "2846. docling  -> 5\n",
      "2847. user experience (ux)  -> 5\n",
      "2848. anythingllm  -> 5\n",
      "2849. okta  -> 5\n",
      "2850. connector development  -> 5\n",
      "2851. object storage  -> 5\n",
      "2852. natural language reinforcement learning (nlrl)  -> 5\n",
      "2853. nemo guardrails  -> 5\n",
      "2854. tabbyapi  -> 5\n",
      "2855. confidence calibration  -> 5\n",
      "2856. conditional computation  -> 5\n",
      "2857. character ai  -> 5\n",
      "2858. chain-of-thought (cot) reasoning  -> 5\n",
      "2859. capacity planning  -> 5\n",
      "2860. cohere rerank  -> 5\n",
      "2861. reverse engineering  -> 5\n",
      "2862. generative engine optimization (geo)  -> 5\n",
      "2863. sagemaker canvas  -> 5\n",
      "2864. sagemaker inference  -> 5\n",
      "2865. computational chemistry  -> 5\n",
      "2866. mean average precision (map)  -> 5\n",
      "2867. mcp protocol  -> 5\n",
      "2868. mechatronics  -> 5\n",
      "2869. tiktoken  -> 5\n",
      "2870. lmstudio  -> 5\n",
      "2871. risk management  -> 5\n",
      "2872. change management  -> 5\n",
      "2873. agentops  -> 5\n",
      "2874. gemini ai  -> 5\n",
      "2875. gemini code assist  -> 5\n",
      "2876. local model hosting  -> 5\n",
      "2877. temperature sampling  -> 5\n",
      "2878. temperature tuning  -> 5\n",
      "2879. temporal difference learning  -> 5\n",
      "2880. compositing  -> 5\n",
      "2881. container management  -> 5\n",
      "2882. content summarization  -> 5\n",
      "2883. synthid  -> 5\n",
      "2884. memory management (llm)  -> 5\n",
      "2885. retinanet  -> 5\n",
      "2886. neural interface  -> 5\n",
      "2887. compiler  -> 5\n",
      "2888. computational design  -> 5\n",
      "2889. token compression  -> 5\n",
      "2890. agentic frameworks  -> 5\n",
      "2891. grouped query attention (gqa)  -> 5\n",
      "2892. tensor product attention  -> 5\n",
      "2893. tensor offload  -> 5\n",
      "2894. compiler design  -> 5\n",
      "2895. business process automation  -> 5\n",
      "2896. throughput  -> 5\n",
      "2897. question answering systems  -> 5\n",
      "2898. document indexing  -> 5\n",
      "2899. document clustering  -> 5\n",
      "2900. document embedding  -> 5\n",
      "2901. apple silicon  -> 5\n",
      "2902. api orchestration  -> 5\n",
      "2903. spatial understanding  -> 5\n",
      "2904. vehicle detection  -> 5\n",
      "2905. model guardrails  -> 5\n",
      "2906. value iteration  -> 5\n",
      "2907. dirt detection  -> 5\n",
      "2908. distributed data parallel (ddp)  -> 5\n",
      "2909. sparse autoencoders (sae)  -> 5\n",
      "2910. deepar  -> 5\n",
      "2911. k-nn  -> 5\n",
      "2912. kaggle  -> 5\n",
      "2913. sagemaker jumpstart  -> 5\n",
      "2914. sagemaker python sdk  -> 5\n",
      "2915. causal language models  -> 5\n",
      "2916. causal masking  -> 5\n",
      "2917. tilelang  -> 5\n",
      "2918. amazon efs  -> 5\n",
      "2919. amazon nova sonic  -> 5\n",
      "2920. model reliability  -> 5\n",
      "2921. gpudirect storage (gds)  -> 5\n",
      "2922. numerical stability  -> 5\n",
      "2923. non-autoregressive generation  -> 5\n",
      "2924. gpu hardware  -> 5\n",
      "2925. rope (rotary position embedding)  -> 5\n",
      "2926. normalization  -> 5\n",
      "2927. 1-bit llm  -> 5\n",
      "2928. cli tools  -> 5\n",
      "2929. low-precision training/inference  -> 5\n",
      "2930. cloud ai infrastructure  -> 5\n",
      "2931. text rendering  -> 5\n",
      "2932. inverse reinforcement learning (airl)  -> 5\n",
      "2933. instrumentation  -> 5\n",
      "2934. software composition analysis (sca)  -> 5\n",
      "2935. nucleus sampling (top-p)  -> 5\n",
      "2936. directx  -> 5\n",
      "2937. activation steering  -> 5\n",
      "2938. 3d rendering  -> 5\n",
      "2939. adapter tuning  -> 5\n",
      "2940. nvidia gpu optimization  -> 5\n",
      "2941. classification metrics  -> 5\n",
      "2942. adversarial evaluation  -> 5\n",
      "2943. robotics ai  -> 5\n",
      "2944. rpa (robotic process automation)  -> 5\n",
      "2945. gis  -> 5\n",
      "2946. agent debugging  -> 5\n",
      "2947. cognitive architecture  -> 5\n",
      "2948. problem solving (ai)  -> 5\n",
      "2949. pricing optimization  -> 5\n",
      "2950. long-context inference  -> 5\n",
      "2951. risk modeling  -> 5\n",
      "2952. governance  -> 5\n",
      "2953. value function  -> 5\n",
      "2954. model lifecycle management  -> 5\n",
      "2955. model generalization  -> 5\n",
      "2956. interpretable ai  -> 5\n",
      "2957. react agent  -> 5\n",
      "2958. semantic tool calling  -> 5\n",
      "2959. multi-vector models  -> 5\n",
      "2960. open-source ml  -> 5\n",
      "2961. ppo (proximal policy optimization)  -> 5\n",
      "2962. rag pipelines  -> 5\n",
      "2963. diarization  -> 5\n",
      "2964. difference-in-differences (did)  -> 5\n",
      "2965. diagnostic ai  -> 5\n",
      "2966. ransomware detection  -> 5\n",
      "2967. disaggregated inference  -> 5\n",
      "2968. discrete diffusion  -> 5\n",
      "2969. ci/cd for ai  -> 5\n",
      "2970. chrome devtools protocol (cdp)  -> 5\n",
      "2971. text-to-3d generation  -> 5\n",
      "2972. policy learning  -> 5\n",
      "2973. machine learning models  -> 5\n",
      "2974. machine learning pipelines  -> 5\n",
      "2975. a2a protocol  -> 5\n",
      "2976. xr  -> 5\n",
      "2977. claude 3.5  -> 5\n",
      "2978. text-to-music  -> 5\n",
      "2979. text-to-music generation  -> 5\n",
      "2980. cloudformation  -> 5\n",
      "2981. cloud sql  -> 5\n",
      "2982. rubric design  -> 5\n",
      "2983. gradient-based optimization  -> 5\n",
      "2984. cheminformatics  -> 5\n",
      "2985. nl2sql  -> 4\n",
      "2986. nist ai risk management framework  -> 4\n",
      "2987. zero-trust security  -> 4\n",
      "2988. wizardlm  -> 4\n",
      "2989. zero-shot transfer  -> 4\n",
      "2990. robustscaler  -> 4\n",
      "2991. gpu monitoring  -> 4\n",
      "2992. workflow  -> 4\n",
      "2993. yolov8  -> 4\n",
      "2994. object counting  -> 4\n",
      "2995. nvidia omniverse  -> 4\n",
      "2996. nvidia rtx  -> 4\n",
      "2997. nvidia triton  -> 4\n",
      "2998. robust ai system design  -> 4\n",
      "2999. robotics (ai)  -> 4\n",
      "3000. gpu debugging  -> 4\n",
      "3001. gpu deployment  -> 4\n",
      "3002. gpt-4o-mini  -> 4\n",
      "3003. gpu orchestration  -> 4\n",
      "3004. robot perception  -> 4\n",
      "3005. global average pooling  -> 4\n",
      "3006. glove  -> 4\n",
      "3007. rrhf  -> 4\n",
      "3008. web development  -> 4\n",
      "3009. object classification  -> 4\n",
      "3010. wearable sensor data analysis  -> 4\n",
      "3011. agent training  -> 4\n",
      "3012. neural network optimization  -> 4\n",
      "3013. neural engine  -> 4\n",
      "3014. weather forecasting  -> 4\n",
      "3015. web application security  -> 4\n",
      "3016. wearable computing  -> 4\n",
      "3017. agentworkflow  -> 4\n",
      "3018. networking  -> 4\n",
      "3019. agentic llm  -> 4\n",
      "3020. agentic planning  -> 4\n",
      "3021. wan 2.1  -> 4\n",
      "3022. agentic ai systems  -> 4\n",
      "3023. agent2agent (a2a) protocol  -> 4\n",
      "3024. ai for math  -> 4\n",
      "3025. safety evaluation  -> 4\n",
      "3026. graph embeddings  -> 4\n",
      "3027. graph fusion  -> 4\n",
      "3028. rule-based systems  -> 4\n",
      "3029. glsl  -> 4\n",
      "3030. graph convolutional networks (gcn)  -> 4\n",
      "3031. geometry processing  -> 4\n",
      "3032. geospatial ai  -> 4\n",
      "3033. geospatial reasoning  -> 4\n",
      "3034. ruby  -> 4\n",
      "3035. gpu benchmarking  -> 4\n",
      "3036. gpu utilization  -> 4\n",
      "3037. on-prem deployment  -> 4\n",
      "3038. on-premise ai  -> 4\n",
      "3039. on-demand inference  -> 4\n",
      "3040. ai compiler  -> 4\n",
      "3041. ai code review  -> 4\n",
      "3042. voice user interface design  -> 4\n",
      "3043. ai bias  -> 4\n",
      "3044. music ai  -> 4\n",
      "3045. ai avatar generation  -> 4\n",
      "3046. ai art  -> 4\n",
      "3047. ai assistant integration  -> 4\n",
      "3048. ai agent orchestration  -> 4\n",
      "3049. offline reinforcement learning  -> 4\n",
      "3050. visual-text compression  -> 4\n",
      "3051. visuomotor control  -> 4\n",
      "3052. ai bias detection  -> 4\n",
      "3053. graphstorm  -> 4\n",
      "3054. graph transformers  -> 4\n",
      "3055. graph-based workflows  -> 4\n",
      "3056. safety guardrails  -> 4\n",
      "3057. rl environments  -> 4\n",
      "3058. grounded ai  -> 4\n",
      "3059. genetic programming  -> 4\n",
      "3060. genie 3  -> 4\n",
      "3061. generative fill  -> 4\n",
      "3062. graph pruning  -> 4\n",
      "3063. graph generation  -> 4\n",
      "3064. multistep planning  -> 4\n",
      "3065. multimodal qa  -> 4\n",
      "3066. one-shot learning  -> 4\n",
      "3067. multimodel serving  -> 4\n",
      "3068. ai api integration  -> 4\n",
      "3069. ai apis  -> 4\n",
      "3070. ai cost optimization  -> 4\n",
      "3071. multimodal integration  -> 4\n",
      "3072. narrative generation  -> 4\n",
      "3073. ai operations  -> 4\n",
      "3074. ai model selection  -> 4\n",
      "3075. vision-language-action (vla)  -> 4\n",
      "3076. voice ui  -> 4\n",
      "3077. onecyclelr  -> 4\n",
      "3078. ai model analysis  -> 4\n",
      "3079. ai lifecycle management  -> 4\n",
      "3080. ai innovation  -> 4\n",
      "3081. ai in finance  -> 4\n",
      "3082. ai ides  -> 4\n",
      "3083. ai implementation  -> 4\n",
      "3084. ai safety testing  -> 4\n",
      "3085. vlsi design  -> 4\n",
      "3086. generalized preference optimization (gpo)  -> 4\n",
      "3087. gemini 2.5  -> 4\n",
      "3088. generative agents  -> 4\n",
      "3089. retriever models  -> 4\n",
      "3090. gcp cloud run  -> 4\n",
      "3091. samplers  -> 4\n",
      "3092. grpc  -> 4\n",
      "3093. grpo (group relative policy optimization)  -> 4\n",
      "3094. saliency maps  -> 4\n",
      "3095. retrieval models  -> 4\n",
      "3096. gemini 2.5 flash  -> 4\n",
      "3097. gemini 2.5 flash image  -> 4\n",
      "3098. sagemaker unified studio  -> 4\n",
      "3099. multi-party computation  -> 4\n",
      "3100. ai safety & guardrails  -> 4\n",
      "3101. vision  -> 4\n",
      "3102. virtual private cloud  -> 4\n",
      "3103. multiclass classification  -> 4\n",
      "3104. ai performance metrics  -> 4\n",
      "3105. ai platform development  -> 4\n",
      "3106. video-to-audio generation  -> 4\n",
      "3107. multi-model systems  -> 4\n",
      "3108. multi-node training  -> 4\n",
      "3109. ai robustness  -> 4\n",
      "3110. multi-llm orchestration  -> 4\n",
      "3111. multi-gpu scaling  -> 4\n",
      "3112. openai models  -> 4\n",
      "3113. multi-hop qa  -> 4\n",
      "3114. multi-image fusion  -> 4\n",
      "3115. ai product  -> 4\n",
      "3116. ai summarization  -> 4\n",
      "3117. ai voice assistant  -> 4\n",
      "3118. openai-compatible api  -> 4\n",
      "3119. sandbox execution  -> 4\n",
      "3120. satellite imagery analysis  -> 4\n",
      "3121. hd mapping  -> 4\n",
      "3122. scalability engineering  -> 4\n",
      "3123. hierarchical planning  -> 4\n",
      "3124. hellaswag  -> 4\n",
      "3125. gymnasium  -> 4\n",
      "3126. multi-agent architecture  -> 4\n",
      "3127. motion transfer  -> 4\n",
      "3128. ai workflow design  -> 4\n",
      "3129. motion generation  -> 4\n",
      "3130. ai translation  -> 4\n",
      "3131. multi-agent workflows  -> 4\n",
      "3132. ai system integration  -> 4\n",
      "3133. ai system monitoring  -> 4\n",
      "3134. motion control  -> 4\n",
      "3135. air-gapped deployment  -> 4\n",
      "3136. aitemplate  -> 4\n",
      "3137. ai text detection  -> 4\n",
      "3138. molecular property prediction  -> 4\n",
      "3139. ai voice cloning  -> 4\n",
      "3140. openinterpreter  -> 4\n",
      "3141. video-language models  -> 4\n",
      "3142. video stabilization  -> 4\n",
      "3143. video denoising  -> 4\n",
      "3144. ai-assisted programming  -> 4\n",
      "3145. ai-driven automation  -> 4\n",
      "3146. ai-assisted code review  -> 4\n",
      "3147. moderation systems  -> 4\n",
      "3148. model-based reinforcement learning  -> 4\n",
      "3149. model traceability  -> 4\n",
      "3150. video super-resolution  -> 4\n",
      "3151. video question answering  -> 4\n",
      "3152. hidden markov models  -> 4\n",
      "3153. scaled dot-product attention  -> 4\n",
      "3154. scaling  -> 4\n",
      "3155. scalable model serving  -> 4\n",
      "3156. request batching  -> 4\n",
      "3157. schema design  -> 4\n",
      "3158. fp32  -> 4\n",
      "3159. frame generation  -> 4\n",
      "3160. scalable oversight  -> 4\n",
      "3161. hardware security  -> 4\n",
      "3162. scene graph generation  -> 4\n",
      "3163. optax  -> 4\n",
      "3164. amazon bedrock data automation  -> 4\n",
      "3165. amazon augmented ai (a2i)  -> 4\n",
      "3166. algorithmic bias  -> 4\n",
      "3167. orbax  -> 4\n",
      "3168. optoelectronics  -> 4\n",
      "3169. alexa skills kit (ask)  -> 4\n",
      "3170. verl  -> 4\n",
      "3171. optics  -> 4\n",
      "3172. vertex ai sdk  -> 4\n",
      "3173. amazon titan  -> 4\n",
      "3174. amazon titan embeddings  -> 4\n",
      "3175. alltoall communication  -> 4\n",
      "3176. amazon polly  -> 4\n",
      "3177. amazon q developer  -> 4\n",
      "3178. amazon nova reel  -> 4\n",
      "3179. amazon sagemaker ai  -> 4\n",
      "3180. v-jepa  -> 4\n",
      "3181. vector similarity  -> 4\n",
      "3182. amazon bedrock converse api  -> 4\n",
      "3183. model performance optimization  -> 4\n",
      "3184. fp4 quantization  -> 4\n",
      "3185. formal methods  -> 4\n",
      "3186. sdk integration  -> 4\n",
      "3187. reproducible ai  -> 4\n",
      "3188. reliability engineering  -> 4\n",
      "3189. second-order optimization  -> 4\n",
      "3190. secure aggregation  -> 4\n",
      "3191. research  -> 4\n",
      "3192. residual connections  -> 4\n",
      "3193. secure multi-party computation  -> 4\n",
      "3194. model licensing  -> 4\n",
      "3195. model lineage  -> 4\n",
      "3196. user profiling  -> 4\n",
      "3197. osint  -> 4\n",
      "3198. user preference modeling  -> 4\n",
      "3199. aotinductor  -> 4\n",
      "3200. apache airflow  -> 4\n",
      "3201. animal detection  -> 4\n",
      "3202. amazon emr  -> 4\n",
      "3203. user segmentation  -> 4\n",
      "3204. model ensemble  -> 4\n",
      "3205. owl  -> 4\n",
      "3206. apache beam  -> 4\n",
      "3207. apache flink  -> 4\n",
      "3208. apache iceberg  -> 4\n",
      "3209. ann search  -> 4\n",
      "3210. analytics  -> 4\n",
      "3211. model efficiency optimization  -> 4\n",
      "3212. api development (ai)  -> 4\n",
      "3213. arm architecture  -> 4\n",
      "3214. output filtering  -> 4\n",
      "3215. assistant prefilling  -> 4\n",
      "3216. audio preprocessing  -> 4\n",
      "3217. apache kafka  -> 4\n",
      "3218. hugging face platform  -> 4\n",
      "3219. hugging face trl  -> 4\n",
      "3220. hugging face optimum  -> 4\n",
      "3221. feature pyramid network (fpn)  -> 4\n",
      "3222. feature steering  -> 4\n",
      "3223. fastembed  -> 4\n",
      "3224. human oversight  -> 4\n",
      "3225. hugging face pipelines  -> 4\n",
      "3226. fastai  -> 4\n",
      "3227. secure software development  -> 4\n",
      "3228. secure code execution  -> 4\n",
      "3229. secure code generation  -> 4\n",
      "3230. huawei ascend  -> 4\n",
      "3231. hybrid model  -> 4\n",
      "3232. foundation models (fms)  -> 4\n",
      "3233. forced alignment (mfa)  -> 4\n",
      "3234. full-stack development  -> 4\n",
      "3235. reranker  -> 4\n",
      "3236. fasttext  -> 4\n",
      "3237. model adaptation  -> 4\n",
      "3238. approximate nearest neighbor search  -> 4\n",
      "3239. applied ai  -> 4\n",
      "3240. unslothai  -> 4\n",
      "3241. arrhythmia detection  -> 4\n",
      "3242. artificial superintelligence (asi)  -> 4\n",
      "3243. audio fingerprinting  -> 4\n",
      "3244. audio intelligence  -> 4\n",
      "3245. ar (augmented reality)  -> 4\n",
      "3246. selective classification  -> 4\n",
      "3247. security command center  -> 4\n",
      "3248. security monitoring  -> 4\n",
      "3249. face generation  -> 4\n",
      "3250. segment anything model (sam)  -> 4\n",
      "3251. seldon core  -> 4\n",
      "3252. self-driving cars  -> 4\n",
      "3253. fairness & bias mitigation  -> 4\n",
      "3254. fact verification  -> 4\n",
      "3255. financial nlp  -> 4\n",
      "3256. attention optimization  -> 4\n",
      "3257. parameter efficiency  -> 4\n",
      "3258. ui generation  -> 4\n",
      "3259. ui testing  -> 4\n",
      "3260. uav autonomy  -> 4\n",
      "3261. audio encoding  -> 4\n",
      "3262. ui/ux for ai  -> 4\n",
      "3263. attention masks  -> 4\n",
      "3264. attention models  -> 4\n",
      "3265. audience segmentation  -> 4\n",
      "3266. ml model training  -> 4\n",
      "3267. ml frameworks  -> 4\n",
      "3268. ml governance  -> 4\n",
      "3269. unity  -> 4\n",
      "3270. parlant  -> 4\n",
      "3271. part-of-speech tagging  -> 4\n",
      "3272. trust & safety  -> 4\n",
      "3273. auditing  -> 4\n",
      "3274. audio-to-video generation  -> 4\n",
      "3275. audio-language model  -> 4\n",
      "3276. automated prompt optimization  -> 4\n",
      "3277. mobilenet  -> 4\n",
      "3278. mobile app integration  -> 4\n",
      "3279. parent document retrieval  -> 4\n",
      "3280. ml deployment  -> 4\n",
      "3281. mixture-of-agents  -> 4\n",
      "3282. mixture-of-recursions  -> 4\n",
      "3283. audiovisual alignment  -> 4\n",
      "3284. ethernet networking  -> 4\n",
      "3285. reft  -> 4\n",
      "3286. regional prompting  -> 4\n",
      "3287. regression models  -> 4\n",
      "3288. iam role  -> 4\n",
      "3289. event streams  -> 4\n",
      "3290. entity deduplication  -> 4\n",
      "3291. enterprise ai solutions  -> 4\n",
      "3292. enterprise data integration  -> 4\n",
      "3293. identity preservation  -> 4\n",
      "3294. identity resolution  -> 4\n",
      "3295. human-in-the-loop ml  -> 4\n",
      "3296. relevance ranking  -> 4\n",
      "3297. ml workflow  -> 4\n",
      "3298. automated grading  -> 4\n",
      "3299. automated incident response  -> 4\n",
      "3300. mixup  -> 4\n",
      "3301. ml benchmarking  -> 4\n",
      "3302. autofocus algorithms  -> 4\n",
      "3303. mixed precision (fp16/bf16)  -> 4\n",
      "3304. automated machine learning  -> 4\n",
      "3305. autoregressive image models  -> 4\n",
      "3306. transcriptomics  -> 4\n",
      "3307. mistral ai  -> 4\n",
      "3308. minicoil  -> 4\n",
      "3309. peft (parameter-efficient finetuning)  -> 4\n",
      "3310. trajectory optimization  -> 4\n",
      "3311. autonomous robotics  -> 4\n",
      "3312. pddl  -> 4\n",
      "3313. pdf extraction  -> 4\n",
      "3314. microvms  -> 4\n",
      "3315. aws x-ray  -> 4\n",
      "3316. traceability  -> 4\n",
      "3317. microsoft 365 integration  -> 4\n",
      "3318. autoregressive decoding  -> 4\n",
      "3319. image denoising  -> 4\n",
      "3320. image description  -> 4\n",
      "3321. image annotation  -> 4\n",
      "3322. image generation (ai)  -> 4\n",
      "3323. end-to-end training  -> 4\n",
      "3324. end-to-end learning  -> 4\n",
      "3325. image colorization  -> 4\n",
      "3326. image compression  -> 4\n",
      "3327. semantic code search  -> 4\n",
      "3328. self-improving ai  -> 4\n",
      "3329. ensemble learning  -> 4\n",
      "3330. meta-reasoning  -> 4\n",
      "3331. metadata extraction  -> 4\n",
      "3332. training loop  -> 4\n",
      "3333. micronaut  -> 4\n",
      "3334. tool integration for llms  -> 4\n",
      "3335. personalized recommendations  -> 4\n",
      "3336. aws deep learning containers (dlc)  -> 4\n",
      "3337. persona engineering  -> 4\n",
      "3338. message passing neural networks (mpnn)  -> 4\n",
      "3339. message queues  -> 4\n",
      "3340. meta ai  -> 4\n",
      "3341. bentoml  -> 4\n",
      "3342. benchmark testing  -> 4\n",
      "3343. memory-augmented agents  -> 4\n",
      "3344. memory-augmented llms  -> 4\n",
      "3345. topology-aware scheduling  -> 4\n",
      "3346. personalization ai  -> 4\n",
      "3347. personalization algorithms  -> 4\n",
      "3348. battery management systems  -> 4\n",
      "3349. base64 encoding  -> 4\n",
      "3350. azure table storage  -> 4\n",
      "3351. memory-efficient fine-tuning  -> 4\n",
      "3352. mesh processing  -> 4\n",
      "3353. bayesian linear regression  -> 4\n",
      "3354. bayesian methods  -> 4\n",
      "3355. embedding-based retrieval  -> 4\n",
      "3356. recursive agents  -> 4\n",
      "3357. embedded ml  -> 4\n",
      "3358. embedded vision  -> 4\n",
      "3359. image-to-3d  -> 4\n",
      "3360. elmo  -> 4\n",
      "3361. efficient model training  -> 4\n",
      "3362. embedding quantization  -> 4\n",
      "3363. self-training  -> 4\n",
      "3364. semantic analysis  -> 4\n",
      "3365. image moderation  -> 4\n",
      "3366. phishing detection  -> 4\n",
      "3367. photorealistic rendering  -> 4\n",
      "3368. personalized learning  -> 4\n",
      "3369. blip  -> 4\n",
      "3370. bit-lora  -> 4\n",
      "3371. bioinformatics ai  -> 4\n",
      "3372. big data processing  -> 4\n",
      "3373. bias evaluation  -> 4\n",
      "3374. bias testing  -> 4\n",
      "3375. bfloat16 (bf16)  -> 4\n",
      "3376. tool design  -> 4\n",
      "3377. cache optimization  -> 4\n",
      "3378. broadcasts  -> 4\n",
      "3379. bidirectional streaming  -> 4\n",
      "3380. recommendation algorithm  -> 4\n",
      "3381. ecapa-tdnn  -> 4\n",
      "3382. dynamics modeling  -> 4\n",
      "3383. educational technology  -> 4\n",
      "3384. image tokenization  -> 4\n",
      "3385. dynamic retrieval  -> 4\n",
      "3386. dynamic weight quantization (dwq)  -> 4\n",
      "3387. dynamic workload scheduler (dws)  -> 4\n",
      "3388. maxtext  -> 4\n",
      "3389. c/c++  -> 4\n",
      "3390. c2pa  -> 4\n",
      "3391. cache management  -> 4\n",
      "3392. pix2struct  -> 4\n",
      "3393. plan validation (val)  -> 4\n",
      "3394. tinyml  -> 4\n",
      "3395. mediapipe  -> 4\n",
      "3396. bm25 retrieval  -> 4\n",
      "3397. mcmc sampling  -> 4\n",
      "3398. mcp (model control protocol)  -> 4\n",
      "3399. maxabsscaler  -> 4\n",
      "3400. math  -> 4\n",
      "3401. mathematical ai  -> 4\n",
      "3402. token context window  -> 4\n",
      "3403. mask r-cnn  -> 4\n",
      "3404. timesfm  -> 4\n",
      "3405. causal training  -> 4\n",
      "3406. cbam  -> 4\n",
      "3407. mathematical modeling  -> 4\n",
      "3408. matching algorithms  -> 4\n",
      "3409. causal discovery  -> 4\n",
      "3410. c programming  -> 4\n",
      "3411. thunderkittens  -> 4\n",
      "3412. threat hunting  -> 4\n",
      "3413. three.js  -> 4\n",
      "3414. chat templates  -> 4\n",
      "3415. thermal management  -> 4\n",
      "3416. causal analysis  -> 4\n",
      "3417. real-time speech translation  -> 4\n",
      "3418. real-time video analytics  -> 4\n",
      "3419. inference cost optimization  -> 4\n",
      "3420. inference engine development  -> 4\n",
      "3421. dynamic batching  -> 4\n",
      "3422. industrial ai  -> 4\n",
      "3423. inception  -> 4\n",
      "3424. infrastructure  -> 4\n",
      "3425. infonce loss  -> 4\n",
      "3426. industrial automation  -> 4\n",
      "3427. image registration  -> 4\n",
      "3428. in-browser ai  -> 4\n",
      "3429. information retrieval (ai)  -> 4\n",
      "3430. postgres  -> 4\n",
      "3431. chi-square test  -> 4\n",
      "3432. positional skip-wise (pose)  -> 4\n",
      "3433. policy evaluation  -> 4\n",
      "3434. text-to-video models  -> 4\n",
      "3435. chat completion api  -> 4\n",
      "3436. chain-of-thought monitoring  -> 4\n",
      "3437. machine vision  -> 4\n",
      "3438. machine learning training  -> 4\n",
      "3439. cloud logging  -> 4\n",
      "3440. machine learning frameworks  -> 4\n",
      "3441. camera calibration  -> 4\n",
      "3442. singing voice synthesis  -> 4\n",
      "3443. dowhy  -> 4\n",
      "3444. inference speed optimization  -> 4\n",
      "3445. documentation generation  -> 4\n",
      "3446. dynamic graph neural networks  -> 4\n",
      "3447. site reliability engineering (sre)  -> 4\n",
      "3448. sketch-to-image  -> 4\n",
      "3449. slot filling  -> 4\n",
      "3450. sleep analysis  -> 4\n",
      "3451. drone autonomy  -> 4\n",
      "3452. sim2real  -> 4\n",
      "3453. document processing (ai)  -> 4\n",
      "3454. document question answering  -> 4\n",
      "3455. low-rank approximation  -> 4\n",
      "3456. low-latency systems  -> 4\n",
      "3457. low-light image enhancement  -> 4\n",
      "3458. cloud gpu  -> 4\n",
      "3459. cloud integration  -> 4\n",
      "3460. post-training optimization  -> 4\n",
      "3461. machine learning infrastructure  -> 4\n",
      "3462. citation generation  -> 4\n",
      "3463. preference alignment  -> 4\n",
      "3464. looker  -> 4\n",
      "3465. climate modeling  -> 4\n",
      "3466. claude opus 4.1  -> 4\n",
      "3467. cloud architecture  -> 4\n",
      "3468. clinical decision support systems  -> 4\n",
      "3469. presentation generation  -> 4\n",
      "3470. loss function engineering  -> 4\n",
      "3471. cloud ml platform  -> 4\n",
      "3472. cloud monitoring  -> 4\n",
      "3473. long-context training  -> 4\n",
      "3474. text prompt  -> 4\n",
      "3475. cloudwatch metrics  -> 4\n",
      "3476. logging and auditing  -> 4\n",
      "3477. code review automation  -> 4\n",
      "3478. instrumental variables  -> 4\n",
      "3479. distributed ai systems  -> 4\n",
      "3480. distributed checkpointing (dcp)  -> 4\n",
      "3481. intelligent agents  -> 4\n",
      "3482. dinov3  -> 4\n",
      "3483. digital signatures  -> 4\n",
      "3484. distributed data parallelism  -> 4\n",
      "3485. distributed file systems  -> 4\n",
      "3486. real-time personalization  -> 4\n",
      "3487. real-time recommendations  -> 4\n",
      "3488. sip  -> 4\n",
      "3489. directx 12  -> 4\n",
      "3490. cohere embeddings  -> 4\n",
      "3491. colab  -> 4\n",
      "3492. codellm  -> 4\n",
      "3493. collective communication  -> 4\n",
      "3494. tesseract  -> 4\n",
      "3495. test  -> 4\n",
      "3496. code evaluation  -> 4\n",
      "3497. testing and validation  -> 4\n",
      "3498. test-time compute scaling  -> 4\n",
      "3499. codebase analysis  -> 4\n",
      "3500. temperature  -> 4\n",
      "3501. code models  -> 4\n",
      "3502. rdf  -> 4\n",
      "3503. react (reasoning and acting)  -> 4\n",
      "3504. rationale compression  -> 4\n",
      "3505. digital health  -> 4\n",
      "3506. differentiable physics  -> 4\n",
      "3507. differential attention  -> 4\n",
      "3508. dexterous manipulation  -> 4\n",
      "3509. directed acyclic graph (dag)  -> 4\n",
      "3510. randomized controlled trial  -> 4\n",
      "3511. real-time animation  -> 4\n",
      "3512. real-time control  -> 4\n",
      "3513. real-time data pipelines  -> 4\n",
      "3514. react pattern  -> 4\n",
      "3515. dialogue generation  -> 4\n",
      "3516. production monitoring  -> 4\n",
      "3517. procedural generation  -> 4\n",
      "3518. process optimization  -> 4\n",
      "3519. localai  -> 4\n",
      "3520. temporal coherence  -> 4\n",
      "3521. lm evaluation harness  -> 4\n",
      "3522. tekton  -> 4\n",
      "3523. target encoding  -> 4\n",
      "3524. competitive intelligence  -> 4\n",
      "3525. comet  -> 4\n",
      "3526. programming  -> 4\n",
      "3527. congestion control  -> 4\n",
      "3528. connection pooling  -> 4\n",
      "3529. consistency models  -> 4\n",
      "3530. llm testing  -> 4\n",
      "3531. confidence estimation  -> 4\n",
      "3532. confidence interval  -> 4\n",
      "3533. concept drift detection  -> 4\n",
      "3534. product quantization (pq)  -> 4\n",
      "3535. task orchestration  -> 4\n",
      "3536. t-test  -> 4\n",
      "3537. computational fluid dynamics  -> 4\n",
      "3538. configuration management  -> 4\n",
      "3539. conda  -> 4\n",
      "3540. context length handling  -> 4\n",
      "3541. context length management  -> 4\n",
      "3542. llm prompt  -> 4\n",
      "3543. sparql  -> 4\n",
      "3544. sparse activation  -> 4\n",
      "3545. detection engineering  -> 4\n",
      "3546. detectron2  -> 4\n",
      "3547. sound recognition  -> 4\n",
      "3548. software supply chain security  -> 4\n",
      "3549. social media analysis  -> 4\n",
      "3550. desktop automation  -> 4\n",
      "3551. llm interpretability  -> 4\n",
      "3552. table parsing  -> 4\n",
      "3553. llm memory management  -> 4\n",
      "3554. llm monitoring  -> 4\n",
      "3555. system prompt learning (spl)  -> 4\n",
      "3556. continuous training  -> 4\n",
      "3557. conversation design  -> 4\n",
      "3558. swe-bench  -> 4\n",
      "3559. prompt distillation  -> 4\n",
      "3560. llm chains  -> 4\n",
      "3561. context-aware systems  -> 4\n",
      "3562. context window handling  -> 4\n",
      "3563. llama api  -> 4\n",
      "3564. container security  -> 4\n",
      "3565. jsonl  -> 4\n",
      "3566. julia  -> 4\n",
      "3567. jvm  -> 4\n",
      "3568. json schema validation  -> 4\n",
      "3569. dense vectors  -> 4\n",
      "3570. dense layers  -> 4\n",
      "3571. defect detection  -> 4\n",
      "3572. deep research  -> 4\n",
      "3573. query generation  -> 4\n",
      "3574. query refinement  -> 4\n",
      "3575. denclue  -> 4\n",
      "3576. spatial grounding  -> 4\n",
      "3577. stylegan  -> 4\n",
      "3578. stress testing  -> 4\n",
      "3579. coqui tts  -> 4\n",
      "3580. coreset selection  -> 4\n",
      "3581. copyright infringement  -> 4\n",
      "3582. cross-encoder reranking  -> 4\n",
      "3583. llama model  -> 4\n",
      "3584. liquid cooling  -> 4\n",
      "3585. live translation  -> 4\n",
      "3586. conversationalretrievalchain  -> 4\n",
      "3587. converse api  -> 4\n",
      "3588. structured output parsing  -> 4\n",
      "3589. lightgbm  -> 4\n",
      "3590. lidar navigation  -> 4\n",
      "3591. lidar processing  -> 4\n",
      "3592. cross-modal alignment  -> 4\n",
      "3593. surrogate modeling  -> 4\n",
      "3594. custom cuda kernels  -> 4\n",
      "3595. prophet  -> 4\n",
      "3596. prosody modeling  -> 4\n",
      "3597. storage optimization  -> 4\n",
      "3598. stdio  -> 4\n",
      "3599. credential management  -> 4\n",
      "3600. credibility assessment  -> 4\n",
      "3601. structured data processing  -> 4\n",
      "3602. custom gpt  -> 4\n",
      "3603. protocol translation  -> 4\n",
      "3604. data-efficient training  -> 4\n",
      "3605. debugging (ai)  -> 4\n",
      "3606. dax  -> 4\n",
      "3607. dbscan  -> 4\n",
      "3608. kernel profiling  -> 4\n",
      "3609. keda  -> 4\n",
      "3610. specification gaming  -> 4\n",
      "3611. speaker identification  -> 4\n",
      "3612. debiasing  -> 4\n",
      "3613. question answering (qa)  -> 4\n",
      "3614. stateful workflows  -> 4\n",
      "3615. static application security testing (sast)  -> 4\n",
      "3616. latent variable models  -> 4\n",
      "3617. dagster  -> 4\n",
      "3618. cutmix  -> 4\n",
      "3619. cybernetics  -> 4\n",
      "3620. stemming  -> 4\n",
      "3621. protein generation  -> 4\n",
      "3622. protocol design  -> 4\n",
      "3623. static quantization  -> 4\n",
      "3624. cute  -> 4\n",
      "3625. provision throughput  -> 4\n",
      "3626. large multimodal model  -> 4\n",
      "3627. pymc  -> 4\n",
      "3628. layer offloading  -> 4\n",
      "3629. late-interaction retrieval  -> 4\n",
      "3630. large scale model training  -> 4\n",
      "3631. data pruning  -> 4\n",
      "3632. language model training  -> 4\n",
      "3633. knowledge graph embedding  -> 4\n",
      "3634. speech models  -> 4\n",
      "3635. quarkus  -> 4\n",
      "3636. quantization aware training (qat)  -> 4\n",
      "3637. spmd  -> 4\n",
      "3638. data synchronization  -> 4\n",
      "3639. database querying  -> 4\n",
      "3640. data retrieval  -> 4\n",
      "3641. knowledge graph reasoning  -> 4\n",
      "3642. knowledge engineering  -> 4\n",
      "3643. quantized training  -> 4\n",
      "3644. decoding  -> 4\n",
      "3645. data streaming  -> 4\n",
      "3646. data structuring  -> 4\n",
      "3647. data scraping  -> 4\n",
      "3648. langchain agents  -> 4\n",
      "3649. pytorch distributed  -> 4\n",
      "3650. data indexing  -> 4\n",
      "3651. data privacy compliance  -> 4\n",
      "3652. data federation  -> 4\n",
      "3653. data forensics  -> 4\n",
      "3654. data engineering for ml  -> 4\n",
      "3655. langgraph.js  -> 4\n",
      "3656. lag features  -> 4\n",
      "3657. data compliance  -> 4\n",
      "3658. data center management  -> 4\n",
      "3659. stable diffusion xl  -> 4\n",
      "3660. data drift  -> 4\n",
      "3661. quantitative finance  -> 4\n",
      "3662. q4 quantization  -> 4\n",
      "3663. data poisoning mitigation  -> 4\n",
      "3664. data pipeline development  -> 4\n",
      "3665. l1 regularization  -> 4\n",
      "3666. l2 regularization  -> 4\n",
      "3667. speech ai  -> 4\n",
      "3668. dataset generation  -> 4\n",
      "3669. dataops  -> 4\n",
      "3670. dataproc  -> 4\n",
      "3671. neuro-symbolic methods  -> 4\n",
      "3672. nvidia cuda  -> 4\n",
      "3673. no-code automation  -> 4\n",
      "3674. webhooks  -> 4\n",
      "3675. neural signal processing  -> 4\n",
      "3676. adaptive inference  -> 4\n",
      "3677. workflow design  -> 4\n",
      "3678. accelerated computing  -> 4\n",
      "3679. 3d simulation  -> 4\n",
      "3680. windows ml  -> 4\n",
      "3681. 3d segmentation  -> 4\n",
      "3682. 2-bit quantization  -> 4\n",
      "3683. npu acceleration  -> 4\n",
      "3684. xlstm  -> 4\n",
      "3685. word2vec  -> 4\n",
      "3686. neuroprosthetics  -> 3\n",
      "3687. 3d scene reconstruction  -> 3\n",
      "3688. 3d world generation  -> 3\n",
      "3689. workflow management  -> 3\n",
      "3690. 3d convolution  -> 3\n",
      "3691. 3d deep learning  -> 3\n",
      "3692. xnnpack  -> 3\n",
      "3693. xml processing  -> 3\n",
      "3694. 2d animation  -> 3\n",
      "3695. 3  -> 3\n",
      "3696. rotary positional encoding (rope)  -> 3\n",
      "3697. rolling window features  -> 3\n",
      "3698. rlcard  -> 3\n",
      "3699. gke inference gateway  -> 3\n",
      "3700. gpt-4.5  -> 3\n",
      "3701. google workspace  -> 3\n",
      "3702. google tpu  -> 3\n",
      "3703. google kubernetes engine  -> 3\n",
      "3704. activation quantization  -> 3\n",
      "3705. acktr  -> 3\n",
      "3706. acoustic event detection  -> 3\n",
      "3707. acoustic signal processing  -> 3\n",
      "3708. workflow automation (ai)  -> 3\n",
      "3709. routing  -> 3\n",
      "3710. rotary embeddings  -> 3\n",
      "3711. rotary position embedding  -> 3\n",
      "3712. agent payments protocol (ap2)  -> 3\n",
      "3713. neural network inference  -> 3\n",
      "3714. neural engineering  -> 3\n",
      "3715. neural mmo  -> 3\n",
      "3716. neural compression  -> 3\n",
      "3717. wearable sensor processing  -> 3\n",
      "3718. agent-based reasoning  -> 3\n",
      "3719. agent-based simulation  -> 3\n",
      "3720. agent building  -> 3\n",
      "3721. agent coordination  -> 3\n",
      "3722. agent ai  -> 3\n",
      "3723. adversarial regularization  -> 3\n",
      "3724. adversarial analysis  -> 3\n",
      "3725. web3  -> 3\n",
      "3726. agent tool integration  -> 3\n",
      "3727. agent tool use  -> 3\n",
      "3728. speechbrain  -> 3\n",
      "3729. quantisation  -> 3\n",
      "3730. q8 quantization  -> 3\n",
      "3731. qat (quantization-aware training)  -> 3\n",
      "3732. speech-to-speech model  -> 3\n",
      "3733. data optimization  -> 3\n",
      "3734. data orchestration  -> 3\n",
      "3735. ssm-transformer  -> 3\n",
      "3736. labels  -> 3\n",
      "3737. kv quantization  -> 3\n",
      "3738. kubernetes operator  -> 3\n",
      "3739. kullback-leibler divergence  -> 3\n",
      "3740. language model evaluation  -> 3\n",
      "3741. data contamination detection  -> 3\n",
      "3742. spring ai  -> 3\n",
      "3743. spss  -> 3\n",
      "3744. data loading  -> 3\n",
      "3745. data logging  -> 3\n",
      "3746. data masking  -> 3\n",
      "3747. data mesh  -> 3\n",
      "3748. data literacy  -> 3\n",
      "3749. data integrity  -> 3\n",
      "3750. data governance (ai)  -> 3\n",
      "3751. data harmonization  -> 3\n",
      "3752. neural simulation  -> 3\n",
      "3753. neural world models  -> 3\n",
      "3754. neuro-symbolic reasoning  -> 3\n",
      "3755. nvidia h200  -> 3\n",
      "3756. nvidia jetson  -> 3\n",
      "3757. nf4  -> 3\n",
      "3758. nim  -> 3\n",
      "3759. dataset distillation  -> 3\n",
      "3760. data sovereignty  -> 3\n",
      "3761. dataset construction  -> 3\n",
      "3762. database optimization  -> 3\n",
      "3763. knowledge representation (ai)  -> 3\n",
      "3764. knowledge synthesis  -> 3\n",
      "3765. knowledge tracing  -> 3\n",
      "3766. knowledge graph extraction  -> 3\n",
      "3767. speech-to-animation  -> 3\n",
      "3768. joint embeddings  -> 3\n",
      "3769. jpeg-lm  -> 3\n",
      "3770. json generation  -> 3\n",
      "3771. keyword spotting  -> 3\n",
      "3772. data selection  -> 3\n",
      "3773. data shuffling  -> 3\n",
      "3774. data redaction  -> 3\n",
      "3775. data sampling  -> 3\n",
      "3776. stable image  -> 3\n",
      "3777. stable video diffusion  -> 3\n",
      "3778. data formatting  -> 3\n",
      "3779. langserve  -> 3\n",
      "3780. pytorch custom ops  -> 3\n",
      "3781. q&a systems  -> 3\n",
      "3782. pythia  -> 3\n",
      "3783. data i/o optimization  -> 3\n",
      "3784. ssml  -> 3\n",
      "3785. spreadsheet automation  -> 3\n",
      "3786. data distillation  -> 3\n",
      "3787. data chunking  -> 3\n",
      "3788. custom silicon  -> 3\n",
      "3789. data architecture  -> 3\n",
      "3790. data acquisition  -> 3\n",
      "3791. stakeholder engagement  -> 3\n",
      "3792. dall·e 3  -> 3\n",
      "3793. dark pattern  -> 3\n",
      "3794. state persistence  -> 3\n",
      "3795. state representation  -> 3\n",
      "3796. state machine  -> 3\n",
      "3797. state machine design  -> 3\n",
      "3798. python development  -> 3\n",
      "3799. custom llm  -> 3\n",
      "3800. pygame  -> 3\n",
      "3801. pypdf2  -> 3\n",
      "3802. public policy  -> 3\n",
      "3803. pydanticai  -> 3\n",
      "3804. latent chain-of-thought  -> 3\n",
      "3805. late interaction models  -> 3\n",
      "3806. late-interaction models  -> 3\n",
      "3807. dalle-3  -> 3\n",
      "3808. layout parsing  -> 3\n",
      "3809. latent space analysis  -> 3\n",
      "3810. latent space manipulation  -> 3\n",
      "3811. large video language models (lvlms)  -> 3\n",
      "3812. large-scale ai infrastructure  -> 3\n",
      "3813. large-scale ai training  -> 3\n",
      "3814. large model deployment  -> 3\n",
      "3815. large model inference  -> 3\n",
      "3816. speculative sampling  -> 3\n",
      "3817. language model pretraining  -> 3\n",
      "3818. language understanding  -> 3\n",
      "3819. langflow  -> 3\n",
      "3820. legal nlp  -> 3\n",
      "3821. layout understanding  -> 3\n",
      "3822. layoutlm  -> 3\n",
      "3823. lcm (latent consistency models)  -> 3\n",
      "3824. deception detection  -> 3\n",
      "3825. decision intelligence  -> 3\n",
      "3826. dbt  -> 3\n",
      "3827. dcgan  -> 3\n",
      "3828. karpenter  -> 3\n",
      "3829. kerasnlp  -> 3\n",
      "3830. kernel density estimation (kde)  -> 3\n",
      "3831. data-efficient learning  -> 3\n",
      "3832. query transformation  -> 3\n",
      "3833. query understanding  -> 3\n",
      "3834. ddp (distributed data parallel)  -> 3\n",
      "3835. dataset preprocessing  -> 3\n",
      "3836. dataset versioning  -> 3\n",
      "3837. datasheet  -> 3\n",
      "3838. spec-driven development  -> 3\n",
      "3839. spatio-temporal reasoning  -> 3\n",
      "3840. stem separation  -> 3\n",
      "3841. statistical hypothesis testing  -> 3\n",
      "3842. statistical testing  -> 3\n",
      "3843. stategraph  -> 3\n",
      "3844. latent space reasoning  -> 3\n",
      "3845. latent-space reasoning  -> 3\n",
      "3846. qwen3  -> 3\n",
      "3847. query reformulation  -> 3\n",
      "3848. protein modeling  -> 3\n",
      "3849. proof assistants  -> 3\n",
      "3850. propensity score matching  -> 3\n",
      "3851. cyclegan  -> 3\n",
      "3852. cython  -> 3\n",
      "3853. customer service automation  -> 3\n",
      "3854. customer-managed encryption keys (cmek)  -> 3\n",
      "3855. provenance tracking  -> 3\n",
      "3856. custom attention kernels  -> 3\n",
      "3857. linear models  -> 3\n",
      "3858. linear projection  -> 3\n",
      "3859. lineage tracking  -> 3\n",
      "3860. cross-lingual nlp  -> 3\n",
      "3861. conversational ux  -> 3\n",
      "3862. convnext  -> 3\n",
      "3863. convolution  -> 3\n",
      "3864. stereo vision  -> 3\n",
      "3865. steganalysis  -> 3\n",
      "3866. level 3 autonomy  -> 3\n",
      "3867. lexical search  -> 3\n",
      "3868. librechat  -> 3\n",
      "3869. librosa  -> 3\n",
      "3870. straight-through estimator  -> 3\n",
      "3871. streamdiffusion  -> 3\n",
      "3872. cross entropy loss  -> 3\n",
      "3873. creative writing generation  -> 3\n",
      "3874. creativity  -> 3\n",
      "3875. crag  -> 3\n",
      "3876. creative writing (ai)  -> 3\n",
      "3877. custom gpt development  -> 3\n",
      "3878. custom instructions  -> 3\n",
      "3879. cursor ide  -> 3\n",
      "3880. decentralized systems  -> 3\n",
      "3881. deep java library (djl)  -> 3\n",
      "3882. deep learning ami  -> 3\n",
      "3883. decoder-only transformer  -> 3\n",
      "3884. latex  -> 3\n",
      "3885. psnr  -> 3\n",
      "3886. prototype networks  -> 3\n",
      "3887. prototype projection  -> 3\n",
      "3888. deepseek api  -> 3\n",
      "3889. deep rts  -> 3\n",
      "3890. query processing  -> 3\n",
      "3891. kafka  -> 3\n",
      "3892. qwen2vl  -> 3\n",
      "3893. streaming ai  -> 3\n",
      "3894. streaming data  -> 3\n",
      "3895. streaming llm responses  -> 3\n",
      "3896. sparse vector search  -> 3\n",
      "3897. deep learning optimizers  -> 3\n",
      "3898. deep learning training  -> 3\n",
      "3899. deduplication  -> 3\n",
      "3900. deep graph library (dgl)  -> 3\n",
      "3901. decision support systems  -> 3\n",
      "3902. deltanet  -> 3\n",
      "3903. deepseek r1  -> 3\n",
      "3904. streaming tts  -> 3\n",
      "3905. jaeger  -> 3\n",
      "3906. jags  -> 3\n",
      "3907. jakarta ee  -> 3\n",
      "3908. iterative reasoning  -> 3\n",
      "3909. itk  -> 3\n",
      "3910. sparse fine-tuning  -> 3\n",
      "3911. sparse representations  -> 3\n",
      "3912. structured reasoning  -> 3\n",
      "3913. counterfactual analysis  -> 3\n",
      "3914. coreml  -> 3\n",
      "3915. linear transformers  -> 3\n",
      "3916. prompt routing  -> 3\n",
      "3917. prompt techniques  -> 3\n",
      "3918. sub-agent coordination  -> 3\n",
      "3919. streaming responses  -> 3\n",
      "3920. prompt design  -> 3\n",
      "3921. tableau  -> 3\n",
      "3922. system monitoring  -> 3\n",
      "3923. system programming  -> 3\n",
      "3924. synthetic media generation  -> 3\n",
      "3925. content recommendation  -> 3\n",
      "3926. content creation  -> 3\n",
      "3927. constraint solving  -> 3\n",
      "3928. control systems (ai)  -> 3\n",
      "3929. continuous retraining  -> 3\n",
      "3930. conversational commerce  -> 3\n",
      "3931. conversational retrieval  -> 3\n",
      "3932. conv2d  -> 3\n",
      "3933. student modeling  -> 3\n",
      "3934. prompt injection prevention  -> 3\n",
      "3935. prompt injection testing  -> 3\n",
      "3936. contextual reasoning  -> 3\n",
      "3937. contextual retrieval  -> 3\n",
      "3938. symbolic regression  -> 3\n",
      "3939. symbolic search  -> 3\n",
      "3940. swarmui  -> 3\n",
      "3941. prompt evaluation  -> 3\n",
      "3942. llm cli tools  -> 3\n",
      "3943. llm architecture design  -> 3\n",
      "3944. llama fine-tuning  -> 3\n",
      "3945. syftr  -> 3\n",
      "3946. surveillance systems  -> 3\n",
      "3947. context-parallel training  -> 3\n",
      "3948. context quarantine  -> 3\n",
      "3949. context injection  -> 3\n",
      "3950. continuous fine-tuning  -> 3\n",
      "3951. contextual biasing  -> 3\n",
      "3952. source discovery  -> 3\n",
      "3953. source separation  -> 3\n",
      "3954. source verification  -> 3\n",
      "3955. solidity  -> 3\n",
      "3956. sonic  -> 3\n",
      "3957. sound effect generation  -> 3\n",
      "3958. ipex-llm  -> 3\n",
      "3959. r  -> 3\n",
      "3960. inverse rendering  -> 3\n",
      "3961. inverse text normalization (itn)  -> 3\n",
      "3962. sound event detection  -> 3\n",
      "3963. design systems  -> 3\n",
      "3964. depth sensing  -> 3\n",
      "3965. dense vector embeddings  -> 3\n",
      "3966. dense vector search  -> 3\n",
      "3967. source citation  -> 3\n",
      "3968. llm hallucination mitigation  -> 3\n",
      "3969. llm infrastructure  -> 3\n",
      "3970. llm evaluation & benchmarking  -> 3\n",
      "3971. llm evaluation and benchmarking  -> 3\n",
      "3972. context isolation  -> 3\n",
      "3973. context length  -> 3\n",
      "3974. context length extension  -> 3\n",
      "3975. software engineering automation  -> 3\n",
      "3976. llm frameworks  -> 3\n",
      "3977. llm fundamentals  -> 3\n",
      "3978. llm grounding  -> 3\n",
      "3979. llm guardrails  -> 3\n",
      "3980. llm-d  -> 3\n",
      "3981. llm-swarm  -> 3\n",
      "3982. llm training optimization  -> 3\n",
      "3983. llm model selection  -> 3\n",
      "3984. llm routing  -> 3\n",
      "3985. llm scaling  -> 3\n",
      "3986. program repair  -> 3\n",
      "3987. complex reasoning  -> 3\n",
      "3988. compliance automation  -> 3\n",
      "3989. communication optimization  -> 3\n",
      "3990. communication overlapping  -> 3\n",
      "3991. competitive programming  -> 3\n",
      "3992. computer-aided design  -> 3\n",
      "3993. computer-aided diagnosis (cad)  -> 3\n",
      "3994. product matching  -> 3\n",
      "3995. consent management  -> 3\n",
      "3996. consistency distillation  -> 3\n",
      "3997. llm tuning  -> 3\n",
      "3998. llm-assisted coding  -> 3\n",
      "3999. llm tool calling  -> 3\n",
      "4000. control barrier functions  -> 3\n",
      "4001. concept normalization  -> 3\n",
      "4002. tabular data modeling  -> 3\n",
      "4003. tailwind css  -> 3\n",
      "4004. tapas  -> 3\n",
      "4005. computational simulation  -> 3\n",
      "4006. computational social science  -> 3\n",
      "4007. conditional image generation  -> 3\n",
      "4008. r-cnn  -> 3\n",
      "4009. radar perception  -> 3\n",
      "4010. radar processing  -> 3\n",
      "4011. spanner  -> 3\n",
      "4012. directed acyclic graphs (dags)  -> 3\n",
      "4013. rag optimization  -> 3\n",
      "4014. ram offloading  -> 3\n",
      "4015. control  -> 3\n",
      "4016. intrusion detection  -> 3\n",
      "4017. inventory management  -> 3\n",
      "4018. interactive visualization  -> 3\n",
      "4019. ransomware  -> 3\n",
      "4020. digital fabrication  -> 3\n",
      "4021. digital forensics  -> 3\n",
      "4022. temporal knowledge graphs  -> 3\n",
      "4023. telemetry analysis  -> 3\n",
      "4024. devin  -> 3\n",
      "4025. direct-to-chip liquid cooling  -> 3\n",
      "4026. dense passage retrieval (dpr)  -> 3\n",
      "4027. differential transformer  -> 3\n",
      "4028. diffusion language models  -> 3\n",
      "4029. differential equations  -> 3\n",
      "4030. diagram generation  -> 3\n",
      "4031. invokemodel api  -> 3\n",
      "4032. telematics  -> 3\n",
      "4033. local processing  -> 3\n",
      "4034. computational materials science  -> 3\n",
      "4035. compressive memory  -> 3\n",
      "4036. real-time agent  -> 3\n",
      "4037. dialog management  -> 3\n",
      "4038. deterministic execution  -> 3\n",
      "4039. detr  -> 3\n",
      "4040. colorization  -> 3\n",
      "4041. locomotion  -> 3\n",
      "4042. local language model  -> 3\n",
      "4043. local ai processing  -> 3\n",
      "4044. lm_eval  -> 3\n",
      "4045. tensor programming  -> 3\n",
      "4046. compiler development  -> 3\n",
      "4047. completion api  -> 3\n",
      "4048. digital assistants  -> 3\n",
      "4049. distributed training/inference  -> 3\n",
      "4050. distributed fine-tuning  -> 3\n",
      "4051. distributed machine learning  -> 3\n",
      "4052. distributed ai training  -> 3\n",
      "4053. real-time analysis  -> 3\n",
      "4054. inter-agent communication  -> 3\n",
      "4055. int8 inference  -> 3\n",
      "4056. collaborative robotics  -> 3\n",
      "4057. collision avoidance  -> 3\n",
      "4058. real-time retrieval  -> 3\n",
      "4059. siri  -> 3\n",
      "4060. discriminative models  -> 3\n",
      "4061. dino  -> 3\n",
      "4062. direct nash optimization (dno)  -> 3\n",
      "4063. digital transformation  -> 3\n",
      "4064. tensor visualization  -> 3\n",
      "4065. tensorcore  -> 3\n",
      "4066. tensorflow lite  -> 3\n",
      "4067. probability distribution  -> 3\n",
      "4068. probability theory  -> 3\n",
      "4069. problem solving  -> 3\n",
      "4070. cognos  -> 3\n",
      "4071. cogvideo  -> 3\n",
      "4072. telephony integration  -> 3\n",
      "4073. task routing  -> 3\n",
      "4074. code optimization  -> 3\n",
      "4075. code fine-tuning  -> 3\n",
      "4076. test-time optimization  -> 3\n",
      "4077. test-driven development (tdd)  -> 3\n",
      "4078. coding (ai)  -> 3\n",
      "4079. code translation  -> 3\n",
      "4080. cloud analytics  -> 3\n",
      "4081. closed-loop control  -> 3\n",
      "4082. low-latency ai  -> 3\n",
      "4083. loreft  -> 3\n",
      "4084. loss function design  -> 3\n",
      "4085. long-horizon tasks  -> 3\n",
      "4086. long-sequence training  -> 3\n",
      "4087. classification (ai)  -> 3\n",
      "4088. code analysis (ai)  -> 3\n",
      "4089. cloud-based ai  -> 3\n",
      "4090. cloud-native ai  -> 3\n",
      "4091. cloud-native architecture  -> 3\n",
      "4092. cloud ml infrastructure  -> 3\n",
      "4093. looker studio  -> 3\n",
      "4094. long-context understanding  -> 3\n",
      "4095. long-horizon reasoning  -> 3\n",
      "4096. probabilistic forecasting  -> 3\n",
      "4097. probabilistic reasoning  -> 3\n",
      "4098. text rewriting  -> 3\n",
      "4099. text-rag  -> 3\n",
      "4100. text mining  -> 3\n",
      "4101. text post-processing  -> 3\n",
      "4102. text recognition  -> 3\n",
      "4103. text encoding  -> 3\n",
      "4104. instruct tuning  -> 3\n",
      "4105. social media monitoring  -> 3\n",
      "4106. distributed optimizers  -> 3\n",
      "4107. sleep apnea detection  -> 3\n",
      "4108. real-time speech processing  -> 3\n",
      "4109. real-time data streaming  -> 3\n",
      "4110. compute scaling  -> 3\n",
      "4111. logit biasing  -> 3\n",
      "4112. documentation  -> 3\n",
      "4113. docvqa  -> 3\n",
      "4114. dom parsing  -> 3\n",
      "4115. dynamic expert routing  -> 3\n",
      "4116. slack api  -> 3\n",
      "4117. simd optimization  -> 3\n",
      "4118. double machine learning  -> 3\n",
      "4119. dpo training  -> 3\n",
      "4120. sigmoid function  -> 3\n",
      "4121. shared memory  -> 3\n",
      "4122. document intelligence  -> 3\n",
      "4123. document automation  -> 3\n",
      "4124. distributeddataparallel  -> 3\n",
      "4125. dlrm  -> 3\n",
      "4126. domain modeling  -> 3\n",
      "4127. domain randomization  -> 3\n",
      "4128. textual inversion  -> 3\n",
      "4129. claude sonnet 4.5  -> 3\n",
      "4130. low-vram inference  -> 3\n",
      "4131. lpips  -> 3\n",
      "4132. low-power machine learning  -> 3\n",
      "4133. prefect  -> 3\n",
      "4134. cloud inference  -> 3\n",
      "4135. dsl  -> 3\n",
      "4136. classification models  -> 3\n",
      "4137. citation-aware generation  -> 3\n",
      "4138. text-to-image diffusion  -> 3\n",
      "4139. ci/cd integration  -> 3\n",
      "4140. precision@k  -> 3\n",
      "4141. prediction  -> 3\n",
      "4142. power bi  -> 3\n",
      "4143. powerpoint automation  -> 3\n",
      "4144. image quality assessment  -> 3\n",
      "4145. incremental training  -> 3\n",
      "4146. instance_type  -> 3\n",
      "4147. infrared imaging  -> 3\n",
      "4148. inference-time scaling  -> 3\n",
      "4149. inference-time verification  -> 3\n",
      "4150. inference framework  -> 3\n",
      "4151. inference backend  -> 3\n",
      "4152. mann-whitney u test  -> 3\n",
      "4153. mapreduce  -> 3\n",
      "4154. manipulation  -> 3\n",
      "4155. machine unlearning  -> 3\n",
      "4156. chatkit  -> 3\n",
      "4157. chemical language models  -> 3\n",
      "4158. emergent behavior analysis  -> 3\n",
      "4159. image processing (ai)  -> 3\n",
      "4160. chartllm  -> 3\n",
      "4161. chain of code  -> 3\n",
      "4162. maestro  -> 3\n",
      "4163. population stability index (psi)  -> 3\n",
      "4164. plugin architecture  -> 3\n",
      "4165. captioning  -> 3\n",
      "4166. texture generation  -> 3\n",
      "4167. texturing  -> 3\n",
      "4168. information gain  -> 3\n",
      "4169. inference speed  -> 3\n",
      "4170. cloud computing (for ai)  -> 3\n",
      "4171. cloud computing for ai  -> 3\n",
      "4172. cloud cost optimization  -> 3\n",
      "4173. catastrophic forgetting  -> 3\n",
      "4174. caching strategies  -> 3\n",
      "4175. canary testing  -> 3\n",
      "4176. chromium development  -> 3\n",
      "4177. polars  -> 3\n",
      "4178. planning (ai)  -> 3\n",
      "4179. platform engineering  -> 3\n",
      "4180. matlab  -> 3\n",
      "4181. matrix factorization  -> 3\n",
      "4182. token efficiency optimization  -> 3\n",
      "4183. bounding box detection  -> 3\n",
      "4184. c++ inference  -> 3\n",
      "4185. causal modeling  -> 3\n",
      "4186. causalml  -> 3\n",
      "4187. catastrophic forgetting mitigation  -> 3\n",
      "4188. masking  -> 3\n",
      "4189. materials design  -> 3\n",
      "4190. marketing mix modeling (mmm)  -> 3\n",
      "4191. thrust  -> 3\n",
      "4192. drug discovery ai  -> 3\n",
      "4193. chat models  -> 3\n",
      "4194. theorem prover (lean)  -> 3\n",
      "4195. thread  -> 3\n",
      "4196. categorical crossentropy  -> 3\n",
      "4197. causal ai  -> 3\n",
      "4198. causal attention  -> 3\n",
      "4199. causal forests  -> 3\n",
      "4200. inference caching  -> 3\n",
      "4201. inception architecture  -> 3\n",
      "4202. incremental learning  -> 3\n",
      "4203. short-term memory (stm)  -> 3\n",
      "4204. shadow deployment  -> 3\n",
      "4205. reasoning evaluation  -> 3\n",
      "4206. reasoning interpretability  -> 3\n",
      "4207. dvora  -> 3\n",
      "4208. earlystopping  -> 3\n",
      "4209. ebpf  -> 3\n",
      "4210. image/video upscaling  -> 3\n",
      "4211. imbalanced data handling  -> 3\n",
      "4212. image-to-3d conversion  -> 3\n",
      "4213. image-to-3d generation  -> 3\n",
      "4214. image-to-video conversion  -> 3\n",
      "4215. reasoning agents  -> 3\n",
      "4216. session hijack  -> 3\n",
      "4217. session isolation  -> 3\n",
      "4218. service discovery  -> 3\n",
      "4219. durable workflows  -> 3\n",
      "4220. shannon entropy  -> 3\n",
      "4221. edge machine learning  -> 3\n",
      "4222. econml  -> 3\n",
      "4223. early fusion  -> 3\n",
      "4224. medical diagnosis ai  -> 3\n",
      "4225. md5  -> 3\n",
      "4226. mean reciprocal rank (mrr)  -> 3\n",
      "4227. mean squared error (mse)  -> 3\n",
      "4228. recursive language models (rlms)  -> 3\n",
      "4229. recursivecharactertextsplitter  -> 3\n",
      "4230. recurrence  -> 3\n",
      "4231. image-text alignment  -> 3\n",
      "4232. bpe tokenization  -> 3\n",
      "4233. brier score  -> 3\n",
      "4234. bluetooth  -> 3\n",
      "4235. bot development  -> 3\n",
      "4236. plagiarism detection  -> 3\n",
      "4237. pipeline  -> 3\n",
      "4238. token-level analysis  -> 3\n",
      "4239. tinyjit  -> 3\n",
      "4240. sentence-bert  -> 3\n",
      "4241. sequence-to-sequence  -> 3\n",
      "4242. sequence-to-sequence models  -> 3\n",
      "4243. serialization  -> 3\n",
      "4244. serpapi  -> 3\n",
      "4245. elastic  -> 3\n",
      "4246. embedding optimization  -> 3\n",
      "4247. embedding training  -> 3\n",
      "4248. memory for llms  -> 3\n",
      "4249. memory hierarchy optimization  -> 3\n",
      "4250. medical imaging analysis  -> 3\n",
      "4251. tokenizer optimization  -> 3\n",
      "4252. tool chaining  -> 3\n",
      "4253. blue-green deployment  -> 3\n",
      "4254. semantic annotation  -> 3\n",
      "4255. image matching  -> 3\n",
      "4256. tokenizer configuration  -> 3\n",
      "4257. tokenizer engineering  -> 3\n",
      "4258. token-based processing  -> 3\n",
      "4259. bias detection (ai)  -> 3\n",
      "4260. bertscore  -> 3\n",
      "4261. biomedical nlp  -> 3\n",
      "4262. binary vector embeddings  -> 3\n",
      "4263. bing copilot  -> 3\n",
      "4264. shampoo optimizer  -> 3\n",
      "4265. efficientnet  -> 3\n",
      "4266. ehr integration  -> 3\n",
      "4267. eeg analysis  -> 3\n",
      "4268. byte latent transformer  -> 3\n",
      "4269. budget forcing  -> 3\n",
      "4270. browser agent  -> 3\n",
      "4271. tokenization-free models  -> 3\n",
      "4272. tool use for llms  -> 3\n",
      "4273. personalized medicine  -> 3\n",
      "4274. phi  -> 3\n",
      "4275. personalization (ai)  -> 3\n",
      "4276. aws dynamodb  -> 3\n",
      "4277. aws ecr  -> 3\n",
      "4278. aws codebuild  -> 3\n",
      "4279. awq quantization  -> 3\n",
      "4280. bedrock agentcore runtime  -> 3\n",
      "4281. bayesian regression  -> 3\n",
      "4282. bci (brain-computer interface)  -> 3\n",
      "4283. meta-analysis  -> 3\n",
      "4284. memory-augmented  -> 3\n",
      "4285. top-p sampling  -> 3\n",
      "4286. person tracking  -> 3\n",
      "4287. meta  -> 3\n",
      "4288. embodied reasoning  -> 3\n",
      "4289. erp integration  -> 3\n",
      "4290. error detection  -> 3\n",
      "4291. bitblas  -> 3\n",
      "4292. pii handling  -> 3\n",
      "4293. physical reasoning  -> 3\n",
      "4294. physical simulation  -> 3\n",
      "4295. physics-informed ai  -> 3\n",
      "4296. embedding alignment  -> 3\n",
      "4297. seo optimization  -> 3\n",
      "4298. sequence packing  -> 3\n",
      "4299. image tagging  -> 3\n",
      "4300. image tiling  -> 3\n",
      "4301. image resizing  -> 3\n",
      "4302. image signal processing (isp)  -> 3\n",
      "4303. encodec  -> 3\n",
      "4304. energy-efficient ml  -> 3\n",
      "4305. endpoint management  -> 3\n",
      "4306. refine (chain)  -> 3\n",
      "4307. reflection tuning  -> 3\n",
      "4308. reflexion  -> 3\n",
      "4309. reference-based evaluation  -> 3\n",
      "4310. reference-based generation  -> 3\n",
      "4311. semantic textual similarity (sts)  -> 3\n",
      "4312. backtesting  -> 3\n",
      "4313. azure machine learning  -> 3\n",
      "4314. self-hosting ai models  -> 3\n",
      "4315. self-rag  -> 3\n",
      "4316. evolutionary game theory  -> 3\n",
      "4317. semi-supervised learning  -> 3\n",
      "4318. semiconductor engineering  -> 3\n",
      "4319. energy-based transformers  -> 3\n",
      "4320. aws lake formation  -> 3\n",
      "4321. aws identity and access management (iam)  -> 3\n",
      "4322. microscopy image analysis  -> 3\n",
      "4323. metadata tagging  -> 3\n",
      "4324. metal programming  -> 3\n",
      "4325. meta-tuning  -> 3\n",
      "4326. metadata enrichment  -> 3\n",
      "4327. backdoor attacks  -> 3\n",
      "4328. aws ai services  -> 3\n",
      "4329. aws amplify  -> 3\n",
      "4330. aws budgets  -> 3\n",
      "4331. mitre atlas  -> 3\n",
      "4332. mixed precision (bf16  -> 3\n",
      "4333. training from scratch  -> 3\n",
      "4334. training data  -> 3\n",
      "4335. aws sigv4  -> 3\n",
      "4336. autotuning  -> 3\n",
      "4337. avc-lm  -> 3\n",
      "4338. awq (activation-aware weight quantization)  -> 3\n",
      "4339. autoregressive transformer  -> 3\n",
      "4340. trajectory prediction  -> 3\n",
      "4341. transformer encoders  -> 3\n",
      "4342. autograd  -> 3\n",
      "4343. triton kernels  -> 3\n",
      "4344. perceiver  -> 3\n",
      "4345. transformers (library)  -> 3\n",
      "4346. transformer fine-tuning  -> 3\n",
      "4347. training pipeline development  -> 3\n",
      "4348. training data preparation  -> 3\n",
      "4349. minimax algorithm  -> 3\n",
      "4350. microsoft graph api  -> 3\n",
      "4351. microsoft presidio  -> 3\n",
      "4352. microsoft autogen  -> 3\n",
      "4353. autoprompt  -> 3\n",
      "4354. autorag  -> 3\n",
      "4355. autoregressive generation  -> 3\n",
      "4356. perceptual hashing  -> 3\n",
      "4357. middleware development  -> 3\n",
      "4358. performance evaluation  -> 3\n",
      "4359. pdq  -> 3\n",
      "4360. image outpainting  -> 3\n",
      "4361. image encoding  -> 3\n",
      "4362. image conditioning  -> 3\n",
      "4363. image editing/inpainting  -> 3\n",
      "4364. semantic routing  -> 3\n",
      "4365. semantic hashing  -> 3\n",
      "4366. semantic indexing  -> 3\n",
      "4367. tpu computing  -> 3\n",
      "4368. entropy decoding  -> 3\n",
      "4369. ifttt integration  -> 3\n",
      "4370. ide extension  -> 3\n",
      "4371. hyperbolic embeddings  -> 3\n",
      "4372. image labeling  -> 3\n",
      "4373. error level analysis  -> 3\n",
      "4374. evolutionary optimization  -> 3\n",
      "4375. event-driven systems  -> 3\n",
      "4376. ml ci/cd  -> 3\n",
      "4377. human-machine interaction  -> 3\n",
      "4378. relational graph convolutional network (rgcn)  -> 3\n",
      "4379. reinforcement learning fine-tuning (rlft)  -> 3\n",
      "4380. estimator  -> 3\n",
      "4381. environment variables  -> 3\n",
      "4382. equation recognition  -> 3\n",
      "4383. entropy analysis  -> 3\n",
      "4384. automated content moderation  -> 3\n",
      "4385. automated essay scoring  -> 3\n",
      "4386. autoformalization  -> 3\n",
      "4387. autogptq  -> 3\n",
      "4388. mixed-precision quantization  -> 3\n",
      "4389. mixed precision (fp16)  -> 3\n",
      "4390. mixed precision (fp8)  -> 3\n",
      "4391. ml supply chain security  -> 3\n",
      "4392. triton programming  -> 3\n",
      "4393. trl (transformer reinforcement learning)  -> 3\n",
      "4394. trulens  -> 3\n",
      "4395. tree-based models  -> 3\n",
      "4396. trend analysis  -> 3\n",
      "4397. transformerlens  -> 3\n",
      "4398. automated malware analysis  -> 3\n",
      "4399. automated code repair  -> 3\n",
      "4400. unit test generation  -> 3\n",
      "4401. unity catalog  -> 3\n",
      "4402. asynchronous rollouts  -> 3\n",
      "4403. athena  -> 3\n",
      "4404. attribution  -> 3\n",
      "4405. ui agents  -> 3\n",
      "4406. ui/ux design  -> 3\n",
      "4407. tucker decomposition  -> 3\n",
      "4408. patch-level training  -> 3\n",
      "4409. partial dependence plots  -> 3\n",
      "4410. paraphrasing  -> 3\n",
      "4411. ml optimization  -> 3\n",
      "4412. ml pipeline development  -> 3\n",
      "4413. ml platforms  -> 3\n",
      "4414. ml model management  -> 3\n",
      "4415. ml experimentation  -> 3\n",
      "4416. mobile model optimization  -> 3\n",
      "4417. type hints  -> 3\n",
      "4418. type safety  -> 3\n",
      "4419. trust-aware aggregation  -> 3\n",
      "4420. autocomplete  -> 3\n",
      "4421. ml inference  -> 3\n",
      "4422. pathways  -> 3\n",
      "4423. passage retrieval  -> 3\n",
      "4424. reinforce leave-one-out (rloo)  -> 3\n",
      "4425. self-adaptive llms  -> 3\n",
      "4426. self-attention mechanism  -> 3\n",
      "4427. semantic clustering  -> 3\n",
      "4428. mixture of recursions (mor)  -> 3\n",
      "4429. mixture-of-depths  -> 3\n",
      "4430. audio tagging  -> 3\n",
      "4431. audio-driven facial animation  -> 3\n",
      "4432. reinforcement learning pretraining (rlp)  -> 3\n",
      "4433. selective generation  -> 3\n",
      "4434. security engineering  -> 3\n",
      "4435. hybrid parallelism  -> 3\n",
      "4436. hybrid ai systems  -> 3\n",
      "4437. hybrid attention  -> 3\n",
      "4438. panel data analysis  -> 3\n",
      "4439. audio llms  -> 3\n",
      "4440. expectation-maximization  -> 3\n",
      "4441. experiment  -> 3\n",
      "4442. self-distillation  -> 3\n",
      "4443. fairness assessment  -> 3\n",
      "4444. fact-checking (ai)  -> 3\n",
      "4445. fair  -> 3\n",
      "4446. face animation  -> 3\n",
      "4447. face reenactment  -> 3\n",
      "4448. financial data analysis  -> 3\n",
      "4449. financial reasoning  -> 3\n",
      "4450. ffn fusion  -> 3\n",
      "4451. fhir  -> 3\n",
      "4452. exploit development  -> 3\n",
      "4453. exploration strategies  -> 3\n",
      "4454. exponential backoff  -> 3\n",
      "4455. express  -> 3\n",
      "4456. audio deepfake detection  -> 3\n",
      "4457. audio enhancement  -> 3\n",
      "4458. audio event detection  -> 3\n",
      "4459. audio feature extraction  -> 3\n",
      "4460. attention sinks  -> 3\n",
      "4461. attention visualization  -> 3\n",
      "4462. parameter offloading  -> 3\n",
      "4463. parallel training  -> 3\n",
      "4464. security architecture  -> 3\n",
      "4465. hybrid model architectures  -> 3\n",
      "4466. federated querying  -> 3\n",
      "4467. feature matching  -> 3\n",
      "4468. feedback loop design  -> 3\n",
      "4469. hugging face endpoints  -> 3\n",
      "4470. http server development  -> 3\n",
      "4471. fine-grained image classification  -> 3\n",
      "4472. modal  -> 3\n",
      "4473. model fingerprinting  -> 3\n",
      "4474. atropos  -> 3\n",
      "4475. assistive technology  -> 3\n",
      "4476. ast analysis  -> 3\n",
      "4477. representation alignment (repa)  -> 3\n",
      "4478. fault detection  -> 3\n",
      "4479. fall detection  -> 3\n",
      "4480. arize  -> 3\n",
      "4481. arize phoenix  -> 3\n",
      "4482. aqlm  -> 3\n",
      "4483. palm vein recognition  -> 3\n",
      "4484. model compatibility  -> 3\n",
      "4485. model building  -> 3\n",
      "4486. model analysis  -> 3\n",
      "4487. model apis  -> 3\n",
      "4488. audio machine learning  -> 3\n",
      "4489. ar/vr development  -> 3\n",
      "4490. application security  -> 3\n",
      "4491. uplift modeling  -> 3\n",
      "4492. unstructured data classification  -> 3\n",
      "4493. unstructured data management  -> 3\n",
      "4494. arviz  -> 3\n",
      "4495. arctic long sequence training (alst)  -> 3\n",
      "4496. model elicitation  -> 3\n",
      "4497. model drift detection  -> 3\n",
      "4498. model cost optimization  -> 3\n",
      "4499. model design  -> 3\n",
      "4500. ant colony optimization  -> 3\n",
      "4501. anthropic claude 3.5  -> 3\n",
      "4502. animation generation  -> 3\n",
      "4503. utcp  -> 3\n",
      "4504. api keys  -> 3\n",
      "4505. padding masks  -> 3\n",
      "4506. output verification  -> 3\n",
      "4507. over-the-air (ota) updates  -> 3\n",
      "4508. overfitting prevention  -> 3\n",
      "4509. analog in-memory computing (aimc)  -> 3\n",
      "4510. analytical reasoning  -> 3\n",
      "4511. underfitting  -> 3\n",
      "4512. output formatting  -> 3\n",
      "4513. output parsing  -> 3\n",
      "4514. anchor boxes  -> 3\n",
      "4515. ancova  -> 3\n",
      "4516. apple mlx  -> 3\n",
      "4517. apple neural engine  -> 3\n",
      "4518. api performance optimization  -> 3\n",
      "4519. apigee  -> 3\n",
      "4520. fine-tune  -> 3\n",
      "4521. fine-tuning (ai)  -> 3\n",
      "4522. ascend npu  -> 3\n",
      "4523. audio streaming  -> 3\n",
      "4524. pair programming  -> 3\n",
      "4525. api access  -> 3\n",
      "4526. api calls  -> 3\n",
      "4527. api cost optimization  -> 3\n",
      "4528. schema markup  -> 3\n",
      "4529. reproducible ml  -> 3\n",
      "4530. relighting  -> 3\n",
      "4531. hopfield networks  -> 3\n",
      "4532. hpc (high-performance computing)  -> 3\n",
      "4533. htap  -> 3\n",
      "4534. html parsing  -> 3\n",
      "4535. fp4 training  -> 3\n",
      "4536. search personalization  -> 3\n",
      "4537. fine-grained access control  -> 3\n",
      "4538. honeypots  -> 3\n",
      "4539. high availability  -> 3\n",
      "4540. finrl  -> 3\n",
      "4541. firebase  -> 3\n",
      "4542. fine-tuning (sft)  -> 3\n",
      "4543. search algorithms (ai)  -> 3\n",
      "4544. output validation  -> 3\n",
      "4545. model packaging  -> 3\n",
      "4546. health checks  -> 3\n",
      "4547. research agents  -> 3\n",
      "4548. residual networks  -> 3\n",
      "4549. search relevance  -> 3\n",
      "4550. search technologies  -> 3\n",
      "4551. search integration  -> 3\n",
      "4552. user behavior analysis  -> 3\n",
      "4553. user behavior analytics  -> 3\n",
      "4554. user interface design  -> 3\n",
      "4555. model optimization for mobile  -> 3\n",
      "4556. model interpretation  -> 3\n",
      "4557. model isolation  -> 3\n",
      "4558. model loading  -> 3\n",
      "4559. user research  -> 3\n",
      "4560. ambient agents  -> 3\n",
      "4561. amazon route 53  -> 3\n",
      "4562. algorithm optimization  -> 3\n",
      "4563. algorithm selection  -> 3\n",
      "4564. algorithmic accountability  -> 3\n",
      "4565. alexnet  -> 3\n",
      "4566. verilog  -> 3\n",
      "4567. versioning  -> 3\n",
      "4568. model signing  -> 3\n",
      "4569. model specification  -> 3\n",
      "4570. model scaling laws  -> 3\n",
      "4571. model predictive control (mpc)  -> 3\n",
      "4572. amd mi300x  -> 3\n",
      "4573. amd rocm  -> 3\n",
      "4574. amazon titan multimodal embeddings  -> 3\n",
      "4575. amazon titan text embeddings  -> 3\n",
      "4576. vector processing  -> 3\n",
      "4577. amazon bedrock api  -> 3\n",
      "4578. model profiling  -> 3\n",
      "4579. model watermarking  -> 3\n",
      "4580. model weights management  -> 3\n",
      "4581. amazon kinesis  -> 3\n",
      "4582. value learning  -> 3\n",
      "4583. model grounding  -> 3\n",
      "4584. model performance evaluation  -> 3\n",
      "4585. model performance monitoring  -> 3\n",
      "4586. model memory  -> 3\n",
      "4587. model moderation  -> 3\n",
      "4588. amazon lex  -> 3\n",
      "4589. vera  -> 3\n",
      "4590. verifiable credentials (vcs)  -> 3\n",
      "4591. vector normalization  -> 3\n",
      "4592. function calling (ai)  -> 3\n",
      "4593. fsr  -> 3\n",
      "4594. fsx for lustre  -> 3\n",
      "4595. full-stack ai engineering  -> 3\n",
      "4596. framework development  -> 3\n",
      "4597. fpga  -> 3\n",
      "4598. heterogeneous graph transformer (hgt)  -> 3\n",
      "4599. head pose estimation  -> 3\n",
      "4600. scene graph detection  -> 3\n",
      "4601. scheduling  -> 3\n",
      "4602. schema evolution  -> 3\n",
      "4603. fp4 precision  -> 3\n",
      "4604. fpga design  -> 3\n",
      "4605. scene analysis  -> 3\n",
      "4606. scalable ml infrastructure  -> 3\n",
      "4607. requests  -> 3\n",
      "4608. operator fusion  -> 3\n",
      "4609. optical flow  -> 3\n",
      "4610. amazon bedrock flows  -> 3\n",
      "4611. hardware optimization (for ai)  -> 3\n",
      "4612. hardware-aware training  -> 3\n",
      "4613. hardware acceleration for ai  -> 3\n",
      "4614. hardware design  -> 3\n",
      "4615. schema-guided generation  -> 3\n",
      "4616. monte carlo  -> 3\n",
      "4617. vertex ai vision  -> 3\n",
      "4618. algorithmic transparency  -> 3\n",
      "4619. algorithmic efficiency  -> 3\n",
      "4620. algorithmic optimization  -> 3\n",
      "4621. optimal transport  -> 3\n",
      "4622. optimization techniques  -> 3\n",
      "4623. operations research  -> 3\n",
      "4624. ai tracking  -> 3\n",
      "4625. ai system testing  -> 3\n",
      "4626. mrkl  -> 3\n",
      "4627. motion estimation  -> 3\n",
      "4628. motion prediction  -> 3\n",
      "4629. multi-model endpoints  -> 3\n",
      "4630. ai transformation  -> 3\n",
      "4631. openblas  -> 3\n",
      "4632. vertex ai agent engine  -> 3\n",
      "4633. ai/ml engineer  -> 3\n",
      "4634. ai-powered tracking  -> 3\n",
      "4635. ai-powered obstacle avoidance  -> 3\n",
      "4636. ai-generated content  -> 3\n",
      "4637. ai ultra robot vacuum  -> 3\n",
      "4638. ai theory  -> 3\n",
      "4639. ai tool integration  -> 3\n",
      "4640. openspiel  -> 3\n",
      "4641. openxla  -> 3\n",
      "4642. video generation (ai)  -> 3\n",
      "4643. video inpainting  -> 3\n",
      "4644. video diffusion models  -> 3\n",
      "4645. vid2vid  -> 3\n",
      "4646. video action recognition  -> 3\n",
      "4647. molecular modeling  -> 3\n",
      "4648. amazon bedrock agentcore gateway  -> 3\n",
      "4649. model training optimization  -> 3\n",
      "4650. model streaming  -> 3\n",
      "4651. video moderation  -> 3\n",
      "4652. video rendering  -> 3\n",
      "4653. ai-assisted code editing  -> 3\n",
      "4654. mongodb atlas  -> 3\n",
      "4655. modular ai design  -> 3\n",
      "4656. hardware engineering  -> 3\n",
      "4657. scalable ai infrastructure  -> 3\n",
      "4658. sap joule  -> 3\n",
      "4659. sarimax  -> 3\n",
      "4660. gaussian mixture models  -> 3\n",
      "4661. responses api  -> 3\n",
      "4662. resource management (ai)  -> 3\n",
      "4663. ai video  -> 3\n",
      "4664. gaussian noise injection  -> 3\n",
      "4665. gap identification  -> 3\n",
      "4666. garak  -> 3\n",
      "4667. g-eval  -> 3\n",
      "4668. gail  -> 3\n",
      "4669. galaxy ai  -> 3\n",
      "4670. function-calling  -> 3\n",
      "4671. fused kernels  -> 3\n",
      "4672. gui control  -> 3\n",
      "4673. gui interaction  -> 3\n",
      "4674. fuzz testing  -> 3\n",
      "4675. fuzzy search  -> 3\n",
      "4676. fuzzy string matching  -> 3\n",
      "4677. geneformer  -> 3\n",
      "4678. generalized advantage estimation (gae)  -> 3\n",
      "4679. hierarchical models  -> 3\n",
      "4680. multi-agent rl  -> 3\n",
      "4681. multi-adapter inference  -> 3\n",
      "4682. multi-agent collaboration  -> 3\n",
      "4683. mqtt  -> 3\n",
      "4684. ai watermarking  -> 3\n",
      "4685. ai workflows  -> 3\n",
      "4686. h100 (p5)  -> 3\n",
      "4687. halide  -> 3\n",
      "4688. ai prototyping  -> 3\n",
      "4689. ai regulation compliance  -> 3\n",
      "4690. ai infrastructure optimization  -> 3\n",
      "4691. ai performance optimization  -> 3\n",
      "4692. ai pipeline  -> 3\n",
      "4693. vision reasoning  -> 3\n",
      "4694. virtual screening  -> 3\n",
      "4695. virtualization  -> 3\n",
      "4696. multi-gpu systems  -> 3\n",
      "4697. multi-gpu training/inference  -> 3\n",
      "4698. multi-head latent attention (mla)  -> 3\n",
      "4699. ai surveillance  -> 3\n",
      "4700. ai sustainability  -> 3\n",
      "4701. ai system deployment  -> 3\n",
      "4702. view synthesis  -> 3\n",
      "4703. multi-node inference  -> 3\n",
      "4704. multi-cloud deployment  -> 3\n",
      "4705. multi-frame generation  -> 3\n",
      "4706. multi-gpu orchestration  -> 3\n",
      "4707. openai gpt-4  -> 3\n",
      "4708. ai product design  -> 3\n",
      "4709. ai programming  -> 3\n",
      "4710. ai project management  -> 3\n",
      "4711. multi-instance gpu (mig)  -> 3\n",
      "4712. ai video filter  -> 3\n",
      "4713. openelm  -> 3\n",
      "4714. ai platform engineering  -> 3\n",
      "4715. ai policies  -> 3\n",
      "4716. ai processor  -> 3\n",
      "4717. ai stack  -> 3\n",
      "4718. ai servers  -> 3\n",
      "4719. ai simulation  -> 3\n",
      "4720. sampling optimization  -> 3\n",
      "4721. guided generation  -> 3\n",
      "4722. gsm8k  -> 3\n",
      "4723. generalized least squares (gls)  -> 3\n",
      "4724. gemini llm  -> 3\n",
      "4725. generative ai workflows  -> 3\n",
      "4726. ai safety and ethics  -> 3\n",
      "4727. ai training data  -> 3\n",
      "4728. sagemaker sdk  -> 3\n",
      "4729. salesforce  -> 3\n",
      "4730. salesforce integration  -> 3\n",
      "4731. sam (segment anything model)  -> 3\n",
      "4732. retraining  -> 3\n",
      "4733. gcloud cli  -> 3\n",
      "4734. gdpr  -> 3\n",
      "4735. sampler algorithms  -> 3\n",
      "4736. vision-rag  -> 3\n",
      "4737. ai scalability  -> 3\n",
      "4738. ai security testing  -> 3\n",
      "4739. safety pretraining  -> 3\n",
      "4740. safety systems  -> 3\n",
      "4741. safety validation  -> 3\n",
      "4742. sage attention  -> 3\n",
      "4743. safety and alignment  -> 3\n",
      "4744. vision adapters  -> 3\n",
      "4745. vision ai  -> 3\n",
      "4746. virtual machines  -> 3\n",
      "4747. multilingual  -> 3\n",
      "4748. multi-vector embeddings  -> 3\n",
      "4749. multi-query retrieval  -> 3\n",
      "4750. multi-tenancy  -> 3\n",
      "4751. multi-objective bayesian optimization  -> 3\n",
      "4752. voice user interface (vui) design  -> 3\n",
      "4753. ai api development  -> 3\n",
      "4754. ai cost management  -> 3\n",
      "4755. multimodal language models  -> 3\n",
      "4756. ai for chip design  -> 3\n",
      "4757. ai for code  -> 3\n",
      "4758. ai for code generation  -> 3\n",
      "4759. ai engine optimization  -> 3\n",
      "4760. open source llms  -> 3\n",
      "4761. online inference  -> 3\n",
      "4762. ai oversight  -> 3\n",
      "4763. ai overviews  -> 3\n",
      "4764. ai object recognition  -> 3\n",
      "4765. ai model integration  -> 3\n",
      "4766. ai moderation  -> 3\n",
      "4767. ai ecosystem  -> 3\n",
      "4768. visual autoregressive modeling  -> 3\n",
      "4769. visual generation  -> 3\n",
      "4770. ai model fine-tuning  -> 3\n",
      "4771. vision-language-action (vla) models  -> 3\n",
      "4772. multimodal generative models  -> 3\n",
      "4773. multimodal data  -> 3\n",
      "4774. multilingual translation  -> 3\n",
      "4775. multilingual tts  -> 3\n",
      "4776. open source software  -> 3\n",
      "4777. open-set object detection  -> 3\n",
      "4778. ai licensing  -> 3\n",
      "4779. ai in robotics  -> 3\n",
      "4780. vocoder  -> 3\n",
      "4781. ai in education  -> 3\n",
      "4782. visual tokenization  -> 3\n",
      "4783. visual language model  -> 3\n",
      "4784. green ai  -> 3\n",
      "4785. grounded generation  -> 3\n",
      "4786. graph machine learning  -> 3\n",
      "4787. genomics modeling  -> 3\n",
      "4788. safety fine-tuning  -> 3\n",
      "4789. visualization  -> 3\n",
      "4790. visual recognition  -> 3\n",
      "4791. on-premise llm deployment  -> 3\n",
      "4792. generative ai application development  -> 3\n",
      "4793. graph querying  -> 3\n",
      "4794. rl (reinforcement learning)  -> 3\n",
      "4795. rl environment design  -> 3\n",
      "4796. rl for llms  -> 3\n",
      "4797. risk analysis  -> 3\n",
      "4798. sagemaker processing  -> 3\n",
      "4799. safety classification  -> 3\n",
      "4800. graph analytics  -> 3\n",
      "4801. graph api  -> 3\n",
      "4802. graph attention networks (gat)  -> 3\n",
      "4803. graph construction  -> 3\n",
      "4804. sagemaker catalog  -> 3\n",
      "4805. sagemaker debugger  -> 3\n",
      "4806. sagemaker ground truth  -> 3\n",
      "4807. generative video model  -> 3\n",
      "4808. ai environment (linux)  -> 3\n",
      "4809. multispeaker tts  -> 3\n",
      "4810. multimodal summarization  -> 3\n",
      "4811. multimodal moderation  -> 3\n",
      "4812. multimodal pretraining  -> 3\n",
      "4813. ai hallucination  -> 3\n",
      "4814. ai for scientific discovery  -> 3\n",
      "4815. ai gateway  -> 3\n",
      "4816. google compute engine  -> 3\n",
      "4817. google assistant integration  -> 3\n",
      "4818. grain  -> 3\n",
      "4819. grammar checks  -> 3\n",
      "4820. gradient quantization  -> 3\n",
      "4821. gradient-based learning  -> 3\n",
      "4822. safety classifiers  -> 3\n",
      "4823. safety filters  -> 3\n",
      "4824. gnss  -> 3\n",
      "4825. github models  -> 3\n",
      "4826. github api  -> 3\n",
      "4827. github integration  -> 3\n",
      "4828. genomic analysis  -> 3\n",
      "4829. saas integration  -> 3\n",
      "4830. rtl design  -> 3\n",
      "4831. runnable  -> 3\n",
      "4832. multivariate time series  -> 3\n",
      "4833. music generation (ai)  -> 3\n",
      "4834. on-device models  -> 3\n",
      "4835. offloading  -> 3\n",
      "4836. ai coding tools  -> 3\n",
      "4837. gpu-accelerated computing  -> 3\n",
      "4838. gqa (grouped-query attention)  -> 3\n",
      "4839. gpu snapshotting  -> 3\n",
      "4840. ai capabilities  -> 3\n",
      "4841. ai auditability  -> 3\n",
      "4842. ai acceleration  -> 3\n",
      "4843. off-policy learning  -> 3\n",
      "4844. offensive security  -> 3\n",
      "4845. vs code integration  -> 3\n",
      "4846. volume rendering  -> 3\n",
      "4847. vpc networking  -> 3\n",
      "4848. ai act  -> 3\n",
      "4849. ai advertising  -> 3\n",
      "4850. agi development  -> 3\n",
      "4851. agi safety  -> 3\n",
      "4852. agentic search  -> 3\n",
      "4853. agentspace  -> 3\n",
      "4854. agent monitoring  -> 3\n",
      "4855. agent builder  -> 3\n",
      "4856. agentic context engineering  -> 3\n",
      "4857. wasserstein gan  -> 3\n",
      "4858. vulnerability discovery  -> 3\n",
      "4859. vulnerability management  -> 3\n",
      "4860. vulnerability research  -> 3\n",
      "4861. negative sampling  -> 3\n",
      "4862. nemotron  -> 3\n",
      "4863. ai accountability  -> 3\n",
      "4864. agentic browsing  -> 3\n",
      "4865. agentic capabilities  -> 3\n",
      "4866. agent workflows  -> 3\n",
      "4867. nerf (neural radiance fields)  -> 3\n",
      "4868. natural language queries  -> 3\n",
      "4869. natural language reasoning  -> 3\n",
      "4870. ode solvers  -> 3\n",
      "4871. agent engine  -> 3\n",
      "4872. graph data science  -> 3\n",
      "4873. ai for finance  -> 3\n",
      "4874. ai for healthcare  -> 3\n",
      "4875. ai for robotics  -> 3\n",
      "4876. natural language  -> 3\n",
      "4877. agentcore gateway  -> 3\n",
      "4878. agentcore runtime  -> 3\n",
      "4879. agentic ai development  -> 3\n",
      "4880. zero-3  -> 3\n",
      "4881. wireless sensing  -> 3\n",
      "4882. word error rate (wer)  -> 3\n",
      "4883. accelerated processing kit (xpk)  -> 3\n",
      "4884. nl-to-sql  -> 3\n",
      "4885. gpu infrastructure management  -> 3\n",
      "4886. neuron sdk  -> 3\n",
      "4887. workflow integration  -> 3\n",
      "4888. yamnet  -> 3\n",
      "4889. 3d model generation  -> 3\n",
      "4890. 3d parallelism  -> 3\n",
      "4891. 3d-unet  -> 3\n",
      "4892. 3d printing  -> 3\n",
      "4893. zero-shot voice cloning  -> 3\n",
      "4894. zero trust security  -> 3\n",
      "4895. zero++  -> 3\n",
      "4896. 3d image processing  -> 3\n",
      "4897. 3d avatar generation  -> 3\n",
      "4898. gpu kernel generation  -> 3\n",
      "4899. gpu kernel programming  -> 3\n",
      "4900. zero-shot evaluation  -> 3\n",
      "4901. zero optimization  -> 3\n",
      "4902. zero redundancy optimizer  -> 3\n",
      "4903. xtc sampling  -> 3\n",
      "4904. gpu parallelism  -> 3\n",
      "4905. gpu parallelization  -> 3\n",
      "4906. gpu performance tuning  -> 3\n",
      "4907. robust evaluation  -> 3\n",
      "4908. robust scaling  -> 3\n",
      "4909. gpu compute  -> 3\n",
      "4910. neural radiance caching  -> 3\n",
      "4911. 3d perception  -> 3\n",
      "4912. adaptive algorithms  -> 3\n",
      "4913. nvidia dgx  -> 3\n",
      "4914. whisperx  -> 3\n",
      "4915. wi-fi  -> 3\n",
      "4916. weight merging  -> 3\n",
      "4917. adaptive systems  -> 3\n",
      "4918. adobe photoshop  -> 3\n",
      "4919. adtech  -> 3\n",
      "4920. a2c  -> 3\n",
      "4921. abstention  -> 3\n",
      "4922. workflow engineering  -> 3\n",
      "4923. advanced analytics  -> 3\n",
      "4924. adaptive compute  -> 3\n",
      "4925. adaptive decoding  -> 3\n",
      "4926. adaptive sampling  -> 3\n",
      "4927. adaptability  -> 3\n",
      "4928. accelerator programming  -> 3\n",
      "4929. window functions  -> 3\n",
      "4930. windsurf  -> 3\n",
      "4931. weights and biases  -> 3\n",
      "4932. nvidia  -> 3\n",
      "4933. numba  -> 3\n",
      "4934. 3d scene understanding  -> 3\n",
      "4935. ad personalization  -> 3\n",
      "4936. npc behavior  -> 3\n",
      "4937. npu (neural processing unit)  -> 3\n",
      "4938. npu architecture  -> 3\n",
      "4939. noise robustness  -> 3\n",
      "4940. non-maximum suppression (nms)  -> 3\n",
      "4941. no-code ml  -> 3\n",
      "4942. 3d content generation  -> 3\n",
      "4943. accelerator architecture  -> 3\n",
      "4944. zmp control  -> 2\n",
      "4945. 1-bit inference  -> 2\n",
      "4946. 2d-to-3d conversion  -> 2\n",
      "4947. 3d avatar animation  -> 2\n",
      "4948. 3d content creation  -> 2\n",
      "4949. 3d generative ai  -> 2\n",
      "4950. 3d learning  -> 2\n",
      "4951. 3d modeling (ai-assisted)  -> 2\n",
      "4952. 3d neural networks  -> 2\n",
      "4953. xss  -> 2\n",
      "4954. xtc sampler  -> 2\n",
      "4955. y_test  -> 2\n",
      "4956. yarn scaling  -> 2\n",
      "4957. yolov5  -> 2\n",
      "4958. z-score standardization  -> 2\n",
      "4959. zepp coach  -> 2\n",
      "4960. zero trust architecture  -> 2\n",
      "4961. zero-day threat detection  -> 2\n",
      "4962. zero-shot generalization  -> 2\n",
      "4963. whole exome sequencing (wes)  -> 2\n",
      "4964. whole-body control  -> 2\n",
      "4965. wilcoxon signed-rank test  -> 2\n",
      "4966. win32  -> 2\n",
      "4967. winmltools  -> 2\n",
      "4968. wireless communication  -> 2\n",
      "4969. accent adaptation  -> 2\n",
      "4970. accurate quantized training (aqt)  -> 2\n",
      "4971. ademamix  -> 2\n",
      "4972. webdataset  -> 2\n",
      "4973. websocket apis  -> 2\n",
      "4974. webui  -> 2\n",
      "4975. webui development  -> 2\n",
      "4976. webxr  -> 2\n",
      "4977. weight sharing  -> 2\n",
      "4978. welch's t-test  -> 2\n",
      "4979. adamw optimizer  -> 2\n",
      "4980. adapter modules  -> 2\n",
      "4981. adapter training  -> 2\n",
      "4982. adapter-based fine-tuning  -> 2\n",
      "4983. adaptive noise cancellation  -> 2\n",
      "4984. adaptive rag  -> 2\n",
      "4985. adaptive rubrics  -> 2\n",
      "4986. adaptive temperature control  -> 2\n",
      "4987. adversarial testing/red teaming  -> 2\n",
      "4988. adversarial validation  -> 2\n",
      "4989. adverse event detection  -> 2\n",
      "4990. aerial image analysis  -> 2\n",
      "4991. agent communication  -> 2\n",
      "4992. ad tech  -> 2\n",
      "4993. adam-mini  -> 2\n",
      "4994. adamw optimization  -> 2\n",
      "4995. ndcg  -> 2\n",
      "4996. negative log likelihood  -> 2\n",
      "4997. negative log-likelihood (nll)  -> 2\n",
      "4998. nemo-rl  -> 2\n",
      "4999. network analysis  -> 2\n",
      "5000. network engineering  -> 2\n",
      "5001. network monitoring  -> 2\n",
      "5002. network protocols  -> 2\n",
      "5003. nvswitch  -> 2\n",
      "5004. object interaction modeling  -> 2\n",
      "5005. observability and logging  -> 2\n",
      "5006. observability for ai systems  -> 2\n",
      "5007. octave  -> 2\n",
      "5008. octokit  -> 2\n",
      "5009. natural language prompts  -> 2\n",
      "5010. nd4j  -> 2\n",
      "5011. neural implants  -> 2\n",
      "5012. neural network initialization  -> 2\n",
      "5013. neural operators  -> 2\n",
      "5014. neural search  -> 2\n",
      "5015. neural shaders  -> 2\n",
      "5016. nvidia jetson orin  -> 2\n",
      "5017. nvidia tensorrt  -> 2\n",
      "5018. nvidia thrust  -> 2\n",
      "5019. nf4 quantization  -> 2\n",
      "5020. nist ai rmf  -> 2\n",
      "5021. no-code ai tools  -> 2\n",
      "5022. no-code machine learning  -> 2\n",
      "5023. neural accelerator  -> 2\n",
      "5024. neural debugging  -> 2\n",
      "5025. neural fields  -> 2\n",
      "5026. neural game engine  -> 2\n",
      "5027. mxfp4 quantization  -> 2\n",
      "5028. mxfp8  -> 2\n",
      "5029. mysql  -> 2\n",
      "5030. n-gram models  -> 2\n",
      "5031. n-grams  -> 2\n",
      "5032. naive bayes  -> 2\n",
      "5033. naive seasonal  -> 2\n",
      "5034. nano banana  -> 2\n",
      "5035. on-policy distillation  -> 2\n",
      "5036. on-policy rl  -> 2\n",
      "5037. muonclip optimizer  -> 2\n",
      "5038. music recommendation  -> 2\n",
      "5039. music transcription  -> 2\n",
      "5040. musiclogo  -> 2\n",
      "5041. mutual information  -> 2\n",
      "5042. muzero  -> 2\n",
      "5043. offline rl  -> 2\n",
      "5044. olmo  -> 2\n",
      "5045. ols regression  -> 2\n",
      "5046. omegafold  -> 2\n",
      "5047. on-chip memory  -> 2\n",
      "5048. on-device llm deployment  -> 2\n",
      "5049. on-device local inference  -> 2\n",
      "5050. on-device vector search  -> 2\n",
      "5051. network telemetry  -> 2\n",
      "5052. network traffic analysis  -> 2\n",
      "5053. networkx  -> 2\n",
      "5054. off-policy evaluation  -> 2\n",
      "5055. off-policy reinforcement learning  -> 2\n",
      "5056. office automation  -> 2\n",
      "5057. offline ai  -> 2\n",
      "5058. offline inference  -> 2\n",
      "5059. multilingual speech recognition  -> 2\n",
      "5060. multilingual tokenization  -> 2\n",
      "5061. multilingual tokenizers  -> 2\n",
      "5062. multimedia forensics  -> 2\n",
      "5063. multimodal analysis  -> 2\n",
      "5064. multimodal analytics  -> 2\n",
      "5065. multimodal applications  -> 2\n",
      "5066. multimodal architecture  -> 2\n",
      "5067. open ai model  -> 2\n",
      "5068. open data  -> 2\n",
      "5069. open model training  -> 2\n",
      "5070. open source  -> 2\n",
      "5071. open source ai models  -> 2\n",
      "5072. open source ml  -> 2\n",
      "5073. multilingual ocr  -> 2\n",
      "5074. multilingual retrieval  -> 2\n",
      "5075. one-shot prompting  -> 2\n",
      "5076. one-vs-rest (ovr)  -> 2\n",
      "5077. onetrainer  -> 2\n",
      "5078. online evaluation  -> 2\n",
      "5079. ontologies  -> 2\n",
      "5080. ontology evolution  -> 2\n",
      "5081. ontology modeling  -> 2\n",
      "5082. oobabooga  -> 2\n",
      "5083. nanovlm  -> 2\n",
      "5084. natural language commands  -> 2\n",
      "5085. natural language instruction  -> 2\n",
      "5086. multimodal large language models (mllms)  -> 2\n",
      "5087. multimodal parsing  -> 2\n",
      "5088. multimodal planning  -> 2\n",
      "5089. multimodal tokenization  -> 2\n",
      "5090. one-class classification  -> 2\n",
      "5091. open-weights  -> 2\n",
      "5092. openai gpt oss  -> 2\n",
      "5093. openai gpt-oss  -> 2\n",
      "5094. multi-factor authentication  -> 2\n",
      "5095. multi-gpu computing  -> 2\n",
      "5096. multi-gpu deployment  -> 2\n",
      "5097. multi-gpu setup  -> 2\n",
      "5098. multi-gpu/nvlink  -> 2\n",
      "5099. multi-view fusion  -> 2\n",
      "5100. multicloud architecture  -> 2\n",
      "5101. multilayer perceptron  -> 2\n",
      "5102. open weight models  -> 2\n",
      "5103. open-domain question answering  -> 2\n",
      "5104. open-ended learning  -> 2\n",
      "5105. open-source  -> 2\n",
      "5106. open-source model release  -> 2\n",
      "5107. multi-robot coordination  -> 2\n",
      "5108. multi-scale rendering  -> 2\n",
      "5109. multi-speaker synthesis  -> 2\n",
      "5110. multi-touch attribution  -> 2\n",
      "5111. multi-turn dialogue management  -> 2\n",
      "5112. multi-turn evaluation  -> 2\n",
      "5113. multi-turn reasoning  -> 2\n",
      "5114. multi-turn rl  -> 2\n",
      "5115. multimodal audio understanding  -> 2\n",
      "5116. multimodal data fusion  -> 2\n",
      "5117. multimodal data processing  -> 2\n",
      "5118. multimodal diffusion  -> 2\n",
      "5119. multi-omics integration  -> 2\n",
      "5120. multi-party computation (mpc)  -> 2\n",
      "5121. multi-pass reasoning  -> 2\n",
      "5122. multi-person tracking  -> 2\n",
      "5123. modular  -> 2\n",
      "5124. modular data center design  -> 2\n",
      "5125. modular prompting  -> 2\n",
      "5126. moe kernels  -> 2\n",
      "5127. monitoring and logging  -> 2\n",
      "5128. monitoring and reporting  -> 2\n",
      "5129. monte carlo search  -> 2\n",
      "5130. monte carlo simulation  -> 2\n",
      "5131. openaiembeddings  -> 2\n",
      "5132. opencypher  -> 2\n",
      "5133. openeuler  -> 2\n",
      "5134. openhands  -> 2\n",
      "5135. openrlhf  -> 2\n",
      "5136. openusd  -> 2\n",
      "5137. moderation  -> 2\n",
      "5138. moderation api  -> 2\n",
      "5139. mttkrp  -> 2\n",
      "5140. multi-agent ai system  -> 2\n",
      "5141. multi-agent coordination  -> 2\n",
      "5142. multi-agent learning  -> 2\n",
      "5143. multi-armed bandits  -> 2\n",
      "5144. openai moderation api  -> 2\n",
      "5145. openai realtime api  -> 2\n",
      "5146. openai whisper  -> 2\n",
      "5147. multi-lingual language models  -> 2\n",
      "5148. multi-model deployment  -> 2\n",
      "5149. multi-node orchestration  -> 2\n",
      "5150. motion processing  -> 2\n",
      "5151. motor control  -> 2\n",
      "5152. mqa/gqa  -> 2\n",
      "5153. mrope  -> 2\n",
      "5154. mteb  -> 2\n",
      "5155. model-driven workflow  -> 2\n",
      "5156. model-tool interaction  -> 2\n",
      "5157. model_artifact_path  -> 2\n",
      "5158. model_name  -> 2\n",
      "5159. model_output_path  -> 2\n",
      "5160. modelarts  -> 2\n",
      "5161. modelcheckpoint  -> 2\n",
      "5162. modelscope  -> 2\n",
      "5163. model tracing  -> 2\n",
      "5164. model training data management  -> 2\n",
      "5165. model transparency  -> 2\n",
      "5166. model understanding  -> 2\n",
      "5167. model upscaling  -> 2\n",
      "5168. model-agnostic ai  -> 2\n",
      "5169. model-based evaluation  -> 2\n",
      "5170. model-context-protocol  -> 2\n",
      "5171. optimum-intel  -> 2\n",
      "5172. optuna  -> 2\n",
      "5173. oracle  -> 2\n",
      "5174. orchestrator  -> 2\n",
      "5175. ordinary differential equations (odes)  -> 2\n",
      "5176. orthogonality loss  -> 2\n",
      "5177. model testing and validation  -> 2\n",
      "5178. model theft  -> 2\n",
      "5179. opq  -> 2\n",
      "5180. optical networking  -> 2\n",
      "5181. optillm  -> 2\n",
      "5182. optimal control  -> 2\n",
      "5183. optimization (ai)  -> 2\n",
      "5184. optimizer (ml)  -> 2\n",
      "5185. optimizer sharding  -> 2\n",
      "5186. optimizers (ai)  -> 2\n",
      "5187. paddleocr  -> 2\n",
      "5188. paddlepaddle  -> 2\n",
      "5189. model deployment and scaling  -> 2\n",
      "5190. model diagnostics  -> 2\n",
      "5191. model evaluation (ai)  -> 2\n",
      "5192. model evaluation frameworks  -> 2\n",
      "5193. model flops utilization (mfu)  -> 2\n",
      "5194. mobilenetv3  -> 2\n",
      "5195. outlier handling  -> 2\n",
      "5196. outlook  -> 2\n",
      "5197. output parsers  -> 2\n",
      "5198. over-the-air updates  -> 2\n",
      "5199. owasp  -> 2\n",
      "5200. owasp llm top 10  -> 2\n",
      "5201. owl-vit  -> 2\n",
      "5202. p2p computing  -> 2\n",
      "5203. model soups  -> 2\n",
      "5204. model specialization  -> 2\n",
      "5205. model poisoning  -> 2\n",
      "5206. otlp  -> 2\n",
      "5207. out-of-core inference  -> 2\n",
      "5208. out-of-distribution testing  -> 2\n",
      "5209. out-of-sample testing  -> 2\n",
      "5210. out-of-time validation  -> 2\n",
      "5211. model porting  -> 2\n",
      "5212. model precision  -> 2\n",
      "5213. model probing  -> 2\n",
      "5214. model quantization (8-bit)  -> 2\n",
      "5215. model quantization (int4  -> 2\n",
      "5216. model refinement  -> 2\n",
      "5217. model reranking  -> 2\n",
      "5218. model serving and deployment  -> 2\n",
      "5219. mlx.distributed  -> 2\n",
      "5220. mmdit  -> 2\n",
      "5221. mnist  -> 2\n",
      "5222. mobile ai deployment  -> 2\n",
      "5223. mobile ai optimization  -> 2\n",
      "5224. mobile automation  -> 2\n",
      "5225. mobile computer vision  -> 2\n",
      "5226. mobile inference  -> 2\n",
      "5227. parallel tool calls  -> 2\n",
      "5228. parameter scaling  -> 2\n",
      "5229. mlc  -> 2\n",
      "5230. mlp (multi-layer perceptron)  -> 2\n",
      "5231. mlperf  -> 2\n",
      "5232. mlx (framework)  -> 2\n",
      "5233. mlx framework  -> 2\n",
      "5234. mlx lm  -> 2\n",
      "5235. pairwise comparison  -> 2\n",
      "5236. pairwise ranking  -> 2\n",
      "5237. pallas  -> 2\n",
      "5238. paper2agent  -> 2\n",
      "5239. parallel computing (ai)  -> 2\n",
      "5240. parallel execution  -> 2\n",
      "5241. parallel scaling  -> 2\n",
      "5242. parallel token decoding  -> 2\n",
      "5243. mode collapse mitigation  -> 2\n",
      "5244. model acceleration  -> 2\n",
      "5245. model archiving  -> 2\n",
      "5246. model attribution  -> 2\n",
      "5247. model cascading  -> 2\n",
      "5248. model chaining  -> 2\n",
      "5249. model collapse  -> 2\n",
      "5250. pagerank  -> 2\n",
      "5251. ml model registry  -> 2\n",
      "5252. ml models  -> 2\n",
      "5253. ml pipeline automation  -> 2\n",
      "5254. ml research  -> 2\n",
      "5255. ml subreddit  -> 2\n",
      "5256. ml system design  -> 2\n",
      "5257. ml systems  -> 2\n",
      "5258. ml workloads  -> 2\n",
      "5259. pbr texturing  -> 2\n",
      "5260. pbt  -> 2\n",
      "5261. ml experiment tracking  -> 2\n",
      "5262. ml for chip design  -> 2\n",
      "5263. ml infrastructure security  -> 2\n",
      "5264. ml lifecycle management  -> 2\n",
      "5265. ml loss functions  -> 2\n",
      "5266. ml model monitoring  -> 2\n",
      "5267. partial fine-tuning  -> 2\n",
      "5268. partially observable markov decision process (pomdp)  -> 2\n",
      "5269. partner ai app  -> 2\n",
      "5270. passage ranking  -> 2\n",
      "5271. passkeys  -> 2\n",
      "5272. passwordless authentication  -> 2\n",
      "5273. path tracing  -> 2\n",
      "5274. payments integration  -> 2\n",
      "5275. mobile ml optimization  -> 2\n",
      "5276. mobile robotics  -> 2\n",
      "5277. mobile testing  -> 2\n",
      "5278. parameter-efficient tuning  -> 2\n",
      "5279. parameters  -> 2\n",
      "5280. parametric human body models  -> 2\n",
      "5281. paraphrase augmentation  -> 2\n",
      "5282. paraphrase generation  -> 2\n",
      "5283. minference  -> 2\n",
      "5284. minhash  -> 2\n",
      "5285. minimal-pair probing  -> 2\n",
      "5286. mistral large  -> 2\n",
      "5287. mistral.rs  -> 2\n",
      "5288. mistral7b  -> 2\n",
      "5289. mit license  -> 2\n",
      "5290. mixed precision (bf16/fp32)  -> 2\n",
      "5291. performance benchmarking (ai)  -> 2\n",
      "5292. performance capture  -> 2\n",
      "5293. performance modeling  -> 2\n",
      "5294. microsoft purview  -> 2\n",
      "5295. microsoft sentinel  -> 2\n",
      "5296. mind uploading  -> 2\n",
      "5297. mindir  -> 2\n",
      "5298. mindspore lite  -> 2\n",
      "5299. ml evaluation  -> 2\n",
      "5300. pcie  -> 2\n",
      "5301. pde solvers  -> 2\n",
      "5302. pdf report  -> 2\n",
      "5303. pdf text extraction  -> 2\n",
      "5304. pearson correlation  -> 2\n",
      "5305. perception systems  -> 2\n",
      "5306. performance  -> 2\n",
      "5307. mixed precision (fp16/bf16/fp8)  -> 2\n",
      "5308. mixed precision training (bf16/fp16)  -> 2\n",
      "5309. mixed precision training/inference  -> 2\n",
      "5310. mixture of experts (moe) architecture  -> 2\n",
      "5311. mixture of experts (moe) models  -> 2\n",
      "5312. mixture-of-loras  -> 2\n",
      "5313. mixture-of-recursions (mor)  -> 2\n",
      "5314. ml compiler  -> 2\n",
      "5315. personalized content generation  -> 2\n",
      "5316. personalized learning (ai)  -> 2\n",
      "5317. pg_trgm  -> 2\n",
      "5318. phoenix  -> 2\n",
      "5319. phonemization  -> 2\n",
      "5320. photorealism  -> 2\n",
      "5321. medical entity recognition  -> 2\n",
      "5322. medical image processing  -> 2\n",
      "5323. mermaid.js  -> 2\n",
      "5324. message passing  -> 2\n",
      "5325. meta reinforcement fine-tuning (mrt)  -> 2\n",
      "5326. perplexity evaluation  -> 2\n",
      "5327. persistent memory systems  -> 2\n",
      "5328. person re-identification  -> 2\n",
      "5329. persona vectors  -> 2\n",
      "5330. personalized algorithm  -> 2\n",
      "5331. microsoft ag2  -> 2\n",
      "5332. memory retrieval  -> 2\n",
      "5333. memory safety  -> 2\n",
      "5334. memory-augmented transformers  -> 2\n",
      "5335. memory-efficient attention  -> 2\n",
      "5336. memory-efficient training/inference  -> 2\n",
      "5337. mental health detection  -> 2\n",
      "5338. mergekit  -> 2\n",
      "5339. mixed precision (bfloat16)  -> 2\n",
      "5340. metabolomics  -> 2\n",
      "5341. metadata standards  -> 2\n",
      "5342. metal gpu programming  -> 2\n",
      "5343. micro-batching  -> 2\n",
      "5344. microcontrollers  -> 2\n",
      "5345. microfluidics  -> 2\n",
      "5346. microprofile fault tolerance  -> 2\n",
      "5347. planner-executor  -> 2\n",
      "5348. matter protocol  -> 2\n",
      "5349. max tokens  -> 2\n",
      "5350. maximum marginal relevance (mmr)  -> 2\n",
      "5351. maxpooling  -> 2\n",
      "5352. mcp agents  -> 2\n",
      "5353. mcp-forge  -> 2\n",
      "5354. mcptools  -> 2\n",
      "5355. pid control  -> 2\n",
      "5356. pid controller  -> 2\n",
      "5357. pipeline monitoring  -> 2\n",
      "5358. pipelined training  -> 2\n",
      "5359. pipelining  -> 2\n",
      "5360. piper tts  -> 2\n",
      "5361. pkce  -> 2\n",
      "5362. plan-and-execute agents  -> 2\n",
      "5363. memory bank  -> 2\n",
      "5364. memory coalescing  -> 2\n",
      "5365. memory compression  -> 2\n",
      "5366. memory in llms  -> 2\n",
      "5367. memory mapping (mmap)  -> 2\n",
      "5368. php  -> 2\n",
      "5369. physically-based rendering (pbr)  -> 2\n",
      "5370. physics-informed ml  -> 2\n",
      "5371. medical robotics  -> 2\n",
      "5372. meeting transcription  -> 2\n",
      "5373. megatron  -> 2\n",
      "5374. meilisearch  -> 2\n",
      "5375. membership inference  -> 2\n",
      "5376. memoization  -> 2\n",
      "5377. memori  -> 2\n",
      "5378. memory and state management  -> 2\n",
      "5379. position-independent code (pic)  -> 2\n",
      "5380. machine learning monitoring  -> 2\n",
      "5381. machine learning security  -> 2\n",
      "5382. machine learning theory  -> 2\n",
      "5383. machine learning workflows  -> 2\n",
      "5384. machine reasoning  -> 2\n",
      "5385. majority voting  -> 2\n",
      "5386. malicious url detection  -> 2\n",
      "5387. plugins  -> 2\n",
      "5388. policy analysis  -> 2\n",
      "5389. policy compliance  -> 2\n",
      "5390. policy engineering  -> 2\n",
      "5391. policy improvement  -> 2\n",
      "5392. polynorm  -> 2\n",
      "5393. pose control  -> 2\n",
      "5394. position interpolation  -> 2\n",
      "5395. matchmaking algorithms  -> 2\n",
      "5396. material science  -> 2\n",
      "5397. matformer  -> 2\n",
      "5398. matrix computation  -> 2\n",
      "5399. matrix decomposition  -> 2\n",
      "5400. player modeling  -> 2\n",
      "5401. player tracking  -> 2\n",
      "5402. plotting  -> 2\n",
      "5403. mcts (monte carlo tree search)  -> 2\n",
      "5404. mdp (markov decision process)  -> 2\n",
      "5405. meanshift clustering  -> 2\n",
      "5406. media analysis  -> 2\n",
      "5407. media generation  -> 2\n",
      "5408. masked diffusion  -> 2\n",
      "5409. masked self-attention  -> 2\n",
      "5410. mastra  -> 2\n",
      "5411. low-resource fine-tuning  -> 2\n",
      "5412. low-resource nlp  -> 2\n",
      "5413. lru caching  -> 2\n",
      "5414. ls-gan  -> 2\n",
      "5415. lyria  -> 2\n",
      "5416. lyzr  -> 2\n",
      "5417. machine learning compilers  -> 2\n",
      "5418. machine learning for health  -> 2\n",
      "5419. precision-recall  -> 2\n",
      "5420. low-latency networking  -> 2\n",
      "5421. low-level optimization  -> 2\n",
      "5422. low-level programming  -> 2\n",
      "5423. low-light image processing  -> 2\n",
      "5424. low-precision computation  -> 2\n",
      "5425. low-rank factorization  -> 2\n",
      "5426. low-rank projection  -> 2\n",
      "5427. postgresml  -> 2\n",
      "5428. postman  -> 2\n",
      "5429. power efficiency  -> 2\n",
      "5430. power management  -> 2\n",
      "5431. pq/ivf  -> 2\n",
      "5432. pre-layer normalization  -> 2\n",
      "5433. precision agriculture  -> 2\n",
      "5434. precision and recall  -> 2\n",
      "5435. mamba models  -> 2\n",
      "5436. mamba-transformer  -> 2\n",
      "5437. mamba2  -> 2\n",
      "5438. managed connectors  -> 2\n",
      "5439. mape  -> 2\n",
      "5440. mapping and localization  -> 2\n",
      "5441. marketing analytics  -> 2\n",
      "5442. post-stratification  -> 2\n",
      "5443. log probability analysis  -> 2\n",
      "5444. log_artifact  -> 2\n",
      "5445. log_model_to_comet  -> 2\n",
      "5446. log_training_job  -> 2\n",
      "5447. logging & monitoring  -> 2\n",
      "5448. logging and monitoring  -> 2\n",
      "5449. logistics optimization  -> 2\n",
      "5450. logit  -> 2\n",
      "5451. price optimization  -> 2\n",
      "5452. prior predictive simulation  -> 2\n",
      "5453. privacy preservation  -> 2\n",
      "5454. privacy-by-design  -> 2\n",
      "5455. privacy-preserving computation  -> 2\n",
      "5456. privacy-preserving preprocessing  -> 2\n",
      "5457. private ai  -> 2\n",
      "5458. probability estimation  -> 2\n",
      "5459. lorma  -> 2\n",
      "5460. low latency ai  -> 2\n",
      "5461. low-code ai  -> 2\n",
      "5462. prefix caching  -> 2\n",
      "5463. presence penalty  -> 2\n",
      "5464. presto  -> 2\n",
      "5465. pretrained model fine-tuning  -> 2\n",
      "5466. pretraining datasets  -> 2\n",
      "5467. machine learning fundamentals  -> 2\n",
      "5468. long-context transformers  -> 2\n",
      "5469. long-document summarization  -> 2\n",
      "5470. long-form generation  -> 2\n",
      "5471. long-horizon reinforcement learning  -> 2\n",
      "5472. long-short sliding window attention  -> 2\n",
      "5473. long-term memory (ai)  -> 2\n",
      "5474. loop tiling  -> 2\n",
      "5475. llm sdks  -> 2\n",
      "5476. llm usage  -> 2\n",
      "5477. llm-assisted debugging  -> 2\n",
      "5478. llm-based code generation  -> 2\n",
      "5479. llm-based test generation  -> 2\n",
      "5480. llm.c  -> 2\n",
      "5481. llmchain  -> 2\n",
      "5482. llm hallucination  -> 2\n",
      "5483. production systems  -> 2\n",
      "5484. programmable silicon  -> 2\n",
      "5485. programming languages  -> 2\n",
      "5486. prolonged reinforcement learning (prorl)  -> 2\n",
      "5487. prompt adherence  -> 2\n",
      "5488. prompt augmentation  -> 2\n",
      "5489. prompt batching  -> 2\n",
      "5490. llm robustness  -> 2\n",
      "5491. local models  -> 2\n",
      "5492. local planning  -> 2\n",
      "5493. local seo  -> 2\n",
      "5494. processor architecture  -> 2\n",
      "5495. product design  -> 2\n",
      "5496. product discovery  -> 2\n",
      "5497. production ai systems  -> 2\n",
      "5498. production ml deployment  -> 2\n",
      "5499. logits distillation  -> 2\n",
      "5500. long context window management  -> 2\n",
      "5501. lm evaluation  -> 2\n",
      "5502. lm-eval-harness  -> 2\n",
      "5503. lm-evaluation-harness  -> 2\n",
      "5504. local ai development  -> 2\n",
      "5505. local ai inference  -> 2\n",
      "5506. local ai model deployment  -> 2\n",
      "5507. lipreading  -> 2\n",
      "5508. live ai  -> 2\n",
      "5509. livecodebench  -> 2\n",
      "5510. llama (model architecture)  -> 2\n",
      "5511. llama 3.1  -> 2\n",
      "5512. llama 4  -> 2\n",
      "5513. llama guard  -> 2\n",
      "5514. llama index  -> 2\n",
      "5515. prompt libraries  -> 2\n",
      "5516. prompt orchestration  -> 2\n",
      "5517. prompt rewriting  -> 2\n",
      "5518. prompt sanitization  -> 2\n",
      "5519. prompt weighting  -> 2\n",
      "5520. prompt-based editing  -> 2\n",
      "5521. promptwatch  -> 2\n",
      "5522. lip sync generation  -> 2\n",
      "5523. llm classification  -> 2\n",
      "5524. llm compilation  -> 2\n",
      "5525. llm compiler  -> 2\n",
      "5526. llm context  -> 2\n",
      "5527. llm context window management  -> 2\n",
      "5528. llm ensembles  -> 2\n",
      "5529. prompt construction  -> 2\n",
      "5530. prompt injection protection  -> 2\n",
      "5531. llm interaction  -> 2\n",
      "5532. llm management  -> 2\n",
      "5533. llm orchestration frameworks  -> 2\n",
      "5534. llm output validation  -> 2\n",
      "5535. llm parameter tuning  -> 2\n",
      "5536. llm personalization  -> 2\n",
      "5537. llamaextract  -> 2\n",
      "5538. llm agent framework  -> 2\n",
      "5539. proximity detection  -> 2\n",
      "5540. proximity sensing  -> 2\n",
      "5541. proxy management  -> 2\n",
      "5542. ptx programming  -> 2\n",
      "5543. pub/sub  -> 2\n",
      "5544. latent space modeling  -> 2\n",
      "5545. latent space representation  -> 2\n",
      "5546. latex parsing  -> 2\n",
      "5547. linear estimators  -> 2\n",
      "5548. linear probing  -> 2\n",
      "5549. property-based testing  -> 2\n",
      "5550. prosthetics  -> 2\n",
      "5551. protein-ligand docking  -> 2\n",
      "5552. proteomics  -> 2\n",
      "5553. protobuf  -> 2\n",
      "5554. protopaligned  -> 2\n",
      "5555. licensing compliance  -> 2\n",
      "5556. lidar mapping  -> 2\n",
      "5557. lifelong learning  -> 2\n",
      "5558. ligerkernel  -> 2\n",
      "5559. lightning attention  -> 2\n",
      "5560. linear algebra optimization  -> 2\n",
      "5561. linear decay learning rate  -> 2\n",
      "5562. linear estimation  -> 2\n",
      "5563. llama-3.1  -> 2\n",
      "5564. llama-deploy  -> 2\n",
      "5565. llama-swap  -> 2\n",
      "5566. lerobot  -> 2\n",
      "5567. lexical retrieval  -> 2\n",
      "5568. libtorch  -> 2\n",
      "5569. license compliance  -> 2\n",
      "5570. licensing  -> 2\n",
      "5571. pytorch compiler  -> 2\n",
      "5572. pytorch elastic  -> 2\n",
      "5573. pytorch fx  -> 2\n",
      "5574. pytorch jit  -> 2\n",
      "5575. langchain tools  -> 2\n",
      "5576. langextract  -> 2\n",
      "5577. langtrace  -> 2\n",
      "5578. language agents  -> 2\n",
      "5579. latent representation  -> 2\n",
      "5580. latent representation learning  -> 2\n",
      "5581. pufferlib  -> 2\n",
      "5582. pyannote.audio  -> 2\n",
      "5583. pycuda  -> 2\n",
      "5584. pydub  -> 2\n",
      "5585. pypi  -> 2\n",
      "5586. python scripting  -> 2\n",
      "5587. legal research  -> 2\n",
      "5588. legaltech  -> 2\n",
      "5589. large language model (llm) training  -> 2\n",
      "5590. large reasoning models (lrms)  -> 2\n",
      "5591. large-scale compute  -> 2\n",
      "5592. late fusion  -> 2\n",
      "5593. latent attention  -> 2\n",
      "5594. latent consistency models (lcm)  -> 2\n",
      "5595. layer duplication  -> 2\n",
      "5596. layer skip  -> 2\n",
      "5597. layernorm scaling  -> 2\n",
      "5598. ldap/ad  -> 2\n",
      "5599. lean theorem prover  -> 2\n",
      "5600. learning rate optimization  -> 2\n",
      "5601. learning rate schedules  -> 2\n",
      "5602. legal aspects of ai  -> 2\n",
      "5603. knowledge search  -> 2\n",
      "5604. knowledge-backed agents  -> 2\n",
      "5605. kobold  -> 2\n",
      "5606. kohya  -> 2\n",
      "5607. kohya-ss  -> 2\n",
      "5608. koyeb  -> 2\n",
      "5609. kql  -> 2\n",
      "5610. kd-tree  -> 2\n",
      "5611. quality control  -> 2\n",
      "5612. quantitative analysis  -> 2\n",
      "5613. quantization-aware fine-tuning  -> 2\n",
      "5614. quantized models  -> 2\n",
      "5615. quanto  -> 2\n",
      "5616. quantum algorithms  -> 2\n",
      "5617. knowledge base development  -> 2\n",
      "5618. knowledge graph fusion  -> 2\n",
      "5619. kv cache offload  -> 2\n",
      "5620. kv-cache quantization  -> 2\n",
      "5621. l2 distance  -> 2\n",
      "5622. l2-normalization  -> 2\n",
      "5623. laboratory automation  -> 2\n",
      "5624. q-galore  -> 2\n",
      "5625. qa automation  -> 2\n",
      "5626. qsar  -> 2\n",
      "5627. language learning  -> 2\n",
      "5628. language model architecture  -> 2\n",
      "5629. language model development  -> 2\n",
      "5630. kto (kahneman-tversky optimization)  -> 2\n",
      "5631. kubeedge  -> 2\n",
      "5632. kubeflow training operator  -> 2\n",
      "5633. kueue  -> 2\n",
      "5634. kunpeng 950  -> 2\n",
      "5635. qwen2  -> 2\n",
      "5636. qwen2.5  -> 2\n",
      "5637. radiology ai  -> 2\n",
      "5638. ipados development  -> 2\n",
      "5639. iris recognition  -> 2\n",
      "5640. isaac sim  -> 2\n",
      "5641. iso  -> 2\n",
      "5642. iso/iec 42001  -> 2\n",
      "5643. jwt authentication  -> 2\n",
      "5644. k-nn search  -> 2\n",
      "5645. k2-think  -> 2\n",
      "5646. quarot  -> 2\n",
      "5647. query engines  -> 2\n",
      "5648. question decomposition  -> 2\n",
      "5649. question-answering  -> 2\n",
      "5650. qwen-image-edit  -> 2\n",
      "5651. kiro  -> 2\n",
      "5652. kl-divergence  -> 2\n",
      "5653. klu.ai  -> 2\n",
      "5654. knn retrieval  -> 2\n",
      "5655. json mode  -> 2\n",
      "5656. json output  -> 2\n",
      "5657. junit  -> 2\n",
      "5658. just-in-time retrieval  -> 2\n",
      "5659. kernel dsls  -> 2\n",
      "5660. key information extraction (kie)  -> 2\n",
      "5661. key management  -> 2\n",
      "5662. keyframe animation  -> 2\n",
      "5663. keyframe generation  -> 2\n",
      "5664. keyword matching  -> 2\n",
      "5665. kibana  -> 2\n",
      "5666. kimi  -> 2\n",
      "5667. interface agents  -> 2\n",
      "5668. interpretability (ai)  -> 2\n",
      "5669. interpretable machine learning  -> 2\n",
      "5670. interpretive ai  -> 2\n",
      "5671. inventory forecasting  -> 2\n",
      "5672. invokeagentruntime  -> 2\n",
      "5673. ios  -> 2\n",
      "5674. ios app development  -> 2\n",
      "5675. rankers  -> 2\n",
      "5676. ranking models  -> 2\n",
      "5677. rapids  -> 2\n",
      "5678. raptor  -> 2\n",
      "5679. rationale distillation  -> 2\n",
      "5680. ray train  -> 2\n",
      "5681. rayturbo  -> 2\n",
      "5682. interconnect synthesis  -> 2\n",
      "5683. jetbrains ide  -> 2\n",
      "5684. jinja  -> 2\n",
      "5685. jinja2  -> 2\n",
      "5686. rag frameworks  -> 2\n",
      "5687. random network distillation (rnd)  -> 2\n",
      "5688. random seed  -> 2\n",
      "5689. randomized algorithms  -> 2\n",
      "5690. rank-bm25  -> 2\n",
      "5691. iterative closest point (icp)  -> 2\n",
      "5692. iterative fine-tuning  -> 2\n",
      "5693. iterative inference  -> 2\n",
      "5694. jackson  -> 2\n",
      "5695. java vector api  -> 2\n",
      "5696. javascript programming  -> 2\n",
      "5697. jax/xla  -> 2\n",
      "5698. jetbrains ai assistant  -> 2\n",
      "5699. real-time cybersecurity  -> 2\n",
      "5700. real-time decisioning  -> 2\n",
      "5701. real-time embedded systems  -> 2\n",
      "5702. real-time information retrieval  -> 2\n",
      "5703. real-time moderation  -> 2\n",
      "5704. inference orchestration  -> 2\n",
      "5705. inference runtime  -> 2\n",
      "5706. inference systems  -> 2\n",
      "5707. interaction recognition  -> 2\n",
      "5708. interactive segmentation  -> 2\n",
      "5709. react prompting  -> 2\n",
      "5710. react.js  -> 2\n",
      "5711. reactive 3d obstacle avoidance  -> 2\n",
      "5712. real-esrgan  -> 2\n",
      "5713. real-time bidding  -> 2\n",
      "5714. real-time conversational ai  -> 2\n",
      "5715. int8 training  -> 2\n",
      "5716. integer linear programming  -> 2\n",
      "5717. integration engineering  -> 2\n",
      "5718. intel mkl  -> 2\n",
      "5719. intel tdx  -> 2\n",
      "5720. intelligence  -> 2\n",
      "5721. intelligent robotics  -> 2\n",
      "5722. intent optimization  -> 2\n",
      "5723. iot ai  -> 2\n",
      "5724. iot analytics  -> 2\n",
      "5725. iot data integration  -> 2\n",
      "5726. iot data processing  -> 2\n",
      "5727. iot security  -> 2\n",
      "5728. instruction following (ai)  -> 2\n",
      "5729. instruction generation  -> 2\n",
      "5730. int8 optimization  -> 2\n",
      "5731. reasoning frameworks  -> 2\n",
      "5732. reasoning systems  -> 2\n",
      "5733. rebuff.ai  -> 2\n",
      "5734. imagebind  -> 2\n",
      "5735. imagen 3  -> 2\n",
      "5736. impersonation detection  -> 2\n",
      "5737. implicit world modeling  -> 2\n",
      "5738. importance sampling  -> 2\n",
      "5739. inference endpoints  -> 2\n",
      "5740. inference latency optimization  -> 2\n",
      "5741. real-time speech recognition  -> 2\n",
      "5742. real-time video ai  -> 2\n",
      "5743. real-time video generation  -> 2\n",
      "5744. real-time voice ai  -> 2\n",
      "5745. real-time web retrieval  -> 2\n",
      "5746. reasoning benchmarks  -> 2\n",
      "5747. incremental indexing  -> 2\n",
      "5748. incremental retraining  -> 2\n",
      "5749. indel detection  -> 2\n",
      "5750. indexes  -> 2\n",
      "5751. indexing strategies  -> 2\n",
      "5752. indexivfpq  -> 2\n",
      "5753. inductive bias  -> 2\n",
      "5754. industrial robotics  -> 2\n",
      "5755. inference-time optimization  -> 2\n",
      "5756. inference-time techniques  -> 2\n",
      "5757. inference-time training  -> 2\n",
      "5758. information retrieval evaluation  -> 2\n",
      "5759. information synthesis  -> 2\n",
      "5760. infrastructure scaling  -> 2\n",
      "5761. insecure output handling  -> 2\n",
      "5762. incident response automation  -> 2\n",
      "5763. referring expression generation  -> 2\n",
      "5764. reflection (ai)  -> 2\n",
      "5765. reflection-tuning  -> 2\n",
      "5766. reflex  -> 2\n",
      "5767. image diffusion  -> 2\n",
      "5768. image encoders  -> 2\n",
      "5769. image generation models  -> 2\n",
      "5770. image manipulation (ai)  -> 2\n",
      "5771. record-and-playback automation  -> 2\n",
      "5772. recurrent models  -> 2\n",
      "5773. recurrent transformers  -> 2\n",
      "5774. recursive neural networks  -> 2\n",
      "5775. recursive self-improvement  -> 2\n",
      "5776. redaction  -> 2\n",
      "5777. reducelronplateau  -> 2\n",
      "5778. reference resolution  -> 2\n",
      "5779. image prompting  -> 2\n",
      "5780. image quality enhancement  -> 2\n",
      "5781. image stitching  -> 2\n",
      "5782. image style transfer  -> 2\n",
      "5783. image text parsing  -> 2\n",
      "5784. image to video  -> 2\n",
      "5785. image transformation  -> 2\n",
      "5786. image-text understanding  -> 2\n",
      "5787. impromptu  -> 2\n",
      "5788. imu data processing  -> 2\n",
      "5789. in-browser ai deployment  -> 2\n",
      "5790. in-browser ml  -> 2\n",
      "5791. in-context fine-tuning  -> 2\n",
      "5792. in-context image editing  -> 2\n",
      "5793. in-database ai  -> 2\n",
      "5794. in-place operations  -> 2\n",
      "5795. relevance tuning  -> 2\n",
      "5796. human-in-the-loop annotation  -> 2\n",
      "5797. human-in-the-loop learning  -> 2\n",
      "5798. human-in-the-loop training  -> 2\n",
      "5799. human-in-the-loop verification  -> 2\n",
      "5800. hybrid cloud deployment  -> 2\n",
      "5801. hybrid cooling systems  -> 2\n",
      "5802. hybrid index  -> 2\n",
      "5803. identity provider integration  -> 2\n",
      "5804. ifeval  -> 2\n",
      "5805. regulatory sandboxes  -> 2\n",
      "5806. reinforcement learning (rl fine-tuning)  -> 2\n",
      "5807. reinforcement learning from feedback (rlf)  -> 2\n",
      "5808. reinforcement learning with human feedback  -> 2\n",
      "5809. reinforcement learning with verifiable reward  -> 2\n",
      "5810. relational graph convolutional networks  -> 2\n",
      "5811. ibm watsonx orchestrate  -> 2\n",
      "5812. icd-10  -> 2\n",
      "5813. ide  -> 2\n",
      "5814. ide development  -> 2\n",
      "5815. idefics2  -> 2\n",
      "5816. idempotency  -> 2\n",
      "5817. identity federation  -> 2\n",
      "5818. identity preference optimization  -> 2\n",
      "5819. image masking  -> 2\n",
      "5820. image normalization  -> 2\n",
      "5821. hydra  -> 2\n",
      "5822. hyper-personalization  -> 2\n",
      "5823. hyperautomation  -> 2\n",
      "5824. hyperparameter  -> 2\n",
      "5825. iam security  -> 2\n",
      "5826. ibm cloud pak for data  -> 2\n",
      "5827. residual analysis  -> 2\n",
      "5828. residual vector quantization (rvq)  -> 2\n",
      "5829. resilience  -> 2\n",
      "5830. resilience engineering  -> 2\n",
      "5831. hdr processing  -> 2\n",
      "5832. health analytics  -> 2\n",
      "5833. health data analysis  -> 2\n",
      "5834. health monitoring  -> 2\n",
      "5835. html  -> 2\n",
      "5836. html/css generation  -> 2\n",
      "5837. reliability  -> 2\n",
      "5838. relu activation function  -> 2\n",
      "5839. remote direct memory access  -> 2\n",
      "5840. remote patient monitoring  -> 2\n",
      "5841. reproducible ml pipelines  -> 2\n",
      "5842. reproducible tests  -> 2\n",
      "5843. high-content imaging  -> 2\n",
      "5844. high-performance ml  -> 2\n",
      "5845. high-speed connectivity  -> 2\n",
      "5846. high-speed inference  -> 2\n",
      "5847. hitl (human-in-the-loop)  -> 2\n",
      "5848. hive metastore  -> 2\n",
      "5849. hnsw indexing  -> 2\n",
      "5850. hqq  -> 2\n",
      "5851. hybrid reasoning models  -> 2\n",
      "5852. hybrid scoring  -> 2\n",
      "5853. httpx  -> 2\n",
      "5854. hugging face inference  -> 2\n",
      "5855. huggingfacehub  -> 2\n",
      "5856. human feedback  -> 2\n",
      "5857. hierarchical task networks (htn)  -> 2\n",
      "5858. high-bandwidth interconnect  -> 2\n",
      "5859. retail ai  -> 2\n",
      "5860. retraining pipeline  -> 2\n",
      "5861. retrieval augmented finetuning (raft)  -> 2\n",
      "5862. retrieval-augmented finetuning  -> 2\n",
      "5863. retrieval-interleaved generation (rig)  -> 2\n",
      "5864. grounded retrieval  -> 2\n",
      "5865. groundedness  -> 2\n",
      "5866. group sequence policy optimization (gspo)  -> 2\n",
      "5867. harmful content detection  -> 2\n",
      "5868. resilience4j  -> 2\n",
      "5869. resource allocation  -> 2\n",
      "5870. resource scheduling  -> 2\n",
      "5871. resource-constrained ai  -> 2\n",
      "5872. resource-efficient ai  -> 2\n",
      "5873. rest api development  -> 2\n",
      "5874. restricted boltzmann machines (rbm)  -> 2\n",
      "5875. hierarchical reinforcement learning  -> 2\n",
      "5876. hierarchical retrieval  -> 2\n",
      "5877. hallucination detection/mitigation  -> 2\n",
      "5878. hardware compatibility  -> 2\n",
      "5879. hardware for ai  -> 2\n",
      "5880. hardware-accelerated inference  -> 2\n",
      "5881. hardware-aware ml  -> 2\n",
      "5882. harm detection  -> 2\n",
      "5883. health monitoring ai  -> 2\n",
      "5884. healthcare  -> 2\n",
      "5885. heart rate monitoring  -> 2\n",
      "5886. heterogeneous graph learning  -> 2\n",
      "5887. hidiffusion  -> 2\n",
      "5888. hierarchical aggregation  -> 2\n",
      "5889. hierarchical chunking  -> 2\n",
      "5890. hierarchical multi-agent system  -> 2\n",
      "5891. rl post-training  -> 2\n",
      "5892. graph optimization  -> 2\n",
      "5893. graph processing  -> 2\n",
      "5894. graph retrieval  -> 2\n",
      "5895. graph search  -> 2\n",
      "5896. graph-based ai  -> 2\n",
      "5897. graph-based retrieval  -> 2\n",
      "5898. graphic generation  -> 2\n",
      "5899. reward model serving  -> 2\n",
      "5900. rgba video generation  -> 2\n",
      "5901. rigging  -> 2\n",
      "5902. risk banding  -> 2\n",
      "5903. risk mitigation  -> 2\n",
      "5904. risk prioritization  -> 2\n",
      "5905. risk stratification  -> 2\n",
      "5906. rknn  -> 2\n",
      "5907. half-precision training  -> 2\n",
      "5908. hall effect switches  -> 2\n",
      "5909. retriever development  -> 2\n",
      "5910. retriever tuning  -> 2\n",
      "5911. retry strategies  -> 2\n",
      "5912. reverse image search  -> 2\n",
      "5913. reward function  -> 2\n",
      "5914. reward learning  -> 2\n",
      "5915. group tracking  -> 2\n",
      "5916. group-aware time series split  -> 2\n",
      "5917. guardrails ai  -> 2\n",
      "5918. gui localization  -> 2\n",
      "5919. guided text generation  -> 2\n",
      "5920. gym-dssat  -> 2\n",
      "5921. h100 gpu programming  -> 2\n",
      "5922. h100 training  -> 2\n",
      "5923. robots.txt  -> 2\n",
      "5924. robots.txt compliance  -> 2\n",
      "5925. robust learning  -> 2\n",
      "5926. gpu passthrough  -> 2\n",
      "5927. gpu troubleshooting  -> 2\n",
      "5928. gpu virtualization  -> 2\n",
      "5929. gpu-accelerated inference  -> 2\n",
      "5930. gpu-accelerated training  -> 2\n",
      "5931. rmse  -> 2\n",
      "5932. rmsprop  -> 2\n",
      "5933. robot locomotion  -> 2\n",
      "5934. robot simulation  -> 2\n",
      "5935. robot training  -> 2\n",
      "5936. robotaxi systems  -> 2\n",
      "5937. robotic perception  -> 2\n",
      "5938. robotics vision  -> 2\n",
      "5939. grammar correction  -> 2\n",
      "5940. grammar-guided decoding  -> 2\n",
      "5941. granite  -> 2\n",
      "5942. graph  -> 2\n",
      "5943. graph foundation models  -> 2\n",
      "5944. graph isomorphic networks (gin)  -> 2\n",
      "5945. graph learning  -> 2\n",
      "5946. rlaif (reinforcement learning from ai feedback)  -> 2\n",
      "5947. graphmend  -> 2\n",
      "5948. graphson  -> 2\n",
      "5949. gritlm  -> 2\n",
      "5950. grokking  -> 2\n",
      "5951. grounded llms  -> 2\n",
      "5952. gradient computation  -> 2\n",
      "5953. gradient optimization  -> 2\n",
      "5954. gradient-boosted decision trees  -> 2\n",
      "5955. google genai api  -> 2\n",
      "5956. google genai sdk  -> 2\n",
      "5957. google generative ai  -> 2\n",
      "5958. google identity platform  -> 2\n",
      "5959. google llms  -> 2\n",
      "5960. google maps platform  -> 2\n",
      "5961. google perspective api  -> 2\n",
      "5962. google search api  -> 2\n",
      "5963. rope (rotary positional embedding)  -> 2\n",
      "5964. rope positional embeddings  -> 2\n",
      "5965. rotary position embedding (rope)  -> 2\n",
      "5966. rotary position encoding  -> 2\n",
      "5967. rotary positional embeddings  -> 2\n",
      "5968. roundrobingroupchat  -> 2\n",
      "5969. rpc  -> 2\n",
      "5970. google distributed cloud (gdc)  -> 2\n",
      "5971. gpu drivers  -> 2\n",
      "5972. gpu hardware knowledge  -> 2\n",
      "5973. robustness evaluation  -> 2\n",
      "5974. robustness to noise  -> 2\n",
      "5975. rocm programming  -> 2\n",
      "5976. rocm/hip  -> 2\n",
      "5977. root-cause analysis  -> 2\n",
      "5978. rope (rotary position encoding)  -> 2\n",
      "5979. gpu/hpc  -> 2\n",
      "5980. gpu/tpu  -> 2\n",
      "5981. gpu/vram optimization  -> 2\n",
      "5982. gradient analysis  -> 2\n",
      "5983. gradient ascent  -> 2\n",
      "5984. gpt-neo  -> 2\n",
      "5985. gpu cloud  -> 2\n",
      "5986. gpu design  -> 2\n",
      "5987. safety analysis  -> 2\n",
      "5988. genkit  -> 2\n",
      "5989. geolocation  -> 2\n",
      "5990. geometric deep learning  -> 2\n",
      "5991. geospatial mapping  -> 2\n",
      "5992. geospatial visualization  -> 2\n",
      "5993. gesture generation  -> 2\n",
      "5994. gguf model format  -> 2\n",
      "5995. google cloud marketplace  -> 2\n",
      "5996. google cloud tpu  -> 2\n",
      "5997. google deepmind  -> 2\n",
      "5998. runbook automation  -> 2\n",
      "5999. runtime  -> 2\n",
      "6000. runtime governance  -> 2\n",
      "6001. runway gen  -> 2\n",
      "6002. rényi entropy  -> 2\n",
      "6003. global attention  -> 2\n",
      "6004. global planning  -> 2\n",
      "6005. global-batch load balancing  -> 2\n",
      "6006. glue  -> 2\n",
      "6007. google  -> 2\n",
      "6008. google agent development kit (adk)  -> 2\n",
      "6009. google ai models  -> 2\n",
      "6010. google bigquery  -> 2\n",
      "6011. google serper api  -> 2\n",
      "6012. google tensor  -> 2\n",
      "6013. gpqa diamond  -> 2\n",
      "6014. gpt api integration  -> 2\n",
      "6015. gpt integration  -> 2\n",
      "6016. gpt-4 turbo  -> 2\n",
      "6017. gpt-4v  -> 2\n",
      "6018. glm  -> 2\n",
      "6019. gddr memory  -> 2\n",
      "6020. gdpr)  -> 2\n",
      "6021. gelu  -> 2\n",
      "6022. gemini (google llm)  -> 2\n",
      "6023. gemini 2.5 pro  -> 2\n",
      "6024. gemma 2  -> 2\n",
      "6025. gen ai  -> 2\n",
      "6026. genai evaluation service  -> 2\n",
      "6027. generators  -> 2\n",
      "6028. sagemaker batch transform  -> 2\n",
      "6029. sagemaker data wrangler  -> 2\n",
      "6030. sagemaker projects  -> 2\n",
      "6031. salesforce agentforce  -> 2\n",
      "6032. sampling algorithms  -> 2\n",
      "6033. gaze tracking  -> 2\n",
      "6034. gcp text-embedding-005  -> 2\n",
      "6035. generative ai (music)  -> 2\n",
      "6036. generative ai (voice)  -> 2\n",
      "6037. generative ai agent  -> 2\n",
      "6038. generative ai security  -> 2\n",
      "6039. generative image editing  -> 2\n",
      "6040. generative media models  -> 2\n",
      "6041. generative music  -> 2\n",
      "6042. generative simulation  -> 2\n",
      "6043. gin index  -> 2\n",
      "6044. gini impurity  -> 2\n",
      "6045. gist index  -> 2\n",
      "6046. git/github  -> 2\n",
      "6047. github codespaces  -> 2\n",
      "6048. github copilot integration  -> 2\n",
      "6049. generation control  -> 2\n",
      "6050. generative 3d models  -> 2\n",
      "6051. framework integration  -> 2\n",
      "6052. frequency analysis  -> 2\n",
      "6053. frequency domain analysis  -> 2\n",
      "6054. frequency penalty  -> 2\n",
      "6055. frequency-domain analysis  -> 2\n",
      "6056. fréchet inception distance (fid)  -> 2\n",
      "6057. full self-driving (fsd)  -> 2\n",
      "6058. function calling (llm function calling)  -> 2\n",
      "6059. scala  -> 2\n",
      "6060. scalability (ai systems)  -> 2\n",
      "6061. scalable deployment  -> 2\n",
      "6062. scalable inference  -> 2\n",
      "6063. scalable intent driven routing (sidr)  -> 2\n",
      "6064. scalable llm infrastructure  -> 2\n",
      "6065. scalable ml deployment  -> 2\n",
      "6066. frame-aware positional encoding  -> 2\n",
      "6067. gatconv  -> 2\n",
      "6068. gated deltanet  -> 2\n",
      "6069. gating mechanisms  -> 2\n",
      "6070. gaussdb  -> 2\n",
      "6071. gaze detection  -> 2\n",
      "6072. sarsa  -> 2\n",
      "6073. sass  -> 2\n",
      "6074. scaffolding  -> 2\n",
      "6075. gene expression analysis  -> 2\n",
      "6076. fuzzy matching  -> 2\n",
      "6077. fvd  -> 2\n",
      "6078. g2pe  -> 2\n",
      "6079. game asset generation  -> 2\n",
      "6080. game generation  -> 2\n",
      "6081. game theory for ai  -> 2\n",
      "6082. gans (generative adversarial networks)  -> 2\n",
      "6083. fine-tuning ai models  -> 2\n",
      "6084. fingerprint recognition  -> 2\n",
      "6085. firefly ai  -> 2\n",
      "6086. firejail  -> 2\n",
      "6087. firestore  -> 2\n",
      "6088. flamingo  -> 2\n",
      "6089. flash attention 2  -> 2\n",
      "6090. flask-ngrok  -> 2\n",
      "6091. schema inference  -> 2\n",
      "6092. scientific literature mining  -> 2\n",
      "6093. scientific simulation  -> 2\n",
      "6094. scikit-learn pipelines  -> 2\n",
      "6095. scim  -> 2\n",
      "6096. score aggregation  -> 2\n",
      "6097. screen parsing  -> 2\n",
      "6098. search apis  -> 2\n",
      "6099. food recognition  -> 2\n",
      "6100. foreign function & memory api  -> 2\n",
      "6101. formal logic  -> 2\n",
      "6102. foundation model development  -> 2\n",
      "6103. fp16 training  -> 2\n",
      "6104. fp6 quantization  -> 2\n",
      "6105. fp8 mixed precision training  -> 2\n",
      "6106. scene detection  -> 2\n",
      "6107. flops optimization  -> 2\n",
      "6108. florence-2  -> 2\n",
      "6109. flow models  -> 2\n",
      "6110. flowise  -> 2\n",
      "6111. flowspec  -> 2\n",
      "6112. flux kontext  -> 2\n",
      "6113. flux.1 kontext  -> 2\n",
      "6114. foley synthesis  -> 2\n",
      "6115. secure sandboxing  -> 2\n",
      "6116. secure software supply chain  -> 2\n",
      "6117. security & compliance  -> 2\n",
      "6118. falcon  -> 2\n",
      "6119. falkordb  -> 2\n",
      "6120. fast fourier transform (fft)  -> 2\n",
      "6121. fastdeploy  -> 2\n",
      "6122. fault-tolerant training  -> 2\n",
      "6123. fine-grained classification  -> 2\n",
      "6124. fine-tuning (models)  -> 2\n",
      "6125. search grounding  -> 2\n",
      "6126. search optimization  -> 2\n",
      "6127. search technology  -> 2\n",
      "6128. secret scanning  -> 2\n",
      "6129. secure ai development  -> 2\n",
      "6130. secure data handling  -> 2\n",
      "6131. fiftyone  -> 2\n",
      "6132. figma  -> 2\n",
      "6133. figma api  -> 2\n",
      "6134. file search  -> 2\n",
      "6135. file system integration  -> 2\n",
      "6136. filtering  -> 2\n",
      "6137. fim (fill-in-the-middle)  -> 2\n",
      "6138. financial services  -> 2\n",
      "6139. flat index  -> 2\n",
      "6140. flight control  -> 2\n",
      "6141. flight control systems  -> 2\n",
      "6142. float16  -> 2\n",
      "6143. float8 quantization  -> 2\n",
      "6144. floating point arithmetic  -> 2\n",
      "6145. federation  -> 2\n",
      "6146. fedramp compliance  -> 2\n",
      "6147. expected calibration error (ece)  -> 2\n",
      "6148. experiment management  -> 2\n",
      "6149. experimental projects  -> 2\n",
      "6150. experimentation platforms  -> 2\n",
      "6151. expert routing  -> 2\n",
      "6152. exponential smoothing  -> 2\n",
      "6153. express.js  -> 2\n",
      "6154. extended reality  -> 2\n",
      "6155. security compliance  -> 2\n",
      "6156. security vulnerability detection  -> 2\n",
      "6157. selectorgroupchat  -> 2\n",
      "6158. self attention  -> 2\n",
      "6159. self-driving capabilities  -> 2\n",
      "6160. self-driving systems  -> 2\n",
      "6161. self-hosted ai  -> 2\n",
      "6162. execution_role  -> 2\n",
      "6163. facial analysis  -> 2\n",
      "6164. facial expression recognition  -> 2\n",
      "6165. facial expression transfer  -> 2\n",
      "6166. facial reenactment  -> 2\n",
      "6167. factuality in llms  -> 2\n",
      "6168. fair use  -> 2\n",
      "6169. fairgame  -> 2\n",
      "6170. security best practices  -> 2\n",
      "6171. feature detection  -> 2\n",
      "6172. feature drift  -> 2\n",
      "6173. feature learning  -> 2\n",
      "6174. feature processing  -> 2\n",
      "6175. federated queries  -> 2\n",
      "6176. face verification  -> 2\n",
      "6177. facebook analytics  -> 2\n",
      "6178. faceted search  -> 2\n",
      "6179. environment simulation  -> 2\n",
      "6180. epidemiological modeling  -> 2\n",
      "6181. epigenomics  -> 2\n",
      "6182. episodic memory  -> 2\n",
      "6183. equivariant networks  -> 2\n",
      "6184. ernie  -> 2\n",
      "6185. esm2  -> 2\n",
      "6186. esmfold  -> 2\n",
      "6187. semantic compression  -> 2\n",
      "6188. semantic editing  -> 2\n",
      "6189. semantic technologies  -> 2\n",
      "6190. enterprise application integration  -> 2\n",
      "6191. enterprise automation  -> 2\n",
      "6192. enterprise deployment  -> 2\n",
      "6193. enterprise systems integration  -> 2\n",
      "6194. entropy-based sampling  -> 2\n",
      "6195. event processing  -> 2\n",
      "6196. event-based vision  -> 2\n",
      "6197. event-driven programming  -> 2\n",
      "6198. evidence extraction  -> 2\n",
      "6199. evm  -> 2\n",
      "6200. excel automation  -> 2\n",
      "6201. execution traces  -> 2\n",
      "6202. self-refine  -> 2\n",
      "6203. external tool use  -> 2\n",
      "6204. external tools  -> 2\n",
      "6205. external verification  -> 2\n",
      "6206. ethereum  -> 2\n",
      "6207. ethical oversight  -> 2\n",
      "6208. euv lithography  -> 2\n",
      "6209. evaluation metrics (f1 score)  -> 2\n",
      "6210. evaluation pipelines  -> 2\n",
      "6211. embedding similarity  -> 2\n",
      "6212. embedding-based privacy  -> 2\n",
      "6213. embeddinggemma  -> 2\n",
      "6214. embodied conversational agents  -> 2\n",
      "6215. embodied navigation  -> 2\n",
      "6216. embodied vision  -> 2\n",
      "6217. emergent behavior  -> 2\n",
      "6218. emotion transfer  -> 2\n",
      "6219. sensitive data detection  -> 2\n",
      "6220. sensor calibration  -> 2\n",
      "6221. sensor technology  -> 2\n",
      "6222. sequence analysis  -> 2\n",
      "6223. sequence generation  -> 2\n",
      "6224. sequence modelling  -> 2\n",
      "6225. email triage  -> 2\n",
      "6226. embedding engineering  -> 2\n",
      "6227. energy systems modeling  -> 2\n",
      "6228. energy-efficient inference  -> 2\n",
      "6229. ensembleretriever  -> 2\n",
      "6230. enterprise ai deployment  -> 2\n",
      "6231. enterprise ai development  -> 2\n",
      "6232. enterprise ai governance  -> 2\n",
      "6233. semiconductor design  -> 2\n",
      "6234. semiconductor research  -> 2\n",
      "6235. encoder  -> 2\n",
      "6236. end-to-end language models  -> 2\n",
      "6237. end-to-end machine learning  -> 2\n",
      "6238. end-to-end ml  -> 2\n",
      "6239. endpoints  -> 2\n",
      "6240. energy consumption  -> 2\n",
      "6241. energy management  -> 2\n",
      "6242. energy optimization  -> 2\n",
      "6243. servicenow  -> 2\n",
      "6244. serving frameworks  -> 2\n",
      "6245. session tracking  -> 2\n",
      "6246. setfit  -> 2\n",
      "6247. shader programming  -> 2\n",
      "6248. dynamic tool discovery  -> 2\n",
      "6249. dynamo  -> 2\n",
      "6250. ec2 ultraclusters  -> 2\n",
      "6251. server architecture  -> 2\n",
      "6252. serverless ai  -> 2\n",
      "6253. serverless gpu  -> 2\n",
      "6254. serverless ml  -> 2\n",
      "6255. serverless rl  -> 2\n",
      "6256. serversentevents  -> 2\n",
      "6257. service automation  -> 2\n",
      "6258. service quotas  -> 2\n",
      "6259. efficient llm training  -> 2\n",
      "6260. efficient model architectures  -> 2\n",
      "6261. egocentric vision  -> 2\n",
      "6262. eigen decomposition  -> 2\n",
      "6263. eksctl  -> 2\n",
      "6264. email automation  -> 2\n",
      "6265. sequential decision making  -> 2\n",
      "6266. serper api  -> 2\n",
      "6267. emr  -> 2\n",
      "6268. eeg signal processing  -> 2\n",
      "6269. eesel ai  -> 2\n",
      "6270. efa (elastic fabric adapter)  -> 2\n",
      "6271. efficiency  -> 2\n",
      "6272. efficient ai architectures  -> 2\n",
      "6273. efficient ai models  -> 2\n",
      "6274. efficient decoding  -> 2\n",
      "6275. dual-encoder architecture  -> 2\n",
      "6276. dual-encoder retrieval  -> 2\n",
      "6277. dual-image encoding  -> 2\n",
      "6278. duckdb wasm  -> 2\n",
      "6279. duckduckgo api  -> 2\n",
      "6280. durable objects  -> 2\n",
      "6281. dynamic 4-bit quantization  -> 2\n",
      "6282. dynamic context retrieval  -> 2\n",
      "6283. sigmoid attention  -> 2\n",
      "6284. sign language processing  -> 2\n",
      "6285. sign language recognition  -> 2\n",
      "6286. sim.ai  -> 2\n",
      "6287. driver assist systems  -> 2\n",
      "6288. driver monitoring  -> 2\n",
      "6289. drone control  -> 2\n",
      "6290. drug discovery (ai)  -> 2\n",
      "6291. shallow-deep feature alignment  -> 2\n",
      "6292. shallow-fakefacenet  -> 2\n",
      "6293. shape recognition  -> 2\n",
      "6294. sharded model loading  -> 2\n",
      "6295. sharepoint integration  -> 2\n",
      "6296. shielded reinforcement learning  -> 2\n",
      "6297. siglip2  -> 2\n",
      "6298. sigmoid  -> 2\n",
      "6299. ecg signal processing  -> 2\n",
      "6300. edge guardrails  -> 2\n",
      "6301. edge/mobile deployment  -> 2\n",
      "6302. edge/on-device deployment  -> 2\n",
      "6303. edges  -> 2\n",
      "6304. edu-prompting  -> 2\n",
      "6305. educational ai  -> 2\n",
      "6306. shading  -> 2\n",
      "6307. smart home ai  -> 2\n",
      "6308. diverse preference optimization  -> 2\n",
      "6309. dlss frame generation  -> 2\n",
      "6310. dockerfile  -> 2\n",
      "6311. document data extraction  -> 2\n",
      "6312. document enrichment  -> 2\n",
      "6313. document image processing  -> 2\n",
      "6314. document ranking  -> 2\n",
      "6315. simulation training  -> 2\n",
      "6316. simulation-based training  -> 2\n",
      "6317. single-cell rna sequencing  -> 2\n",
      "6318. slack integration  -> 2\n",
      "6319. sleep staging  -> 2\n",
      "6320. slm (small language models)  -> 2\n",
      "6321. smart contract development  -> 2\n",
      "6322. smart home  -> 2\n",
      "6323. domain-specific fine-tuning  -> 2\n",
      "6324. domain-specific languages (dsls)  -> 2\n",
      "6325. domain-specific models  -> 2\n",
      "6326. donut  -> 2\n",
      "6327. dot product  -> 2\n",
      "6328. doubly robust  -> 2\n",
      "6329. dp-sgd  -> 2\n",
      "6330. simulated annealing  -> 2\n",
      "6331. dynamic graph learning  -> 2\n",
      "6332. document reranking  -> 2\n",
      "6333. document screening  -> 2\n",
      "6334. document similarity  -> 2\n",
      "6335. document vqa  -> 2\n",
      "6336. dom manipulation  -> 2\n",
      "6337. domain generalization  -> 2\n",
      "6338. domain knowledge integration  -> 2\n",
      "6339. diffusion training  -> 2\n",
      "6340. digital avatar creation  -> 2\n",
      "6341. digital human rendering  -> 2\n",
      "6342. digital humans  -> 2\n",
      "6343. digital rights management (drm)  -> 2\n",
      "6344. digital twin simulation  -> 2\n",
      "6345. direct advantage policy optimization (dapo)  -> 2\n",
      "6346. devicemesh  -> 2\n",
      "6347. social robotics  -> 2\n",
      "6348. soft prompting  -> 2\n",
      "6349. soft robotics  -> 2\n",
      "6350. software bill of materials (sbom)  -> 2\n",
      "6351. software design  -> 2\n",
      "6352. software engineering ai  -> 2\n",
      "6353. software engineering with llms  -> 2\n",
      "6354. diffusion samplers  -> 2\n",
      "6355. smart navigation  -> 2\n",
      "6356. smithy  -> 2\n",
      "6357. smooth l1 loss  -> 2\n",
      "6358. snomed ct  -> 2\n",
      "6359. soap  -> 2\n",
      "6360. soap optimizer  -> 2\n",
      "6361. soc integration  -> 2\n",
      "6362. social engineering  -> 2\n",
      "6363. disaggregated serving  -> 2\n",
      "6364. discord bot development  -> 2\n",
      "6365. disinformation analysis  -> 2\n",
      "6366. distance metrics  -> 2\n",
      "6367. distributed gpu training  -> 2\n",
      "6368. distributed ledger technology  -> 2\n",
      "6369. distributed ml  -> 2\n",
      "6370. distributed optimization  -> 2\n",
      "6371. sound generation  -> 2\n",
      "6372. sovereign cloud  -> 2\n",
      "6373. spam filtering  -> 2\n",
      "6374. sparse neural networks  -> 2\n",
      "6375. deep think  -> 2\n",
      "6376. deepagents  -> 2\n",
      "6377. deepgemm  -> 2\n",
      "6378. deeplearning4j  -> 2\n",
      "6379. design optimization  -> 2\n",
      "6380. design research  -> 2\n",
      "6381. design-to-code  -> 2\n",
      "6382. determination  -> 2\n",
      "6383. solution architecture  -> 2\n",
      "6384. somatic variant calling  -> 2\n",
      "6385. sound classification  -> 2\n",
      "6386. sound field control  -> 2\n",
      "6387. dense captioning  -> 2\n",
      "6388. deploy  -> 2\n",
      "6389. deploy agents  -> 2\n",
      "6390. deploy_and_evaluate_model  -> 2\n",
      "6391. deployment and scaling  -> 2\n",
      "6392. deployment pipelines  -> 2\n",
      "6393. deployment strategies  -> 2\n",
      "6394. dequantization  -> 2\n",
      "6395. dialog systems  -> 2\n",
      "6396. dialogflow cx  -> 2\n",
      "6397. dictionary learning  -> 2\n",
      "6398. die-to-die interconnect  -> 2\n",
      "6399. diffusion model sampling  -> 2\n",
      "6400. diffusion model training  -> 2\n",
      "6401. denoising diffusion  -> 2\n",
      "6402. denoising objectives  -> 2\n",
      "6403. spectral clustering  -> 2\n",
      "6404. spectral methods  -> 2\n",
      "6405. spectroscopy data analysis  -> 2\n",
      "6406. dataset packing  -> 2\n",
      "6407. dataset_artifact  -> 2\n",
      "6408. dataset_stage  -> 2\n",
      "6409. dbos  -> 2\n",
      "6410. dc power systems  -> 2\n",
      "6411. deep learning infrastructure  -> 2\n",
      "6412. deep learning systems  -> 2\n",
      "6413. deep learning theory  -> 2\n",
      "6414. spatial ai  -> 2\n",
      "6415. spatial analysis  -> 2\n",
      "6416. spatial-temporal planning  -> 2\n",
      "6417. spearman correlation  -> 2\n",
      "6418. species identification  -> 2\n",
      "6419. decision thresholds  -> 2\n",
      "6420. decision transformer  -> 2\n",
      "6421. decision-making  -> 2\n",
      "6422. decoder-only architecture  -> 2\n",
      "6423. decoding algorithms  -> 2\n",
      "6424. decoding optimization  -> 2\n",
      "6425. decoding strategies (temperature  -> 2\n",
      "6426. deep learning compilers  -> 2\n",
      "6427. deepseek sparse attention  -> 2\n",
      "6428. deepsort  -> 2\n",
      "6429. deepspeed zero-3  -> 2\n",
      "6430. deepvariant  -> 2\n",
      "6431. defense ai  -> 2\n",
      "6432. deformable protopnet  -> 2\n",
      "6433. delta live tables  -> 2\n",
      "6434. decision theory  -> 2\n",
      "6435. speech separation  -> 2\n",
      "6436. speech synthesis (text-to-speech)  -> 2\n",
      "6437. speech tokenization  -> 2\n",
      "6438. speech-to-text (whisper)  -> 2\n",
      "6439. data quality validation  -> 2\n",
      "6440. data refactoring  -> 2\n",
      "6441. data residency compliance  -> 2\n",
      "6442. data scaling  -> 2\n",
      "6443. dataset documentation  -> 2\n",
      "6444. speech analytics  -> 2\n",
      "6445. speech apis  -> 2\n",
      "6446. speech continuation  -> 2\n",
      "6447. speech emotion recognition  -> 2\n",
      "6448. speech intelligence  -> 2\n",
      "6449. speech interfaces  -> 2\n",
      "6450. speech recognition (stt)  -> 2\n",
      "6451. data warehouse  -> 2\n",
      "6452. data-driven optimization  -> 2\n",
      "6453. database indexing  -> 2\n",
      "6454. databricks workflows  -> 2\n",
      "6455. dataparallel  -> 2\n",
      "6456. dataset balancing  -> 2\n",
      "6457. dataset contamination detection  -> 2\n",
      "6458. dataset deduplication  -> 2\n",
      "6459. ddpm  -> 2\n",
      "6460. deblurring  -> 2\n",
      "6461. debugging (ai models)  -> 2\n",
      "6462. debugging ai models  -> 2\n",
      "6463. debugging tools  -> 2\n",
      "6464. decentralized pretraining  -> 2\n",
      "6465. decentralized reinforcement learning  -> 2\n",
      "6466. deception technologies  -> 2\n",
      "6467. data packing  -> 2\n",
      "6468. data pipeline architecture  -> 2\n",
      "6469. data platform  -> 2\n",
      "6470. data poisoning defense  -> 2\n",
      "6471. data portability  -> 2\n",
      "6472. data preprocessing for llms  -> 2\n",
      "6473. data protection  -> 2\n",
      "6474. data quality monitoring  -> 2\n",
      "6475. ssim  -> 2\n",
      "6476. ssm (state space models)  -> 2\n",
      "6477. ssm architecture  -> 2\n",
      "6478. ssm models  -> 2\n",
      "6479. stability ai  -> 2\n",
      "6480. stability ai image services  -> 2\n",
      "6481. stable audio  -> 2\n",
      "6482. data monitoring  -> 2\n",
      "6483. spinalhdl  -> 2\n",
      "6484. spot instances  -> 2\n",
      "6485. spreadsheet generation  -> 2\n",
      "6486. spring  -> 2\n",
      "6487. spring boot  -> 2\n",
      "6488. sql integration  -> 2\n",
      "6489. sql optimization  -> 2\n",
      "6490. sse (server-sent events)  -> 2\n",
      "6491. data sourcing  -> 2\n",
      "6492. data splitting  -> 2\n",
      "6493. data stewardship  -> 2\n",
      "6494. data structures  -> 2\n",
      "6495. data summarization  -> 2\n",
      "6496. data unification  -> 2\n",
      "6497. data verification  -> 2\n",
      "6498. speech-to-text translation  -> 2\n",
      "6499. state estimation  -> 2\n",
      "6500. state graph  -> 2\n",
      "6501. state-space search  -> 2\n",
      "6502. dalle 3  -> 2\n",
      "6503. dark pattern detection  -> 2\n",
      "6504. darts  -> 2\n",
      "6505. dast  -> 2\n",
      "6506. data aggregation  -> 2\n",
      "6507. stackai  -> 2\n",
      "6508. standard scaling  -> 2\n",
      "6509. standards compliance  -> 2\n",
      "6510. stanley method  -> 2\n",
      "6511. star-attention  -> 2\n",
      "6512. starcoder  -> 2\n",
      "6513. starlette  -> 2\n",
      "6514. state  -> 2\n",
      "6515. data drift monitoring  -> 2\n",
      "6516. data efficiency  -> 2\n",
      "6517. data engineering for ai  -> 2\n",
      "6518. data exfiltration  -> 2\n",
      "6519. data fusion  -> 2\n",
      "6520. stable diffusion 3  -> 2\n",
      "6521. stable diffusion fine-tuning  -> 2\n",
      "6522. stablecoins  -> 2\n",
      "6523. data interpretation  -> 2\n",
      "6524. data leakage detection  -> 2\n",
      "6525. data lifecycle management  -> 2\n",
      "6526. data loaders  -> 2\n",
      "6527. data management (ai)  -> 2\n",
      "6528. data manipulation  -> 2\n",
      "6529. data crawling  -> 2\n",
      "6530. data curation (ai)  -> 2\n",
      "6531. steering vectors  -> 2\n",
      "6532. steganography detection  -> 2\n",
      "6533. stochastic control  -> 2\n",
      "6534. stochastic modeling  -> 2\n",
      "6535. stop sequences  -> 2\n",
      "6536. cross-platform deployment  -> 2\n",
      "6537. cryptographic proofs  -> 2\n",
      "6538. css  -> 2\n",
      "6539. cypher query language  -> 2\n",
      "6540. cypress  -> 2\n",
      "6541. static embeddings  -> 2\n",
      "6542. static rubrics  -> 2\n",
      "6543. statistical inference  -> 2\n",
      "6544. statistical learning  -> 2\n",
      "6545. stax  -> 2\n",
      "6546. steering behaviors  -> 2\n",
      "6547. customer analytics  -> 2\n",
      "6548. customer churn prediction  -> 2\n",
      "6549. customer service ai  -> 2\n",
      "6550. customer support ai  -> 2\n",
      "6551. cute dsl  -> 2\n",
      "6552. cyber security  -> 2\n",
      "6553. cyber threat intelligence  -> 2\n",
      "6554. cyberbattlesim  -> 2\n",
      "6555. data assimilation  -> 2\n",
      "6556. data auditing  -> 2\n",
      "6557. data blending  -> 2\n",
      "6558. data center  -> 2\n",
      "6559. data center design  -> 2\n",
      "6560. data center systems  -> 2\n",
      "6561. custom loss functions  -> 2\n",
      "6562. custom model training  -> 2\n",
      "6563. credential rotation  -> 2\n",
      "6564. credit assignment  -> 2\n",
      "6565. credit risk modeling  -> 2\n",
      "6566. critic pretraining  -> 2\n",
      "6567. cross-chat memory  -> 2\n",
      "6568. cross-modal fusion  -> 2\n",
      "6569. cross-platform compatibility  -> 2\n",
      "6570. copilot chat  -> 2\n",
      "6571. structured data output  -> 2\n",
      "6572. structured decoding  -> 2\n",
      "6573. structured exploration  -> 2\n",
      "6574. cpu-based inference  -> 2\n",
      "6575. cpu/gpu hybrid inference  -> 2\n",
      "6576. crawlee  -> 2\n",
      "6577. creative experimentation  -> 2\n",
      "6578. creative writing  -> 2\n",
      "6579. custom ai development  -> 2\n",
      "6580. custom chip design  -> 2\n",
      "6581. strategic inference  -> 2\n",
      "6582. strategy  -> 2\n",
      "6583. streaming analytics  -> 2\n",
      "6584. streaming seq2seq  -> 2\n",
      "6585. structure-aware drug potency prediction  -> 2\n",
      "6586. structure-aware interpolation  -> 2\n",
      "6587. csv  -> 2\n",
      "6588. ctes  -> 2\n",
      "6589. cuda debugging  -> 2\n",
      "6590. cuda profiling  -> 2\n",
      "6591. curiosity  -> 2\n",
      "6592. curriculum reinforcement learning  -> 2\n",
      "6593. custom accelerators  -> 2\n",
      "6594. custom agent development  -> 2\n",
      "6595. super resolution  -> 2\n",
      "6596. supply chain ai  -> 2\n",
      "6597. control theory (ai)  -> 2\n",
      "6598. control tokens  -> 2\n",
      "6599. controllable text generation  -> 2\n",
      "6600. controlled text generation  -> 2\n",
      "6601. conversation ai  -> 2\n",
      "6602. conversation branching  -> 2\n",
      "6603. style embeddings  -> 2\n",
      "6604. style guide  -> 2\n",
      "6605. sub-agent architecture  -> 2\n",
      "6606. subgraph extraction  -> 2\n",
      "6607. subtitling  -> 2\n",
      "6608. subword tokenization  -> 2\n",
      "6609. suno  -> 2\n",
      "6610. supabase  -> 2\n",
      "6611. cost optimization for llms  -> 2\n",
      "6612. count-based exploration  -> 2\n",
      "6613. countvectorizer  -> 2\n",
      "6614. cpu architecture  -> 2\n",
      "6615. structured output (ai)  -> 2\n",
      "6616. structured output (llms)  -> 2\n",
      "6617. structured output prompting  -> 2\n",
      "6618. style control  -> 2\n",
      "6619. copyright  -> 2\n",
      "6620. corrective rag  -> 2\n",
      "6621. correlation analysis  -> 2\n",
      "6622. corrigibility  -> 2\n",
      "6623. cost allocation tagging  -> 2\n",
      "6624. cost functions  -> 2\n",
      "6625. cost management for ai  -> 2\n",
      "6626. cost monitoring  -> 2\n",
      "6627. continuous diffusion  -> 2\n",
      "6628. continuous latent reasoning  -> 2\n",
      "6629. continuous monitoring  -> 2\n",
      "6630. continuous provisioning  -> 2\n",
      "6631. continuous-time models  -> 2\n",
      "6632. continuous-time neural networks  -> 2\n",
      "6633. contract analysis  -> 2\n",
      "6634. control algorithms  -> 2\n",
      "6635. symbolic computation  -> 2\n",
      "6636. symbolic solver  -> 2\n",
      "6637. synalinks  -> 2\n",
      "6638. synonym replacement  -> 2\n",
      "6639. synthetic benchmark generation  -> 2\n",
      "6640. contextual embeddings  -> 2\n",
      "6641. contextual memory  -> 2\n",
      "6642. contextual understanding (ai)  -> 2\n",
      "6643. supply chain management  -> 2\n",
      "6644. surveillance ai  -> 2\n",
      "6645. surveillance analytics  -> 2\n",
      "6646. sustainable computing  -> 2\n",
      "6647. sustainable ml  -> 2\n",
      "6648. svdquant  -> 2\n",
      "6649. svelte  -> 2\n",
      "6650. svg generation  -> 2\n",
      "6651. conversation summarization  -> 2\n",
      "6652. conversational ai (chatbots)  -> 2\n",
      "6653. conversational context management  -> 2\n",
      "6654. conversational design  -> 2\n",
      "6655. conversational editing  -> 2\n",
      "6656. conversational interface  -> 2\n",
      "6657. conversational state management  -> 2\n",
      "6658. conversational ui  -> 2\n",
      "6659. tabular data processing  -> 2\n",
      "6660. taichi  -> 2\n",
      "6661. tailwind  -> 2\n",
      "6662. talking-head generation  -> 2\n",
      "6663. concept bottleneck models  -> 2\n",
      "6664. concept bottlenecks  -> 2\n",
      "6665. concurrency  -> 2\n",
      "6666. concurrency control  -> 2\n",
      "6667. content validation  -> 2\n",
      "6668. content-based filtering  -> 2\n",
      "6669. context awareness  -> 2\n",
      "6670. system thinking  -> 2\n",
      "6671. systolic array  -> 2\n",
      "6672. systolic array architecture  -> 2\n",
      "6673. table understanding  -> 2\n",
      "6674. tablegpt  -> 2\n",
      "6675. containerization (ai/ml)  -> 2\n",
      "6676. containerization (docker)  -> 2\n",
      "6677. containers  -> 2\n",
      "6678. content aggregation  -> 2\n",
      "6679. content curation  -> 2\n",
      "6680. content extraction  -> 2\n",
      "6681. content fingerprinting  -> 2\n",
      "6682. content id  -> 2\n",
      "6683. control flow  -> 2\n",
      "6684. control nets  -> 2\n",
      "6685. context extension  -> 2\n",
      "6686. context refinement  -> 2\n",
      "6687. context sharing  -> 2\n",
      "6688. context understanding  -> 2\n",
      "6689. constrained generation  -> 2\n",
      "6690. container image  -> 2\n",
      "6691. computational protein design  -> 2\n",
      "6692. computational storage  -> 2\n",
      "6693. compute architecture optimization  -> 2\n",
      "6694. compute cost estimation  -> 2\n",
      "6695. compute engine  -> 2\n",
      "6696. compute infrastructure  -> 2\n",
      "6697. computer algebra systems  -> 2\n",
      "6698. computer control  -> 2\n",
      "6699. temporal alignment  -> 2\n",
      "6700. temporal retrieval  -> 2\n",
      "6701. compliance verification  -> 2\n",
      "6702. computation-based metrics  -> 2\n",
      "6703. computational efficiency (ai)  -> 2\n",
      "6704. computational geometry  -> 2\n",
      "6705. computational graphs  -> 2\n",
      "6706. computational linguistics  -> 2\n",
      "6707. targeted advertising  -> 2\n",
      "6708. task automation (ai)  -> 2\n",
      "6709. task planning (ai)  -> 2\n",
      "6710. task scheduling  -> 2\n",
      "6711. taxonomy design  -> 2\n",
      "6712. technical debt management  -> 2\n",
      "6713. technical writing  -> 2\n",
      "6714. temporal  -> 2\n",
      "6715. concurrent programming  -> 2\n",
      "6716. conditional gan  -> 2\n",
      "6717. confidence thresholds  -> 2\n",
      "6718. configuration  -> 2\n",
      "6719. conflict resolution  -> 2\n",
      "6720. conformer  -> 2\n",
      "6721. connector integration  -> 2\n",
      "6722. consistency checking  -> 2\n",
      "6723. codebase indexing  -> 2\n",
      "6724. codebase understanding  -> 2\n",
      "6725. codebook modeling  -> 2\n",
      "6726. codegemma  -> 2\n",
      "6727. codegen  -> 2\n",
      "6728. codex cli  -> 2\n",
      "6729. coding skills  -> 2\n",
      "6730. coding with llms  -> 2\n",
      "6731. tensor program optimization  -> 2\n",
      "6732. tensor splitting  -> 2\n",
      "6733. tensorcore optimization  -> 2\n",
      "6734. ternary computing  -> 2\n",
      "6735. ternary neural networks  -> 2\n",
      "6736. tesnet  -> 2\n",
      "6737. code synthesis  -> 2\n",
      "6738. code world model  -> 2\n",
      "6739. communication-efficient training  -> 2\n",
      "6740. complex problem solving  -> 2\n",
      "6741. tensor algebra  -> 2\n",
      "6742. tensor core optimization  -> 2\n",
      "6743. tensor decomposition  -> 2\n",
      "6744. tensor optimization  -> 2\n",
      "6745. tensor parallel computing  -> 2\n",
      "6746. tensor processing units  -> 2\n",
      "6747. color grading  -> 2\n",
      "6748. color optimization  -> 2\n",
      "6749. color science  -> 2\n",
      "6750. combat ai  -> 2\n",
      "6751. comet server  -> 2\n",
      "6752. comet subscription  -> 2\n",
      "6753. comet ui  -> 2\n",
      "6754. commonsense reasoning  -> 2\n",
      "6755. code explanation  -> 2\n",
      "6756. code generation (llms)  -> 2\n",
      "6757. code generation models  -> 2\n",
      "6758. code interpretation (ai)  -> 2\n",
      "6759. code interpreter integration  -> 2\n",
      "6760. code recognition  -> 2\n",
      "6761. code repair  -> 2\n",
      "6762. code security  -> 2\n",
      "6763. text clustering  -> 2\n",
      "6764. text deduplication  -> 2\n",
      "6765. text detection  -> 2\n",
      "6766. text diffusion models  -> 2\n",
      "6767. text editing  -> 2\n",
      "6768. code completion (ai)  -> 2\n",
      "6769. code debugging (ai)  -> 2\n",
      "6770. code execution (ai)  -> 2\n",
      "6771. testcontainers  -> 2\n",
      "6772. testing and qa  -> 2\n",
      "6773. testng  -> 2\n",
      "6774. text  -> 2\n",
      "6775. text analytics  -> 2\n",
      "6776. text and data mining  -> 2\n",
      "6777. text annotation  -> 2\n",
      "6778. text cleaning  -> 2\n",
      "6779. cohen's d  -> 2\n",
      "6780. cohere multilingual v3  -> 2\n",
      "6781. cohere toolkit  -> 2\n",
      "6782. test data generation  -> 2\n",
      "6783. test data management  -> 2\n",
      "6784. test-time compute  -> 2\n",
      "6785. test-time rl  -> 2\n",
      "6786. testability  -> 2\n",
      "6787. text encoder fine-tuning  -> 2\n",
      "6788. text parsing  -> 2\n",
      "6789. text style transfer  -> 2\n",
      "6790. text-generation-webui  -> 2\n",
      "6791. text-guided video editing  -> 2\n",
      "6792. ci/cd pipeline  -> 2\n",
      "6793. cifar-10  -> 2\n",
      "6794. circuit breakers  -> 2\n",
      "6795. cloud ai integration  -> 2\n",
      "6796. cloud ai services  -> 2\n",
      "6797. cloud cost management  -> 2\n",
      "6798. cloud deployment (ai)  -> 2\n",
      "6799. cloud gaming  -> 2\n",
      "6800. cloud gpu deployment  -> 2\n",
      "6801. cloud machine learning  -> 2\n",
      "6802. text embedding models  -> 2\n",
      "6803. cloudtrail  -> 2\n",
      "6804. cloudwatch logs  -> 2\n",
      "6805. cluster director  -> 2\n",
      "6806. cluster scaling  -> 2\n",
      "6807. co-design  -> 2\n",
      "6808. clinical machine learning  -> 2\n",
      "6809. cloud  -> 2\n",
      "6810. cloud ai development  -> 2\n",
      "6811. code signing  -> 2\n",
      "6812. cloud native  -> 2\n",
      "6813. cloud platforms  -> 2\n",
      "6814. cloud services  -> 2\n",
      "6815. cloud siem  -> 2\n",
      "6816. cloud tpus  -> 2\n",
      "6817. cloudflare agents  -> 2\n",
      "6818. cloudflare ai gateway  -> 2\n",
      "6819. thread management  -> 2\n",
      "6820. chatgpt enterprise  -> 2\n",
      "6821. chatprompttemplate  -> 2\n",
      "6822. checkpoint conversion  -> 2\n",
      "6823. chiplet architecture  -> 2\n",
      "6824. chiplet integration  -> 2\n",
      "6825. chrome extension  -> 2\n",
      "6826. chromium  -> 2\n",
      "6827. texture mapping  -> 2\n",
      "6828. texture synthesis  -> 2\n",
      "6829. tfp-sts  -> 2\n",
      "6830. tgi (text generation inference)  -> 2\n",
      "6831. theme extraction  -> 2\n",
      "6832. thermoask  -> 2\n",
      "6833. thompson sampling  -> 2\n",
      "6834. thought anchors  -> 2\n",
      "6835. claude sonnet 4  -> 2\n",
      "6836. cli agents  -> 2\n",
      "6837. cli integration  -> 2\n",
      "6838. clickhouse  -> 2\n",
      "6839. text-to-image synthesis  -> 2\n",
      "6840. text-to-video ai  -> 2\n",
      "6841. text-video-to-audio (tv2a)  -> 2\n",
      "6842. text2python  -> 2\n",
      "6843. circuit identification  -> 2\n",
      "6844. citation-grounded generation  -> 2\n",
      "6845. cityflow  -> 2\n",
      "6846. claim verification  -> 2\n",
      "6847. classifier development  -> 2\n",
      "6848. claude (anthropic)  -> 2\n",
      "6849. claude 3.7 sonnet  -> 2\n",
      "6850. claude llm  -> 2\n",
      "6851. time series  -> 2\n",
      "6852. time series foundation models  -> 2\n",
      "6853. time series prediction  -> 2\n",
      "6854. timestamping  -> 2\n",
      "6855. timestep embedding  -> 2\n",
      "6856. titan text embeddings  -> 2\n",
      "6857. bring your own key (byok)  -> 2\n",
      "6858. browser development  -> 2\n",
      "6859. canny edge detection  -> 2\n",
      "6860. carla  -> 2\n",
      "6861. carla simulator  -> 2\n",
      "6862. case-based reasoning  -> 2\n",
      "6863. catalyst design  -> 2\n",
      "6864. causal self-attention  -> 2\n",
      "6865. threat intelligence integration  -> 2\n",
      "6866. tiledmlp  -> 2\n",
      "6867. character animation  -> 2\n",
      "6868. character design  -> 2\n",
      "6869. character generation  -> 2\n",
      "6870. chart understanding  -> 2\n",
      "6871. chat history  -> 2\n",
      "6872. chat memory  -> 2\n",
      "6873. camera isp tuning  -> 2\n",
      "6874. candle  -> 2\n",
      "6875. ci/cd automation  -> 2\n",
      "6876. cdi  -> 2\n",
      "6877. celery  -> 2\n",
      "6878. cert-manager  -> 2\n",
      "6879. chain-of-code  -> 2\n",
      "6880. chain-of-thought (cot) monitoring  -> 2\n",
      "6881. chain-of-thought training  -> 2\n",
      "6882. chaos engineering  -> 2\n",
      "6883. token-level distillation  -> 2\n",
      "6884. token-level metrics  -> 2\n",
      "6885. token-level processing  -> 2\n",
      "6886. tokenization (nlp)  -> 2\n",
      "6887. tokenizer design  -> 2\n",
      "6888. bias measurement  -> 2\n",
      "6889. bias mitigation (ai)  -> 2\n",
      "6890. bidirectional rnns  -> 2\n",
      "6891. token counting  -> 2\n",
      "6892. token handling  -> 2\n",
      "6893. token routing  -> 2\n",
      "6894. token usage monitoring  -> 2\n",
      "6895. token-aware packing  -> 2\n",
      "6896. token-based generation  -> 2\n",
      "6897. token-based training  -> 2\n",
      "6898. token-efficient training  -> 2\n",
      "6899. blockchain integration  -> 2\n",
      "6900. bloom  -> 2\n",
      "6901. body scanning  -> 2\n",
      "6902. boosted trees  -> 2\n",
      "6903. bootstrapping  -> 2\n",
      "6904. bot management  -> 2\n",
      "6905. bounding box regression  -> 2\n",
      "6906. bpe (byte pair encoding)  -> 2\n",
      "6907. browser extension  -> 2\n",
      "6908. browser-based ml  -> 2\n",
      "6909. browserbase  -> 2\n",
      "6910. building simulation  -> 2\n",
      "6911. byte-level processing  -> 2\n",
      "6912. biotechnology  -> 2\n",
      "6913. block transformer  -> 2\n",
      "6914. block-wise quantization  -> 2\n",
      "6915. benchmarking (ai models)  -> 2\n",
      "6916. bert fine-tuning  -> 2\n",
      "6917. bf16 optimization  -> 2\n",
      "6918. bfclv3  -> 2\n",
      "6919. bfloat11  -> 2\n",
      "6920. bias  -> 2\n",
      "6921. bias and fairness  -> 2\n",
      "6922. bias and fairness evaluation  -> 2\n",
      "6923. tool-using llms  -> 2\n",
      "6924. toolchains  -> 2\n",
      "6925. top-k routing  -> 2\n",
      "6926. top-k sparsification  -> 2\n",
      "6927. behavioral monitoring  -> 2\n",
      "6928. behavioral testing  -> 2\n",
      "6929. beir  -> 2\n",
      "6930. benchmark development  -> 2\n",
      "6931. biometric verification  -> 2\n",
      "6932. tokenomics  -> 2\n",
      "6933. tool development  -> 2\n",
      "6934. tool integration for agents  -> 2\n",
      "6935. tool selection  -> 2\n",
      "6936. tool use (for llms)  -> 2\n",
      "6937. tool-enabled agents  -> 2\n",
      "6938. tool-use rl  -> 2\n",
      "6939. bilinear interpolation  -> 2\n",
      "6940. binary authorization  -> 2\n",
      "6941. binary cross-entropy loss  -> 2\n",
      "6942. bio ai  -> 2\n",
      "6943. bioacoustics  -> 2\n",
      "6944. biomechanical analysis  -> 2\n",
      "6945. biomedical ml  -> 2\n",
      "6946. biometric analysis  -> 2\n",
      "6947. traffic management  -> 2\n",
      "6948. traffic simulation  -> 2\n",
      "6949. aws systems manager parameter store  -> 2\n",
      "6950. aws vpc  -> 2\n",
      "6951. azure ad  -> 2\n",
      "6952. azure cognitive services  -> 2\n",
      "6953. azure functions  -> 2\n",
      "6954. azure logic apps  -> 2\n",
      "6955. torch inductor  -> 2\n",
      "6956. torchchat  -> 2\n",
      "6957. torchcompile  -> 2\n",
      "6958. torchtitan  -> 2\n",
      "6959. toxicity filters  -> 2\n",
      "6960. tpe (tree-structured parzen estimator)  -> 2\n",
      "6961. tpu development  -> 2\n",
      "6962. trace analysis  -> 2\n",
      "6963. bayesian statistics  -> 2\n",
      "6964. bedrock agentcore cli  -> 2\n",
      "6965. behavior analytics  -> 2\n",
      "6966. behavior detection  -> 2\n",
      "6967. behavioral analysis  -> 2\n",
      "6968. behavioral biometrics  -> 2\n",
      "6969. top-p)  -> 2\n",
      "6970. topic classification  -> 2\n",
      "6971. bias audits  -> 2\n",
      "6972. bias awareness  -> 2\n",
      "6973. bias detection/mitigation  -> 2\n",
      "6974. batch processing (ai)  -> 2\n",
      "6975. batch size  -> 2\n",
      "6976. batch tokenization  -> 2\n",
      "6977. batch transform  -> 2\n",
      "6978. bayesian logistic regression  -> 2\n",
      "6979. autoregressive language modeling  -> 2\n",
      "6980. autoregressive u-net  -> 2\n",
      "6981. autoregressive video generation  -> 2\n",
      "6982. avatar creation  -> 2\n",
      "6983. average precision (ap)  -> 2\n",
      "6984. avx2 optimization  -> 2\n",
      "6985. aws api gateway  -> 2\n",
      "6986. aws bedrock agents  -> 2\n",
      "6987. training datasets  -> 2\n",
      "6988. training infrastructure  -> 2\n",
      "6989. training loop development  -> 2\n",
      "6990. trainium  -> 2\n",
      "6991. trajectory analysis  -> 2\n",
      "6992. trajectory attention  -> 2\n",
      "6993. transformer decoders  -> 2\n",
      "6994. autoregressive image generation  -> 2\n",
      "6995. aws marketplace  -> 2\n",
      "6996. aws sqs  -> 2\n",
      "6997. aws systems manager  -> 2\n",
      "6998. train/validation/test split  -> 2\n",
      "6999. training algorithms  -> 2\n",
      "7000. training cost optimization  -> 2\n",
      "7001. training data analysis  -> 2\n",
      "7002. training data generation  -> 2\n",
      "7003. back-translation  -> 2\n",
      "7004. bash scripting  -> 2\n",
      "7005. batch insertion  -> 2\n",
      "7006. aws deep learning ami  -> 2\n",
      "7007. aws eventbridge  -> 2\n",
      "7008. aws graviton  -> 2\n",
      "7009. aws knowledge mcp server  -> 2\n",
      "7010. aws management console  -> 2\n",
      "7011. automated code verification  -> 2\n",
      "7012. automated metrics  -> 2\n",
      "7013. automated model evaluation  -> 2\n",
      "7014. automated moderation  -> 2\n",
      "7015. automated moderation systems  -> 2\n",
      "7016. automated note-taking  -> 2\n",
      "7017. automated pipelines  -> 2\n",
      "7018. automated red teaming  -> 2\n",
      "7019. transformers (hugging face)  -> 2\n",
      "7020. transformers pipeline  -> 2\n",
      "7021. transport layer security  -> 2\n",
      "7022. tree search algorithms  -> 2\n",
      "7023. tree sitter  -> 2\n",
      "7024. trino  -> 2\n",
      "7025. triton (ai)  -> 2\n",
      "7026. automated auditing  -> 2\n",
      "7027. autonomous coding agents  -> 2\n",
      "7028. autonomous decision-making  -> 2\n",
      "7029. autonomous vehicle simulation  -> 2\n",
      "7030. autonomous weapons  -> 2\n",
      "7031. autopilot  -> 2\n",
      "7032. autoprocessor  -> 2\n",
      "7033. autoregression  -> 2\n",
      "7034. transformer interpretability  -> 2\n",
      "7035. aws certificate manager  -> 2\n",
      "7036. aws cost explorer  -> 2\n",
      "7037. aws credential management  -> 2\n",
      "7038. automated remediation  -> 2\n",
      "7039. automatic cot  -> 2\n",
      "7040. automatic music transcription  -> 2\n",
      "7041. automatic rollback  -> 2\n",
      "7042. automotive ai  -> 2\n",
      "7043. audio captioning  -> 2\n",
      "7044. audio codec  -> 2\n",
      "7045. audio forensics  -> 2\n",
      "7046. audio language models  -> 2\n",
      "7047. audio quality assessment  -> 2\n",
      "7048. audio segmentation  -> 2\n",
      "7049. audio source separation  -> 2\n",
      "7050. ascend  -> 2\n",
      "7051. twilio  -> 2\n",
      "7052. type-aware decoding  -> 2\n",
      "7053. type-safe programming  -> 2\n",
      "7054. typed tool schemas  -> 2\n",
      "7055. u-net architecture  -> 2\n",
      "7056. ucie  -> 2\n",
      "7057. ui/ux design (ai)  -> 2\n",
      "7058. attribution modeling  -> 2\n",
      "7059. auto scaling  -> 2\n",
      "7060. auto-cot  -> 2\n",
      "7061. autocompletion  -> 2\n",
      "7062. autodiff  -> 2\n",
      "7063. trusted execution environments (sgx)  -> 2\n",
      "7064. trusted execution environments (tees)  -> 2\n",
      "7065. truthfulqa  -> 2\n",
      "7066. tsmc 3nm  -> 2\n",
      "7067. audio-to-audio generation  -> 2\n",
      "7068. audio-to-text  -> 2\n",
      "7069. audio-visual synthesis  -> 2\n",
      "7070. audio/music generation  -> 2\n",
      "7071. audio/video processing  -> 2\n",
      "7072. aurc  -> 2\n",
      "7073. authentication & authorization  -> 2\n",
      "7074. authentication and authorization  -> 2\n",
      "7075. usb  -> 2\n",
      "7076. application development  -> 2\n",
      "7077. application development (ai)  -> 2\n",
      "7078. application insights  -> 2\n",
      "7079. applied machine learning  -> 2\n",
      "7080. applied mathematics  -> 2\n",
      "7081. approximate nearest neighbor (ann) search  -> 2\n",
      "7082. architecture optimization  -> 2\n",
      "7083. uncertainty sampling  -> 2\n",
      "7084. unifiedbus  -> 2\n",
      "7085. unreal engine 4  -> 2\n",
      "7086. unreal engine 5  -> 2\n",
      "7087. unsloth ai  -> 2\n",
      "7088. unstructured data analysis  -> 2\n",
      "7089. unstructured text processing  -> 2\n",
      "7090. usage analytics  -> 2\n",
      "7091. atrial fibrillation detection  -> 2\n",
      "7092. attention analysis  -> 2\n",
      "7093. attention kernel optimization  -> 2\n",
      "7094. attention kernels  -> 2\n",
      "7095. attention mechanism optimization  -> 2\n",
      "7096. attention mechanisms (ai)  -> 2\n",
      "7097. ui/ux design for ai  -> 2\n",
      "7098. uipath  -> 2\n",
      "7099. asic  -> 2\n",
      "7100. asic development  -> 2\n",
      "7101. assistants api  -> 2\n",
      "7102. assistive ai  -> 2\n",
      "7103. associative memory  -> 2\n",
      "7104. asynchronous agents  -> 2\n",
      "7105. asynchronous ai agents  -> 2\n",
      "7106. asynchronous batch processing  -> 2\n",
      "7107. validation  -> 2\n",
      "7108. validation & verification  -> 2\n",
      "7109. variant calling  -> 2\n",
      "7110. vasa-1  -> 2\n",
      "7111. vast.ai  -> 2\n",
      "7112. vector api  -> 2\n",
      "7113. amazon rekognition  -> 2\n",
      "7114. amazon rekognition custom labels  -> 2\n",
      "7115. anthropomorphism  -> 2\n",
      "7116. anycast network  -> 2\n",
      "7117. user analytics  -> 2\n",
      "7118. user prompts  -> 2\n",
      "7119. user studies  -> 2\n",
      "7120. uwp  -> 2\n",
      "7121. ux research  -> 2\n",
      "7122. vace  -> 2\n",
      "7123. appearance editing  -> 2\n",
      "7124. appium  -> 2\n",
      "7125. apple accelerate  -> 2\n",
      "7126. apple mps  -> 2\n",
      "7127. android env  -> 2\n",
      "7128. android ml  -> 2\n",
      "7129. angleslim  -> 2\n",
      "7130. annotation  -> 2\n",
      "7131. ari (asterisk rest interface)  -> 2\n",
      "7132. artifact registry  -> 2\n",
      "7133. api discovery  -> 2\n",
      "7134. api key authentication  -> 2\n",
      "7135. api key management  -> 2\n",
      "7136. api optimization  -> 2\n",
      "7137. apm  -> 2\n",
      "7138. app development  -> 2\n",
      "7139. velora  -> 2\n",
      "7140. verifiable inference  -> 2\n",
      "7141. verifier training  -> 2\n",
      "7142. vertex ai agent builder  -> 2\n",
      "7143. alexa integration  -> 2\n",
      "7144. alexa skills  -> 2\n",
      "7145. alexa voice service (avs)  -> 2\n",
      "7146. algorithm complexity analysis  -> 2\n",
      "7147. amazon comprehend medical  -> 2\n",
      "7148. amazon documentdb  -> 2\n",
      "7149. amazon ebs  -> 2\n",
      "7150. vector db  -> 2\n",
      "7151. vector graphics generation  -> 2\n",
      "7152. vectorrag  -> 2\n",
      "7153. vehicle dynamics  -> 2\n",
      "7154. vehicle-to-infrastructure communication  -> 2\n",
      "7155. amazon nova act  -> 2\n",
      "7156. amazon quick suite  -> 2\n",
      "7157. alignment techniques  -> 2\n",
      "7158. all-minilm-l6-v2  -> 2\n",
      "7159. amazon appflow  -> 2\n",
      "7160. amazon bedrock agentcore observability  -> 2\n",
      "7161. amazon bedrock custom model import  -> 2\n",
      "7162. amazon bedrock evaluations  -> 2\n",
      "7163. amazon sagemaker studio  -> 2\n",
      "7164. ambient computing  -> 2\n",
      "7165. amd fsr  -> 2\n",
      "7166. amd gpu support  -> 2\n",
      "7167. amd mi300  -> 2\n",
      "7168. amplify_350m  -> 2\n",
      "7169. amplitude  -> 2\n",
      "7170. amazon neptune ml  -> 2\n",
      "7171. ai-generated summaries  -> 2\n",
      "7172. ai-gradio  -> 2\n",
      "7173. ai-powered  -> 2\n",
      "7174. ai-powered cameras  -> 2\n",
      "7175. ai-powered detection  -> 2\n",
      "7176. ai-powered fitness coach  -> 2\n",
      "7177. ai-powered games  -> 2\n",
      "7178. ai-powered recommendations  -> 2\n",
      "7179. video embeddings  -> 2\n",
      "7180. video event detection  -> 2\n",
      "7181. video fine-tuning  -> 2\n",
      "7182. video forensics  -> 2\n",
      "7183. ai-generated avatar  -> 2\n",
      "7184. ai-generated code  -> 2\n",
      "7185. ai-generated image detection  -> 2\n",
      "7186. ai-generated papers  -> 2\n",
      "7187. alignment research  -> 2\n",
      "7188. vertex ai studio  -> 2\n",
      "7189. vgg-16  -> 2\n",
      "7190. vgg-19  -> 2\n",
      "7191. via  -> 2\n",
      "7192. video animation  -> 2\n",
      "7193. video comprehension  -> 2\n",
      "7194. video editing (ai)  -> 2\n",
      "7195. algorithm discovery  -> 2\n",
      "7196. algorithmic bias detection  -> 2\n",
      "7197. algorithmic decision-making  -> 2\n",
      "7198. algorithmic innovation  -> 2\n",
      "7199. alibaba  -> 2\n",
      "7200. alibaba cloud  -> 2\n",
      "7201. alibaba qwen  -> 2\n",
      "7202. alignment auditing  -> 2\n",
      "7203. video-to-video (vid2vid)  -> 2\n",
      "7204. videorag  -> 2\n",
      "7205. ai super resolution  -> 2\n",
      "7206. ai supercomputing  -> 2\n",
      "7207. ai system development  -> 2\n",
      "7208. ai system evaluation  -> 2\n",
      "7209. ai system reliability  -> 2\n",
      "7210. ai technology  -> 2\n",
      "7211. ai-driven analysis  -> 2\n",
      "7212. video processing (ai)  -> 2\n",
      "7213. video restoration  -> 2\n",
      "7214. video simulation  -> 2\n",
      "7215. video streaming  -> 2\n",
      "7216. video tokenization  -> 2\n",
      "7217. video transcription  -> 2\n",
      "7218. video-to-sound  -> 2\n",
      "7219. ai workflow orchestration  -> 2\n",
      "7220. ai writing  -> 2\n",
      "7221. ai-accelerated drug discovery  -> 2\n",
      "7222. ai-assisted editing  -> 2\n",
      "7223. ai-assisted secure coding  -> 2\n",
      "7224. ai-assisted software development  -> 2\n",
      "7225. ai-assisted workflows  -> 2\n",
      "7226. ai-assisted writing  -> 2\n",
      "7227. ai-powered video enhancement  -> 2\n",
      "7228. ai-powered voice assistant  -> 2\n",
      "7229. ai.forecast  -> 2\n",
      "7230. aihwkit-lightning  -> 2\n",
      "7231. albumentations  -> 2\n",
      "7232. ai video creation  -> 2\n",
      "7233. ai voice synthesis  -> 2\n",
      "7234. ai vulnerability research  -> 2\n",
      "7235. virtual environment  -> 2\n",
      "7236. virtual human  -> 2\n",
      "7237. virtual production  -> 2\n",
      "7238. vision api  -> 2\n",
      "7239. vision understanding  -> 2\n",
      "7240. vision-to-code  -> 2\n",
      "7241. ai model security  -> 2\n",
      "7242. ai object detection  -> 2\n",
      "7243. ai policy and regulation  -> 2\n",
      "7244. ai programming languages  -> 2\n",
      "7245. ai projects  -> 2\n",
      "7246. ai protocol design  -> 2\n",
      "7247. ai resilience  -> 2\n",
      "7248. ai robotics  -> 2\n",
      "7249. viewpoint conditioning  -> 2\n",
      "7250. virtual avatar creation  -> 2\n",
      "7251. ai sensors  -> 2\n",
      "7252. ai server engineer  -> 2\n",
      "7253. ai services  -> 2\n",
      "7254. ai skills  -> 2\n",
      "7255. ai solutions  -> 2\n",
      "7256. ai sound boost  -> 2\n",
      "7257. ai sre  -> 2\n",
      "7258. ai policy and compliance  -> 2\n",
      "7259. ai tool use  -> 2\n",
      "7260. ai training optimization  -> 2\n",
      "7261. ai ui/ux design  -> 2\n",
      "7262. ai safety engineering  -> 2\n",
      "7263. ai safety via debate  -> 2\n",
      "7264. ai search engine  -> 2\n",
      "7265. ai search tool  -> 2\n",
      "7266. ai self-correction  -> 2\n",
      "7267. visual slam  -> 2\n",
      "7268. visual tokenizers  -> 2\n",
      "7269. visual tracking  -> 2\n",
      "7270. visualization-of-thought prompting  -> 2\n",
      "7271. vite  -> 2\n",
      "7272. vla (vision-language-action)  -> 2\n",
      "7273. ai for sustainability  -> 2\n",
      "7274. ai game development  -> 2\n",
      "7275. visual context understanding  -> 2\n",
      "7276. visual document retrieval  -> 2\n",
      "7277. visual document understanding  -> 2\n",
      "7278. visual embeddings  -> 2\n",
      "7279. visual intelligence  -> 2\n",
      "7280. visual language models (vllms)  -> 2\n",
      "7281. visual regression testing  -> 2\n",
      "7282. visual semantic parsing  -> 2\n",
      "7283. ai interpreters  -> 2\n",
      "7284. ai leadership  -> 2\n",
      "7285. ai legal compliance  -> 2\n",
      "7286. ai likeness  -> 2\n",
      "7287. ai microservices  -> 2\n",
      "7288. ai mode  -> 2\n",
      "7289. ai model architecture  -> 2\n",
      "7290. visual ai  -> 2\n",
      "7291. ai object mask  -> 2\n",
      "7292. ai obstacle detection  -> 2\n",
      "7293. ai operating systems  -> 2\n",
      "7294. ai os  -> 2\n",
      "7295. ai output evaluation  -> 2\n",
      "7296. ai perception  -> 2\n",
      "7297. ai in software engineering  -> 2\n",
      "7298. ai interface design  -> 2\n",
      "7299. ai enhancement  -> 2\n",
      "7300. ai ethics and governance  -> 2\n",
      "7301. ai explainability  -> 2\n",
      "7302. ai factory  -> 2\n",
      "7303. ai for code analysis  -> 2\n",
      "7304. ai for marketing  -> 2\n",
      "7305. ai for mathematics  -> 2\n",
      "7306. ai code completion  -> 2\n",
      "7307. voice models  -> 2\n",
      "7308. voice style transfer  -> 2\n",
      "7309. ai development frameworks  -> 2\n",
      "7310. ai development platforms  -> 2\n",
      "7311. ai diagnostics  -> 2\n",
      "7312. ai dubbing  -> 2\n",
      "7313. ai economics  -> 2\n",
      "7314. ai energy efficiency  -> 2\n",
      "7315. ai in game development  -> 2\n",
      "7316. vocabulary pruning  -> 2\n",
      "7317. voice biometrics  -> 2\n",
      "7318. voice command  -> 2\n",
      "7319. voice integration  -> 2\n",
      "7320. voice interaction  -> 2\n",
      "7321. voice interface design  -> 2\n",
      "7322. voice isolation  -> 2\n",
      "7323. ai hallucination mitigation  -> 2\n",
      "7324. ai hardware engineering  -> 2\n",
      "7325. ai health assistant  -> 2\n",
      "7326. ai host  -> 2\n",
      "7327. ai hypercomputer  -> 2\n",
      "7328. ai in coding  -> 2\n",
      "7329. ai in creative arts  -> 2\n",
      "7330. ai in cybersecurity  -> 2\n",
      "7331. waveform analysis  -> 2\n",
      "7332. agentic retrieval  -> 2\n",
      "7333. agentic web  -> 2\n",
      "7334. agglomerative clustering  -> 2\n",
      "7335. agno  -> 2\n",
      "7336. agones  -> 2\n",
      "7337. ai accelerator hardware  -> 2\n",
      "7338. ai agent design  -> 2\n",
      "7339. ai camera  -> 2\n",
      "7340. ai chatbot development  -> 2\n",
      "7341. volcano  -> 2\n",
      "7342. vqa (visual question answering)  -> 2\n",
      "7343. vs code development  -> 2\n",
      "7344. vslam  -> 2\n",
      "7345. wafer-scale hardware  -> 2\n",
      "7346. watsonx.ai  -> 2\n",
      "7347. ai data center architecture  -> 2\n",
      "7348. ai data centers  -> 2\n",
      "7349. ai data management  -> 2\n",
      "7350. ai database  -> 2\n",
      "7351. ai audio generation  -> 2\n",
      "7352. ai augmentation  -> 2\n",
      "7353. ai autonomy  -> 2\n",
      "7354. ai benefits  -> 2\n",
      "7355. ai companies  -> 2\n",
      "7356. ai companionship  -> 2\n",
      "7357. ai compiler optimization  -> 2\n",
      "7358. ai compute  -> 2\n",
      "7359. ai content creation  -> 2\n",
      "7360. ai control systems  -> 2\n",
      "7361. ai curricula  -> 2\n",
      "7362. ai customization  -> 2\n",
      "7363. web data extraction  -> 2\n",
      "7364. web development (ai-assisted)  -> 2\n",
      "7365. web grounding  -> 2\n",
      "7366. web ui development  -> 2\n",
      "7367. web ui for llms  -> 2\n",
      "7368. web-based ai development  -> 2\n",
      "7369. adversarial input  -> 2\n",
      "7370. adversarial prompt detection  -> 2\n",
      "7371. agent state  -> 2\n",
      "7372. agent state management  -> 2\n",
      "7373. agent testing  -> 2\n",
      "7374. waveform reconstruction  -> 2\n",
      "7375. wavevae  -> 2\n",
      "7376. wearable machine learning  -> 2\n",
      "7377. wearable sensors  -> 2\n",
      "7378. wearable technology  -> 2\n",
      "7379. agentic reinforcement learning  -> 2\n",
      "7380. agent interoperability  -> 2\n",
      "7381. agent loop  -> 2\n",
      "7382. agent memory systems  -> 2\n",
      "7383. agent mode  -> 2\n",
      "7384. agent observability  -> 2\n",
      "7385. agent protocols  -> 2\n",
      "7386. agent reflection  -> 2\n",
      "7387. ai agent evaluation  -> 2\n",
      "7388. ai agent marketplace  -> 2\n",
      "7389. ai algorithms  -> 2\n",
      "7390. agent-to-agent communication (a2a)  -> 2\n",
      "7391. agent-tool integration  -> 2\n",
      "7392. agent2agent protocol (a2a)  -> 2\n",
      "7393. agentic ai optimization  -> 2\n",
      "7394. agentic reasoning  -> 2\n",
      "7395. wordnet  -> 2\n",
      "7396. workflow optimization  -> 2\n",
      "7397. workflow orchestration (ai)  -> 2\n",
      "7398. world knowledge  -> 2\n",
      "7399. world simulation  -> 2\n",
      "7400. xess  -> 2\n",
      "7401. zerogpu  -> 2\n",
      "7402. zero-shot reasoning  -> 2\n",
      "7403. 8-bit training  -> 2\n",
      "7404. a* search  -> 2\n",
      "7405. ab-mcts  -> 2\n",
      "7406. abstraction  -> 2\n",
      "7407. wireless networks  -> 2\n",
      "7408. wolfram integration  -> 2\n",
      "7409. word sense disambiguation  -> 2\n",
      "7410. word-level timestamping  -> 2\n",
      "7411. actor model  -> 2\n",
      "7412. actor-critic  -> 2\n",
      "7413. 3d world modeling  -> 2\n",
      "7414. 4  -> 2\n",
      "7415. 4-bit training  -> 2\n",
      "7416. 4d scene reconstruction  -> 2\n",
      "7417. 5g  -> 2\n",
      "7418. 8  -> 2\n",
      "7419. action  -> 2\n",
      "7420. action agent  -> 2\n",
      "7421. action planning  -> 2\n",
      "7422. action space normalization  -> 2\n",
      "7423. activation analysis  -> 2\n",
      "7424. activation recomputation  -> 2\n",
      "7425. activepieces  -> 2\n",
      "7426. activity tracking  -> 2\n",
      "7427. nvidia hgx  -> 2\n",
      "7428. nvidia hgx b200  -> 2\n",
      "7429. nvidia hopper  -> 2\n",
      "7430. neural text-to-speech  -> 2\n",
      "7431. neural watermarking  -> 2\n",
      "7432. next token prediction  -> 2\n",
      "7433. next-frame prediction  -> 2\n",
      "7434. next-state prediction  -> 2\n",
      "7435. nt-xent loss  -> 2\n",
      "7436. numerical computing  -> 2\n",
      "7437. nvidia ai enterprise  -> 2\n",
      "7438. nvidia blackwell gpus  -> 2\n",
      "7439. nvidia device plugin  -> 2\n",
      "7440. nvidia drive  -> 2\n",
      "7441. nvidia h100 optimization  -> 2\n",
      "7442. nvidia h200 gpus  -> 2\n",
      "7443. nosql databases  -> 2\n",
      "7444. notebook automation  -> 2\n",
      "7445. notion api  -> 2\n",
      "7446. novelty detection  -> 2\n",
      "7447. novelty search  -> 2\n",
      "7448. nowcasting  -> 2\n",
      "7449. npu design  -> 2\n",
      "7450. nsfw detection  -> 2\n",
      "7451. zero-shot tts  -> 2\n",
      "7452. zero/zero++  -> 2\n",
      "7453. no-code platform  -> 2\n",
      "7454. nodes  -> 2\n",
      "7455. noise injection  -> 2\n",
      "7456. non-autoregressive modeling  -> 2\n",
      "7457. nope  -> 2\n",
      "7458. nosql  -> 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prompt engineering</td>\n",
       "      <td>3255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language processing (nlp)</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer vision</td>\n",
       "      <td>2611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large language model (llm)</td>\n",
       "      <td>2569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llm api</td>\n",
       "      <td>2445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>nodes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>noise injection</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>non-autoregressive modeling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>nope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>nosql</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7458 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  topic  count\n",
       "0                    prompt engineering   3255\n",
       "1     natural language processing (nlp)   2996\n",
       "2                       computer vision   2611\n",
       "3            large language model (llm)   2569\n",
       "4                               llm api   2445\n",
       "...                                 ...    ...\n",
       "7453                              nodes      2\n",
       "7454                    noise injection      2\n",
       "7455        non-autoregressive modeling      2\n",
       "7456                               nope      2\n",
       "7457                              nosql      2\n",
       "\n",
       "[7458 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated df_all_items to filtered dataset (freq >=2).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-bit inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-bit inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-bit llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135142</th>\n",
       "      <td>zero/zero++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135143</th>\n",
       "      <td>zerogpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135144</th>\n",
       "      <td>zerogpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135145</th>\n",
       "      <td>zmp control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135146</th>\n",
       "      <td>zmp control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135147 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic\n",
       "0       1-bit inference\n",
       "1       1-bit inference\n",
       "2             1-bit llm\n",
       "3             1-bit llm\n",
       "4             1-bit llm\n",
       "...                 ...\n",
       "135142      zero/zero++\n",
       "135143          zerogpu\n",
       "135144          zerogpu\n",
       "135145      zmp control\n",
       "135146      zmp control\n",
       "\n",
       "[135147 rows x 1 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- Filter topics with frequency >=2 ----------------\n",
    "min_freq = 2\n",
    "mask_keep = df_all_items['topic'].map(freq_series) >= min_freq\n",
    "filtered_df_all_items = df_all_items[mask_keep].reset_index(drop=True)\n",
    "removed = len(df_all_items) - len(filtered_df_all_items)\n",
    "removed_unique = (freq_series < min_freq).sum()\n",
    "\n",
    "print(f\"\\nFiltering topics with frequency < {min_freq}...\")\n",
    "print(f\"Rows removed: {removed}\")\n",
    "print(f\"Unique topics removed: {removed_unique}\")\n",
    "print(f\"Remaining rows: {len(filtered_df_all_items)}\")\n",
    "print(f\"Remaining unique topics: {filtered_df_all_items['topic'].nunique()}\")\n",
    "\n",
    "# Recompute frequencies after filtering\n",
    "freq_after = filtered_df_all_items['topic'].value_counts()\n",
    "print(\"\\nTop 20 topics after filtering (freq>=2):\\n\")\n",
    "Dic_topics = freq_after.reset_index()\n",
    "Dic_topics.columns = ['topic','count']\n",
    "for i, row in Dic_topics.iterrows():\n",
    "    print(f\"{i+1:2d}. {row['topic']}  -> {row['count']}\")\n",
    "\n",
    "display(Dic_topics)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(freq_after.values, bins=50, log_scale=(False, True))\n",
    "plt.title('Topic Frequency Distribution (Log Y) - After Filtering (freq>=2)')\n",
    "plt.xlabel('Occurrences per topic')\n",
    "plt.ylabel('Count of topics (log)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nUpdated df_all_items to filtered dataset (freq >=2).\")\n",
    "filtered_df_all_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1fa01",
   "metadata": {},
   "source": [
    "# Dictionary topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f302cc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prompt engineering</td>\n",
       "      <td>3255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language processing (nlp)</td>\n",
       "      <td>2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer vision</td>\n",
       "      <td>2611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large language model (llm)</td>\n",
       "      <td>2569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llm api</td>\n",
       "      <td>2445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>nodes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>noise injection</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>non-autoregressive modeling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>nope</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>nosql</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7458 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  topic  count\n",
       "0                    prompt engineering   3255\n",
       "1     natural language processing (nlp)   2996\n",
       "2                       computer vision   2611\n",
       "3            large language model (llm)   2569\n",
       "4                               llm api   2445\n",
       "...                                 ...    ...\n",
       "7453                              nodes      2\n",
       "7454                    noise injection      2\n",
       "7455        non-autoregressive modeling      2\n",
       "7456                               nope      2\n",
       "7457                              nosql      2\n",
       "\n",
       "[7458 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dic_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1061d",
   "metadata": {},
   "source": [
    "### Save dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4514b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File dic_topics_2025-11-08.csv uploaded:  2025-11-08\n",
      "File uploaded successfully\n",
      "(7458, 2)\n"
     ]
    }
   ],
   "source": [
    "#Save data\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\Denis_Davydov2\\\\OneDrive - EPAM\\\\Prophet_AI_docs\\\\Datasets\\\\AI_skills\\\\Topics\\\\'\n",
    "file_name = f'dic_topics_{date.today()}.csv'\n",
    "\n",
    "Dic_topics.to_csv(file_path + file_name, index=False)\n",
    "print(f\"File {file_name} uploaded: \", date.today())\n",
    "\n",
    "print('File uploaded successfully')\n",
    "print(Dic_topics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9166aa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 263 multiword topics:\n",
      "\n",
      "====================================================================================================\n",
      "   0: advanced data analysis (code interpreter)\n",
      "   1: advanced driver assistance systems (adas)\n",
      "   2: agent to agent (a2a) protocol\n",
      "   3: agentic ai / ai agents\n",
      "   4: ai in domain specific applications\n",
      "   5: ai in protein structure prediction\n",
      "   6: ai performance and cost optimization\n",
      "   7: ai safety and content filtering\n",
      "   8: ai safety and content moderation\n",
      "   9: ai user interface (ui) development\n",
      "  10: alignment by preference optimization (apo)\n",
      "  11: amazon bedrock agentcore starter toolkit\n",
      "  12: amazon bedrock custom model import\n",
      "  13: amazon elastic compute cloud (amazon ec2)\n",
      "  14: amazon elastic container registry (amazon ecr)\n",
      "  15: amazon managed service for apache flink\n",
      "  16: amazon sagemaker partner ai apps sdks\n",
      "  17: amazon sagemaker unified studio ide\n",
      "  18: amazon titan text embeddings v2\n",
      "  19: and applications across different contexts.\n",
      "  20: anti-hallucination testing ml frameworks/tools: huggingface\n",
      "  21: api rate limiting and backoff handling\n",
      "  22: approximate nearest neighbor (ann) search\n",
      "  23: arctic long sequence training (alst)\n",
      "  24: artificial general intelligence (agi) research\n",
      "  25: authentication and authorization for ai\n",
      "  26: automated testing ai applications: agentic document workflows\n",
      "  27: automatic carpet detection and avoidance\n",
      "  28: automatic number plate recognition (anpr)\n",
      "  29: aws billing and cost management\n",
      "  30: aws deep learning containers (dlc)\n",
      "  31: aws distro for opentelemetry (adot)\n",
      "  32: aws identity and access management\n",
      "  33: aws identity and access management (iam)\n",
      "  34: aws systems manager parameter store\n",
      "  35: aws systems manager session manager\n",
      "  36: azure ai foundry agent services\n",
      "  37: azure app service authentication (easy auth)\n",
      "  38: azure data lake storage gen2\n",
      "  39: based on the provided ai news\n",
      "  40: batch size optimization (for ml)\n",
      "  41: beginner python for ai engineering\n",
      "  42: bias and fairness in ai\n",
      "  43: bias detection and mitigation (ai)\n",
      "  44: bias detection robotics: sensorimotor control\n",
      "  45: bias mitigation (fairness in ml)\n",
      "  46: bring your own container (byoc)\n",
      "  47: byoc (bring your own container)\n",
      "  48: byoi (bring your own inference)\n",
      "  49: byok (bring your own key)\n",
      "  50: chain of thought reasoning (cot)\n",
      "  51: class-weighted cross entropy loss function\n",
      "  52: cloud identity and access management\n",
      "  53: cloud ml platforms (vertex ai/bedrock)\n",
      "  54: code generation with llms (code interpreter)\n",
      "  55: code llms / code generation\n",
      "  56: comet and sagemaker ai experiment workflow\n",
      "  57: compute architecture for neural networks\n",
      "  58: computer vision (webcam tracking in insta360)\n",
      "  59: conditional value at risk (cvar)\n",
      "  60: credit card fraud detection dataset\n",
      "  61: custom driver development (ai hardware)\n",
      "  62: custom setup for amazon sagemaker ai\n",
      "  63: customer data platforms (cdp) integration\n",
      "  64: dapo (direct advantage policy optimization)\n",
      "  65: data center infrastructure management (dcim)\n",
      "  66: data center management (for ai)\n",
      "  67: data engineering for ml (storage/chunking)\n",
      "  68: data privacy & logging compliance\n",
      "  69: data privacy and compliance (hipaa)\n",
      "  70: data privacy and gdpr compliance\n",
      "  71: data quality management (for ai training)\n",
      "  72: databricks ai risk framework (dasf)\n",
      "  73: descript audio codec (dac) encoding\n",
      "  74: digital millennium copyright act (dmca)\n",
      "  75: distributed ai training and inference\n",
      "  76: distributed systems specialized areas: nlp\n",
      "  77: dlss (deep learning super sampling)\n",
      "  78: document understanding and form parsing\n",
      "  79: document understanding and layout parsing\n",
      "  80: dpop (distributed proximal policy optimization)\n",
      "  81: dsl (domain-specific language) for ai\n",
      "  82: ec2 capacity blocks for ml\n",
      "  83: ecr (amazon elastic container registry)\n",
      "  84: edge ai / ai gateway\n",
      "  85: efficient model training and optimization\n",
      "  86: electronic health record (ehr) processing\n",
      "  87: embeddings ml operations: model benchmarking\n",
      "  88: empirical cumulative distribution function (ecdf)\n",
      "  89: evaluation and benchmarking for multimodal rag\n",
      "  90: evaluation metrics precision and recall\n",
      "  91: experiment tracking (weights & biases)\n",
      "  92: external memory & symbolic planning\n",
      "  93: fine-tuning mlops & infrastructure: vllm\n",
      "  94: flashattention 2 ai infrastructure: gpu programming\n",
      "  95: foreign function & memory api\n",
      "  96: fsdp (fully sharded data parallel)\n",
      "  97: fsdp2 (fully sharded data parallel)\n",
      "  98: fully sharded data parallel (fsdp)\n",
      "  99: fully sharded data parallelism (fsdp)\n",
      " 100: function calling (llm function calling)\n",
      " 101: gemini live conversational ai assistant\n",
      " 102: google agent development kit (adk)\n",
      " 103: google cloud a4 virtual machines\n",
      " 104: google cloud ai basketball coach\n",
      " 105: google cloud security command center\n",
      " 106: google cloud's dynamic workload scheduler\n",
      " 107: group relative policy optimization (grpo)\n",
      " 108: group reward policy optimization (grpo)\n",
      " 109: group sequence policy optimization (gspo)\n",
      " 110: grpo (group proximal policy optimization)\n",
      " 111: grpo (group relative policy optimization)\n",
      " 112: healthcare model context protocol (hmcp)\n",
      " 113: high performance computing (hpc) for ai\n",
      " 114: high-performance computing (hpc) for ai\n",
      " 115: high-performance computing (hpc) for ml\n",
      " 116: hnsw (hierarchical navigable small world)\n",
      " 117: human evaluation of generative models\n",
      " 118: hybrid systems (rules + llms)\n",
      " 119: ibm cloud pak for data\n",
      " 120: ice (internal combustion engine) systems\n",
      " 121: identity and access management (iam)\n",
      " 122: image classification llm & generative ai: prompt engineering\n",
      " 123: incident management (ai for it operations)\n",
      " 124: inertial measurement unit (imu) data processing\n",
      " 125: inference endpoints development: code generation\n",
      " 126: iterated distillation and amplification (ida)\n",
      " 127: joint embedding predictive architecture (jepa)\n",
      " 128: kv cache vision/multimodal: computer vision\n",
      " 129: large language model (llm) training\n",
      " 130: large language model optimization (llmo)\n",
      " 131: large scale ai model training\n",
      " 132: large video language models (lvlms)\n",
      " 133: large-scale data management for ai\n",
      " 134: liquid time constant networks (ltcn)\n",
      " 135: llamahub ai development: prompt engineering\n",
      " 136: llm (implied due to anthropic's primary focus)\n",
      " 137: llm development & deployment: pytorch\n",
      " 138: lora fine-tuning ai development: memory-efficient training\n",
      " 139: machine learning & deep learning: pytorch\n",
      " 140: machine learning & deep learning: tensorflow\n",
      " 141: markov chain monte carlo (mcmc)\n",
      " 142: mcmc (markov chain monte carlo)\n",
      " 143: mcts (monte carlo tree search)\n",
      " 144: memory systems for ai agents benchmarking & evaluation: model benchmarking\n",
      " 145: memory-efficient training model types & frameworks: stable diffusion\n",
      " 146: memory-efficient training nlp: natural language processing\n",
      " 147: message passing neural networks (mpnn)\n",
      " 148: mixed precision (fp16 / fp8)\n",
      " 149: mixture of experts (moe) ai infrastructure & tools: kserve\n",
      " 150: mixture of experts (moe) architecture\n",
      " 151: mixture of experts (moe) models\n",
      " 152: ml security (cybersecurity for ml)\n",
      " 153: mobile neural processing units (npus)\n",
      " 154: model compression ai development: multigpu training\n",
      " 155: model conversion (dense to moe)\n",
      " 156: model evaluation ai safety: learning injection detection\n",
      " 157: model optimization (training & inference)\n",
      " 158: model optimization for edge devices\n",
      " 159: model pruning agent development: multi-agent systems\n",
      " 160: model security and safe model distribution (safetensors)\n",
      " 161: model serving mathematics/technical: fp8 computing\n",
      " 162: mojo (programming language for ai)\n",
      " 163: monitoring and observability for ai systems\n",
      " 164: monte carlo tree search (mcts)\n",
      " 165: multimodal large language models (mllms)\n",
      " 166: natively trainable sparse attention (nsa)\n",
      " 167: natural language reinforcement learning (nlrl)\n",
      " 168: natural language to code execution\n",
      " 169: nccl (nvidia collective communications library)\n",
      " 170: neural processing unit (npu) design\n",
      " 171: neural processing unit (npu) programming\n",
      " 172: nist ai risk management framework\n",
      " 173: nlp ai tools & platforms: prompt engineering\n",
      " 174: no specific ai technologies or skills are detailed.\n",
      " 175: nvidia blackwell tensor core gpus\n",
      " 176: nvidia collective communications library (nccl)\n",
      " 177: on-device ai / edge ai\n",
      " 178: onnx (open neural network exchange)\n",
      " 179: order management system (oms) integration\n",
      " 180: organized in a comma-separated list: prompt engineering\n",
      " 181: owasp agentic security top 10\n",
      " 182: owasp top 10 for genai\n",
      " 183: parallel execution and control flow\n",
      " 184: partially observable markov decision process\n",
      " 185: partially observable markov decision process (pomdp)\n",
      " 186: persistent memory stores (sqlite for rag)\n",
      " 187: planning and reasoning in llms\n",
      " 188: policy optimization (group relative policy optimization)\n",
      " 189: policy optimization (ppo and variants)\n",
      " 190: power management for data centers\n",
      " 191: privacy and compliance (iso 27001)\n",
      " 192: real-time data processing for ai\n",
      " 193: real-time web browsing for llms\n",
      " 194: recursive kl divergence optimization (rkld)\n",
      " 195: region of interest (roi) extraction\n",
      " 196: reinforcement learning computer vision/image generation: stable diffusion\n",
      " 197: reinforcement learning from ai feedback\n",
      " 198: reinforcement learning from ai feedback (rlaif)\n",
      " 199: reinforcement learning from feedback (rlf)\n",
      " 200: reinforcement learning from human feedback\n",
      " 201: reinforcement learning from human feedback (rhlf)\n",
      " 202: reinforcement learning from human feedback (rlhf)\n",
      " 203: reinforcement learning image generation: dall·e\n",
      " 204: reinforcement learning with ai feedback\n",
      " 205: reinforcement learning with ai feedback (rlaif)\n",
      " 206: reinforcement learning with human feedback\n",
      " 207: reinforcement learning with human feedback (rlhf)\n",
      " 208: reinforcement learning with verifiable reward\n",
      " 209: relational graph convolutional network (rgcn)\n",
      " 210: rl with verifiable rewards (rlvr)\n",
      " 211: rlaif (reinforcement learning from ai feedback)\n",
      " 212: rlhf (reinforcement learning from human feedback)\n",
      " 213: rloo (reinforcement learning from objective optimization)\n",
      " 214: rlvr (reinforcement learning from verifiable rewards)\n",
      " 215: robotic manipulation data engineering: data cleaning\n",
      " 216: robust parsing & error handling\n",
      " 217: rope (rotary positional embeddings) scaling\n",
      " 218: sagemaker studio administration best practices\n",
      " 219: scalable intent driven routing (sidr)\n",
      " 220: scaling laws & compute efficiency\n",
      " 221: sdh (subtitles for the deaf and hard of hearing)\n",
      " 222: search enhancement (ai in search)\n",
      " 223: security and compliance for ai\n",
      " 224: sglang ai frameworks & tools: unsloth\n",
      " 225: slam (simultaneous localization and mapping)\n",
      " 226: software bill of materials (sbom)\n",
      " 227: speaker diarization machine learning infrastructure: tensorflow\n",
      " 228: ssm (structured state space models)\n",
      " 229: stable diffusion model architecture: monte carlo tree search\n",
      " 230: state management (in ai systems)\n",
      " 231: static application security testing (sast)\n",
      " 232: structured output / json generation\n",
      " 233: structured state space models (ssm)\n",
      " 234: systems programming in c for ml\n",
      " 235: text encoders (for ai models)\n",
      " 236: thales ciphertrust data security platform\n",
      " 237: time series / weather forecasting\n",
      " 238: token-level monte carlo tree search\n",
      " 239: tokenization and context window management\n",
      " 240: tool integration (for ai agents)\n",
      " 241: tool use (for ai agents)\n",
      " 242: tool use and tool calling\n",
      " 243: tool use in ai agents\n",
      " 244: tools or technologies are detailed.\n",
      " 245: training and fine-tuning large models\n",
      " 246: traveling off the beaten path\n",
      " 247: ttc king of magnetic rgb\n",
      " 248: user and entity behavior analytics\n",
      " 249: user experience (ux) design for ai\n",
      " 250: user experience (ux) for ai\n",
      " 251: user interaction design (for ai)\n",
      " 252: vector search / semantic search\n",
      " 253: virtual private cloud service controls\n",
      " 254: visual studio code extension development\n",
      " 255: voice assistant development (alexa skills)\n",
      " 256: voice user interface (vui) design\n",
      " 257: web and document search integration\n",
      " 258: web application development (with ai)\n",
      " 259: web application firewall (waf) configuration\n",
      " 260: web crawling for llm pretraining\n",
      " 261: web ui development (for ai)\n",
      " 262: zero-shot chain of thought prompting\n",
      "====================================================================================================\n",
      "\n",
      "Total: 263 topics with more than 4 words\n"
     ]
    }
   ],
   "source": [
    "# Display all multiword_topics items in full (no truncation)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(f\"All {len(multiword_topics)} multiword topics:\\n\")\n",
    "print(\"=\" * 100)\n",
    "for idx, topic in enumerate(multiword_topics):\n",
    "    print(f\"{idx:4d}: {topic}\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nTotal: {len(multiword_topics)} topics with more than 4 words\")\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87e99c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 19452 unique topics\n",
      "  Found pair: 'ai' <-> 'artificial intelligence'\n",
      "  Found pair: 'ml' <-> 'machine learning'\n",
      "  Found pair: 'nlp' <-> 'natural language processing'\n",
      "  Found pair: 'cnn' <-> 'convolutional neural network'\n",
      "  Found pair: 'rnn' <-> 'recurrent neural network'\n",
      "  Found pair: 'lstm' <-> 'long short-term memory'\n",
      "  Found pair: 'vae' <-> 'variational autoencoder'\n",
      "  Found pair: 'rag' <-> 'retrieval augmented generation'\n",
      "  Found pair: 'llm' <-> 'large language model'\n",
      "  Found pair: 'asr' <-> 'automatic speech recognition'\n",
      "  Found pair: 'tts' <-> 'text-to-speech'\n",
      "  Found pair: 'ocr' <-> 'optical character recognition'\n",
      "  Found pair: 'mlops' <-> 'machine learning operations'\n",
      "  Found pair: 'aws' <-> 'amazon web services'\n",
      "  Found pair: 'gcp' <-> 'google cloud platform'\n",
      "\n",
      "Detected 349 abbreviation-full form pairs\n",
      "\n",
      "Created 675 merge mappings\n",
      "\n",
      "Sample canonical mappings (first 15):\n",
      "  '128k' → 'long-context llms (128k)'\n",
      "  '4-bit' → 'quantization (4-bit)'\n",
      "  '4-bit quantization' → '4-bit quantization (mxfp4)'\n",
      "  '8-bit' → 'model quantization (8-bit)'\n",
      "  'a2a' → 'agent2agent protocol (a2a)'\n",
      "  'a2i' → 'amazon augmented ai (a2i)'\n",
      "  'accelerated processing kit' → 'accelerated processing kit (xpk)'\n",
      "  'access control' → 'access control (acls)'\n",
      "  'accurate quantized training' → 'accurate quantized training (aqt)'\n",
      "  'acls' → 'access control (acls)'\n",
      "  'acp' → 'agent communication protocol (acp)'\n",
      "  'activation-aware weight quantization' → 'activation-aware weight quantization (awq)'\n",
      "  'active noise cancellation' → 'active noise cancellation (anc)'\n",
      "  'adas' → 'advanced driver assistance systems (adas)'\n",
      "  'adk' → 'google agent development kit (adk)'\n",
      "\n",
      "================================================================================\n",
      "Topics before merging semantic duplicates: 19452\n",
      "Topics after merging:                      19023\n",
      "Reduced by:                                 429\n",
      "================================================================================\n",
      "\n",
      "Final merged_topics1 count: 19023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                \n",
       "1                            .net\n",
       "2           /invocations endpoint\n",
       "3                  /ping endpoint\n",
       "4                           000hz\n",
       "5                          000mah\n",
       "6                 1-bit inference\n",
       "7                       1-bit llm\n",
       "8           1-bit neural networks\n",
       "9              1-bit quantization\n",
       "10             1-bit transformers\n",
       "11    1.5b-parameter llm backbone\n",
       "12            128k context window\n",
       "13                             1u\n",
       "14             2-bit quantization\n",
       "15                         2.4ghz\n",
       "16            2.5d representation\n",
       "17                   2d animation\n",
       "18         2d animation (with ai)\n",
       "19          2d block quantization\n",
       "20          2d texture generation\n",
       "21            2d-to-3d conversion\n",
       "22        2d/3d spatial reasoning\n",
       "23                              3\n",
       "24                          3-bit\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify and merge semantic duplicates: abbreviations + full forms\n",
    "# Strategy: detect common AI abbreviation patterns and their expansions\n",
    "merged_topics1 = merged_topics.copy()\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Known abbreviation mappings (expandable)\n",
    "KNOWN_ABBREV_MAP = {\n",
    "    'ai': 'artificial intelligence',\n",
    "    'ml': 'machine learning',\n",
    "    'nlp': 'natural language processing',\n",
    "    'cv': 'computer vision',\n",
    "    'dl': 'deep learning',\n",
    "    'rl': 'reinforcement learning',\n",
    "    'gan': 'generative adversarial network',\n",
    "    'gans': 'generative adversarial networks',\n",
    "    'cnn': 'convolutional neural network',\n",
    "    'cnns': 'convolutional neural networks',\n",
    "    'rnn': 'recurrent neural network',\n",
    "    'rnns': 'recurrent neural networks',\n",
    "    'lstm': 'long short-term memory',\n",
    "    'gru': 'gated recurrent unit',\n",
    "    'bert': 'bidirectional encoder representations from transformers',\n",
    "    'gpt': 'generative pre-trained transformer',\n",
    "    'vae': 'variational autoencoder',\n",
    "    'api': 'application programming interface',\n",
    "    'apis': 'application programming interfaces',\n",
    "    'sdk': 'software development kit',\n",
    "    'rag': 'retrieval augmented generation',\n",
    "    'llm': 'large language model',\n",
    "    'llms': 'large language models',\n",
    "    'asr': 'automatic speech recognition',\n",
    "    'tts': 'text-to-speech',\n",
    "    'ocr': 'optical character recognition',\n",
    "    'roi': 'return on investment',\n",
    "    'kpi': 'key performance indicator',\n",
    "    'kpis': 'key performance indicators',\n",
    "    'mlops': 'machine learning operations',\n",
    "    'devops': 'development operations',\n",
    "    'cicd': 'continuous integration continuous deployment',\n",
    "    'ci/cd': 'continuous integration continuous deployment',\n",
    "    'aws': 'amazon web services',\n",
    "    'gcp': 'google cloud platform',\n",
    "    'sql': 'structured query language',\n",
    "    'nosql': 'non-relational database',\n",
    "    'etl': 'extract transform load',\n",
    "    'ui': 'user interface',\n",
    "    'ux': 'user experience',\n",
    "    'saas': 'software as a service',\n",
    "    'paas': 'platform as a service',\n",
    "    'iaas': 'infrastructure as a service',\n",
    "}\n",
    "\n",
    "print(f\"Starting with {len(merged_topics1)} unique topics\")\n",
    "\n",
    "# Build a mapping of detected abbreviation-full form pairs\n",
    "abbrev_to_full = {}\n",
    "full_to_abbrev = {}\n",
    "\n",
    "topics_set = set(merged_topics1.dropna().str.strip().str.lower())\n",
    "\n",
    "# 1. Check known abbreviations\n",
    "for abbrev, full_form in KNOWN_ABBREV_MAP.items():\n",
    "    abbrev_clean = abbrev.lower().strip()\n",
    "    full_clean = full_form.lower().strip()\n",
    "    \n",
    "    if abbrev_clean in topics_set and full_clean in topics_set:\n",
    "        # Both exist - merge them\n",
    "        abbrev_to_full[abbrev_clean] = full_clean\n",
    "        full_to_abbrev[full_clean] = abbrev_clean\n",
    "        print(f\"  Found pair: '{abbrev_clean}' <-> '{full_clean}'\")\n",
    "    elif abbrev_clean in topics_set:\n",
    "        # Only abbrev exists, but we know the full form - keep abbrev as-is for now\n",
    "        pass\n",
    "    elif full_clean in topics_set:\n",
    "        # Only full form exists - keep it\n",
    "        pass\n",
    "\n",
    "# 2. Detect patterns like \"full form (abbrev)\" or \"abbrev (full form)\" already in data\n",
    "pattern_with_parens = re.compile(r'^(.+?)\\s*\\(([^)]+)\\)$')\n",
    "for topic in topics_set:\n",
    "    match = pattern_with_parens.match(topic)\n",
    "    if match:\n",
    "        part1 = match.group(1).strip().lower()\n",
    "        part2 = match.group(2).strip().lower()\n",
    "        \n",
    "        # Heuristic: shorter part is likely abbreviation\n",
    "        if len(part2) <= 5 and len(part1) > len(part2):\n",
    "            # part2 is abbreviation\n",
    "            if part2 in topics_set or part1 in topics_set:\n",
    "                abbrev_to_full[part2] = part1\n",
    "                full_to_abbrev[part1] = part2\n",
    "        elif len(part1) <= 5 and len(part2) > len(part1):\n",
    "            # part1 is abbreviation\n",
    "            if part1 in topics_set or part2 in topics_set:\n",
    "                abbrev_to_full[part1] = part2\n",
    "                full_to_abbrev[part2] = part1\n",
    "\n",
    "print(f\"\\nDetected {len(abbrev_to_full)} abbreviation-full form pairs\")\n",
    "\n",
    "# 3. Create canonical mapping: merge both into \"full form (abbrev)\"\n",
    "canonical_map = {}\n",
    "\n",
    "for abbrev, full in abbrev_to_full.items():\n",
    "    canonical = f\"{full} ({abbrev})\"\n",
    "    # Map both abbreviation and full form to canonical\n",
    "    canonical_map[abbrev] = canonical\n",
    "    canonical_map[full] = canonical\n",
    "    \n",
    "print(f\"\\nCreated {len(canonical_map)} merge mappings\")\n",
    "\n",
    "# Sample mappings\n",
    "print(\"\\nSample canonical mappings (first 15):\")\n",
    "for i, (orig, canon) in enumerate(sorted(canonical_map.items())[:15]):\n",
    "    print(f\"  '{orig}' → '{canon}'\")\n",
    "\n",
    "# 4. Apply canonical mapping to topic_items\n",
    "before_count = len(merged_topics1)\n",
    "topic_items_merged = merged_topics1.map(lambda x: canonical_map.get(x.lower().strip(), x) if pd.notna(x) else x)\n",
    "topic_items_merged = topic_items_merged.drop_duplicates().sort_values().reset_index(drop=True)\n",
    "after_count = len(topic_items_merged)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Topics before merging semantic duplicates: {before_count}\")\n",
    "print(f\"Topics after merging:                      {after_count}\")\n",
    "print(f\"Reduced by:                                 {before_count - after_count}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Show examples of what changed\n",
    "merged_examples = []\n",
    "for orig in merged_topics1.head(100):\n",
    "    if pd.notna(orig):\n",
    "        canonical = canonical_map.get(orig.lower().strip())\n",
    "        if canonical and canonical != orig:\n",
    "            merged_examples.append((orig, canonical))\n",
    "            if len(merged_examples) >= 10:\n",
    "                break\n",
    "\n",
    "if merged_examples:\n",
    "    print(\"\\nExample merges (up to 10):\")\n",
    "    for orig, merged in merged_examples:\n",
    "        print(f\"  '{orig}' → '{merged}'\")\n",
    "\n",
    "# Reassign topic_items\n",
    "merged_topics1 = topic_items_merged.copy()\n",
    "print(f\"\\nFinal merged_topics1 count: {len(merged_topics1)}\")\n",
    "merged_topics1.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bce2e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame with 19023 topics\n",
      "Rows after removing empty topics: 19022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>/invocations endpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>/ping endpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>000hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>000mah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>19018</td>\n",
       "      <td>zmp control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>19019</td>\n",
       "      <td>zombie startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>19020</td>\n",
       "      <td>zone-based navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19020</th>\n",
       "      <td>19021</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19021</th>\n",
       "      <td>19022</td>\n",
       "      <td>τ2-bench telecom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                  topic\n",
       "0          1                   .net\n",
       "1          2  /invocations endpoint\n",
       "2          3         /ping endpoint\n",
       "3          4                  000hz\n",
       "4          5                 000mah\n",
       "...      ...                    ...\n",
       "19017  19018            zmp control\n",
       "19018  19019        zombie startups\n",
       "19019  19020  zone-based navigation\n",
       "19020  19021                   zoom\n",
       "19021  19022       τ2-bench telecom\n",
       "\n",
       "[19022 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert merged_topics1 Series to DataFrame with 'id' and 'topic' columns\n",
    "df_topics = pd.DataFrame({\n",
    "    'id': range(len(merged_topics1)),\n",
    "    'topic': merged_topics1.values\n",
    "})\n",
    "\n",
    "print(f\"Created DataFrame with {len(df_topics)} topics\")\n",
    "\n",
    "# Remove rows where topic is empty string\n",
    "df_topics = df_topics[df_topics['topic'] != ''].reset_index(drop=True)\n",
    "print(f\"Rows after removing empty topics: {len(df_topics)}\")\n",
    "df_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d3a3e",
   "metadata": {},
   "source": [
    "# Get defenision (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cf10e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dial-jzrvldj5w14srjlm1bs2bc99myp\n"
     ]
    }
   ],
   "source": [
    "# === Load Environment Variables ===\n",
    "load_dotenv()  # Loads variables from .env file into environment\n",
    "\n",
    "# Retrieve database connection parameters from environment variables\n",
    "DIAL_API_KEY = os.getenv('DIAL_API_KEY')\n",
    "\n",
    "#print(DIAL_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0bb630fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9474</th>\n",
       "      <td>9475</td>\n",
       "      <td>lag-llama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      topic\n",
       "9474  9475  lag-llama"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_items = df_topics.copy()\n",
    "#topic_items = topic_items.head(25)\n",
    "topic_items = topic_items.iloc[9474:9475]\n",
    "topic_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30881b19",
   "metadata": {},
   "source": [
    "#### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dfd89601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read:  not_recognised.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read:  not_recognised.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244</td>\n",
       "      <td>active recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618</td>\n",
       "      <td>agones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1522</td>\n",
       "      <td>ai-gradio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1710</td>\n",
       "      <td>almond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>18965</td>\n",
       "      <td>zenmcp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>18966</td>\n",
       "      <td>zephyr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>18977</td>\n",
       "      <td>zero++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>19013</td>\n",
       "      <td>zig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>19022</td>\n",
       "      <td>τ2-bench telecom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             topic\n",
       "0      244     active recall\n",
       "1      618            agones\n",
       "2     1522         ai-gradio\n",
       "3     1710            almond\n",
       "4     1959               any\n",
       "..     ...               ...\n",
       "231  18965            zenmcp\n",
       "232  18966            zephyr\n",
       "233  18977            zero++\n",
       "234  19013               zig\n",
       "235  19022  τ2-bench telecom\n",
       "\n",
       "[236 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'C:\\\\Users\\\\Denis_Davydov2\\\\OneDrive - EPAM\\\\Prophet_AI_docs\\\\Datasets\\\\AI_skills\\\\Topics\\\\'\n",
    "file_name = 'not_recognised.csv'\n",
    "\n",
    "\n",
    "no_topics = pd.read_csv(file_path+file_name)\n",
    "print(\"File read: \", file_name)\n",
    "topic_items = no_topics[['id', 'term']].rename(columns={'term':'topic'})\n",
    "topic_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d759bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a66b5d5",
   "metadata": {},
   "source": [
    "### 1. Version 1 (standart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdc1b91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to process (after dropping NaN topics): 5019\n",
      "Total payloads: 5019\n",
      "Start: 2025-11-02 19:25:42.048739\n",
      "Processed batches: 76/251\n",
      "Error in batch 77: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 51914 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 77/251\n",
      "Error in batch 77: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 51914 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 77/251\n",
      "Error in batch 78: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 38201 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 78/251\n",
      "Error in batch 78: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 38201 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 78/251\n",
      "Error in batch 79: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 38201 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 79/251\n",
      "Error in batch 79: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 38201 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 79/251\n",
      "Error in batch 80: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 30122 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 80/251\n",
      "Error in batch 80: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 30122 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 80/251\n",
      "Error in batch 81: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 27509 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 81/251\n",
      "Error in batch 81: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 27509 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 81/251\n",
      "Error in batch 82: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 27509 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 82/251\n",
      "Error in batch 82: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 27509 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 82/251\n",
      "Error in batch 83: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 22684 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 83/251\n",
      "Error in batch 83: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 22684 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 83/251\n",
      "Error in batch 84: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 13040 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 84/251\n",
      "Error in batch 84: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 13040 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 84/251\n",
      "Error in batch 85: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 8379 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 85/251\n",
      "Error in batch 85: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 8379 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 85/251\n",
      "Error in batch 86: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 86/251\n",
      "Error in batch 86: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 86/251\n",
      "Error in batch 87: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 87/251\n",
      "Error in batch 87: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 87/251\n",
      "Error in batch 88: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 88/251\n",
      "Error in batch 88: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 88/251\n",
      "Error in batch 89: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 89/251\n",
      "Error in batch 89: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 89/251\n",
      "Error in batch 90: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 90/251\n",
      "Error in batch 90: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 90/251\n",
      "Error in batch 91: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 91/251\n",
      "Error in batch 91: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 91/251\n",
      "Error in batch 92: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 92/251\n",
      "Error in batch 92: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 92/251\n",
      "Error in batch 93: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 93/251\n",
      "Error in batch 93: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 93/251\n",
      "Error in batch 94: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 94/251\n",
      "Error in batch 94: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 94/251\n",
      "Error in batch 95: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 95/251\n",
      "Error in batch 95: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 95/251\n",
      "Error in batch 96: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 96/251\n",
      "Error in batch 96: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 96/251\n",
      "Error in batch 97: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 97/251\n",
      "Error in batch 97: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 97/251\n",
      "Error in batch 98: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 98/251\n",
      "Error in batch 98: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 98/251\n",
      "Error in batch 99: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 99/251\n",
      "Error in batch 99: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 99/251\n",
      "Error in batch 100: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 100/251\n",
      "Error in batch 100: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 100/251\n",
      "Error in batch 101: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 101/251\n",
      "Error in batch 101: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 101/251\n",
      "Error in batch 102: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 102/251\n",
      "Error in batch 102: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 102/251\n",
      "Error in batch 103: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 103/251\n",
      "Error in batch 103: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 103/251\n",
      "Error in batch 104: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 104/251\n",
      "Error in batch 104: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 104/251\n",
      "Error in batch 105: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 105/251\n",
      "Error in batch 105: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 105/251\n",
      "Error in batch 106: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 106/251\n",
      "Error in batch 106: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 106/251\n",
      "Error in batch 107: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 107/251\n",
      "Error in batch 107: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 107/251\n",
      "Error in batch 108: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 108/251\n",
      "Error in batch 108: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 108/251\n",
      "Error in batch 109: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 109/251\n",
      "Error in batch 109: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 109/251\n",
      "Error in batch 110: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 110/251\n",
      "Error in batch 110: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 110/251\n",
      "Error in batch 111: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 111/251\n",
      "Error in batch 111: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 111/251\n",
      "Error in batch 112: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 112/251\n",
      "Error in batch 112: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 112/251\n",
      "Error in batch 113: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 113/251\n",
      "Error in batch 113: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 113/251\n",
      "Error in batch 114: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 114/251\n",
      "Error in batch 114: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 114/251\n",
      "Error in batch 115: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 115/251\n",
      "Error in batch 115: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 115/251\n",
      "Error in batch 116: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 116/251\n",
      "Error in batch 116: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 116/251\n",
      "Error in batch 117: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 117/251\n",
      "Error in batch 117: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 117/251\n",
      "Error in batch 118: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 118/251\n",
      "Error in batch 118: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 118/251\n",
      "Error in batch 119: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 119/251\n",
      "Error in batch 119: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 119/251\n",
      "Error in batch 120: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 120/251\n",
      "Error in batch 120: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 120/251\n",
      "Error in batch 121: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 121/251\n",
      "Error in batch 121: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 121/251\n",
      "Error in batch 122: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 122/251\n",
      "Error in batch 122: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 122/251\n",
      "Error in batch 123: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 123/251\n",
      "Error in batch 123: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 123/251\n",
      "Error in batch 124: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 124/251\n",
      "Error in batch 124: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 124/251\n",
      "Error in batch 125: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 125/251\n",
      "Error in batch 125: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 125/251\n",
      "Error in batch 126: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 126/251\n",
      "Error in batch 126: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 126/251\n",
      "Error in batch 127: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 127/251\n",
      "Error in batch 127: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 127/251\n",
      "Error in batch 128: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 128/251\n",
      "Error in batch 128: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 128/251\n",
      "Error in batch 129: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 129/251\n",
      "Error in batch 129: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 129/251\n",
      "Error in batch 130: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 130/251\n",
      "Error in batch 130: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 130/251\n",
      "Error in batch 131: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 131/251\n",
      "Error in batch 131: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 131/251\n",
      "Error in batch 132: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 132/251\n",
      "Error in batch 132: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 132/251\n",
      "Error in batch 133: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 133/251\n",
      "Error in batch 133: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 133/251\n",
      "Error in batch 134: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 134/251\n",
      "Error in batch 134: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 134/251\n",
      "Error in batch 135: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 135/251\n",
      "Error in batch 135: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 135/251\n",
      "Error in batch 136: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 136/251\n",
      "Error in batch 136: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 136/251\n",
      "Error in batch 137: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 137/251\n",
      "Error in batch 137: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 137/251\n",
      "Error in batch 138: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 138/251\n",
      "Error in batch 138: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 138/251\n",
      "Error in batch 139: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 139/251\n",
      "Error in batch 139: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 139/251\n",
      "Error in batch 140: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 140/251\n",
      "Error in batch 140: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 140/251\n",
      "Error in batch 141: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 141/251\n",
      "Error in batch 141: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 141/251\n",
      "Error in batch 142: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 142/251\n",
      "Error in batch 142: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 142/251\n",
      "Error in batch 143: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 143/251\n",
      "Error in batch 143: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 143/251\n",
      "Error in batch 144: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 144/251\n",
      "Error in batch 144: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 144/251\n",
      "Error in batch 145: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 145/251\n",
      "Error in batch 145: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 145/251\n",
      "Error in batch 146: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 146/251\n",
      "Error in batch 146: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 146/251\n",
      "Error in batch 147: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 147/251\n",
      "Error in batch 147: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 147/251\n",
      "Error in batch 148: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 148/251\n",
      "Error in batch 148: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 148/251\n",
      "Error in batch 149: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 149/251\n",
      "Error in batch 149: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 149/251\n",
      "Error in batch 150: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 150/251\n",
      "Error in batch 150: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 150/251\n",
      "Error in batch 151: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 151/251\n",
      "Error in batch 151: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 151/251\n",
      "Error in batch 152: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 152/251\n",
      "Error in batch 152: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 152/251\n",
      "Error in batch 153: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 153/251\n",
      "Error in batch 153: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 153/251\n",
      "Error in batch 154: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 154/251\n",
      "Error in batch 154: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 154/251\n",
      "Error in batch 155: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 155/251\n",
      "Error in batch 155: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 155/251\n",
      "Error in batch 156: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 156/251\n",
      "Error in batch 156: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 156/251\n",
      "Error in batch 157: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 157/251\n",
      "Error in batch 157: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 157/251\n",
      "Error in batch 158: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 158/251\n",
      "Error in batch 158: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 158/251\n",
      "Error in batch 159: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 159/251\n",
      "Error in batch 159: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 159/251\n",
      "Error in batch 160: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 160/251\n",
      "Error in batch 160: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 160/251\n",
      "Error in batch 161: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 161/251\n",
      "Error in batch 161: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 161/251\n",
      "Error in batch 162: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 162/251\n",
      "Error in batch 162: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 162/251\n",
      "Error in batch 163: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 163/251\n",
      "Error in batch 163: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 163/251\n",
      "Error in batch 164: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 164/251\n",
      "Error in batch 164: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 164/251\n",
      "Error in batch 165: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 165/251\n",
      "Error in batch 165: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 165/251\n",
      "Error in batch 166: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 166/251\n",
      "Error in batch 166: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 166/251\n",
      "Error in batch 167: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 167/251\n",
      "Error in batch 167: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 167/251\n",
      "Error in batch 168: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 168/251\n",
      "Error in batch 168: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 168/251\n",
      "Error in batch 169: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 169/251\n",
      "Error in batch 169: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 169/251\n",
      "Error in batch 170: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 170/251\n",
      "Error in batch 170: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 170/251\n",
      "Error in batch 171: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 171/251\n",
      "Error in batch 171: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 171/251\n",
      "Error in batch 172: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 172/251\n",
      "Error in batch 172: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 172/251\n",
      "Error in batch 173: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 173/251\n",
      "Error in batch 173: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 173/251\n",
      "Error in batch 174: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 174/251\n",
      "Error in batch 174: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 174/251\n",
      "Error in batch 175: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 175/251\n",
      "Error in batch 175: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 175/251\n",
      "Error in batch 176: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 176/251\n",
      "Error in batch 176: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 176/251\n",
      "Error in batch 177: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 177/251\n",
      "Error in batch 177: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 177/251\n",
      "Error in batch 178: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 178/251\n",
      "Error in batch 178: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 178/251\n",
      "Error in batch 179: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 179/251\n",
      "Error in batch 179: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 179/251\n",
      "Error in batch 180: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 180/251\n",
      "Error in batch 180: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 180/251\n",
      "Error in batch 181: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 181/251\n",
      "Error in batch 181: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 181/251\n",
      "Error in batch 182: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 182/251\n",
      "Error in batch 182: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 182/251\n",
      "Error in batch 183: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 183/251\n",
      "Error in batch 183: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 183/251\n",
      "Error in batch 184: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 184/251\n",
      "Error in batch 184: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 184/251\n",
      "Error in batch 185: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 185/251\n",
      "Error in batch 185: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 185/251\n",
      "Error in batch 186: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 186/251\n",
      "Error in batch 186: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 186/251\n",
      "Error in batch 187: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 187/251\n",
      "Error in batch 187: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 187/251\n",
      "Error in batch 188: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 188/251\n",
      "Error in batch 188: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 188/251\n",
      "Error in batch 189: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 189/251\n",
      "Error in batch 189: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 189/251\n",
      "Error in batch 190: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 190/251\n",
      "Error in batch 190: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 190/251\n",
      "Error in batch 191: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 191/251\n",
      "Error in batch 191: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 191/251\n",
      "Error in batch 192: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 192/251\n",
      "Error in batch 192: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 192/251\n",
      "Error in batch 193: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 193/251\n",
      "Error in batch 193: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 193/251\n",
      "Error in batch 194: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 194/251\n",
      "Error in batch 194: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 194/251\n",
      "Error in batch 195: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 195/251\n",
      "Error in batch 195: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 195/251\n",
      "Error in batch 196: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 196/251\n",
      "Error in batch 196: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 196/251\n",
      "Error in batch 197: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 197/251\n",
      "Error in batch 197: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 197/251\n",
      "Error in batch 198: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 198/251\n",
      "Error in batch 198: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 198/251\n",
      "Error in batch 199: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 199/251\n",
      "Error in batch 199: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 199/251\n",
      "Error in batch 200: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 200/251\n",
      "Error in batch 200: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 200/251\n",
      "Error in batch 201: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 201/251\n",
      "Error in batch 201: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 201/251\n",
      "Error in batch 202: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 202/251\n",
      "Error in batch 202: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 202/251\n",
      "Error in batch 203: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 203/251\n",
      "Error in batch 203: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 203/251\n",
      "Error in batch 204: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 204/251\n",
      "Error in batch 204: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 204/251\n",
      "Error in batch 205: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 205/251\n",
      "Error in batch 205: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 205/251\n",
      "Error in batch 206: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 206/251\n",
      "Error in batch 206: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 206/251\n",
      "Error in batch 207: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 207/251\n",
      "Error in batch 207: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 207/251\n",
      "Error in batch 208: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 208/251\n",
      "Error in batch 208: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 208/251\n",
      "Error in batch 209: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 209/251\n",
      "Error in batch 209: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 209/251\n",
      "Error in batch 210: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 210/251\n",
      "Error in batch 210: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 210/251\n",
      "Error in batch 211: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 211/251\n",
      "Error in batch 211: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 211/251\n",
      "Error in batch 212: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 212/251\n",
      "Error in batch 212: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 212/251\n",
      "Error in batch 213: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 213/251\n",
      "Error in batch 213: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 213/251\n",
      "Error in batch 214: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 214/251\n",
      "Error in batch 214: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 214/251\n",
      "Error in batch 215: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 215/251\n",
      "Error in batch 215: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 215/251\n",
      "Error in batch 216: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 216/251\n",
      "Error in batch 216: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 216/251\n",
      "Error in batch 217: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 217/251\n",
      "Error in batch 217: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 217/251\n",
      "Error in batch 218: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 218/251\n",
      "Error in batch 218: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 218/251\n",
      "Error in batch 219: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 219/251\n",
      "Error in batch 219: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 219/251\n",
      "Error in batch 220: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 220/251\n",
      "Error in batch 220: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 220/251\n",
      "Error in batch 221: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 221/251\n",
      "Error in batch 221: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 221/251\n",
      "Error in batch 222: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 222/251\n",
      "Error in batch 222: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 222/251\n",
      "Error in batch 223: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 223/251\n",
      "Error in batch 223: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 223/251\n",
      "Error in batch 224: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 224/251\n",
      "Error in batch 224: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 224/251\n",
      "Error in batch 225: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 225/251\n",
      "Error in batch 225: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 225/251\n",
      "Error in batch 226: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 226/251\n",
      "Error in batch 226: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 226/251\n",
      "Error in batch 227: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 227/251\n",
      "Error in batch 227: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 227/251\n",
      "Error in batch 228: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 228/251\n",
      "Error in batch 228: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 228/251\n",
      "Error in batch 229: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 229/251\n",
      "Error in batch 229: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 229/251\n",
      "Error in batch 230: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 230/251\n",
      "Error in batch 230: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 230/251\n",
      "Error in batch 231: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 231/251\n",
      "Error in batch 231: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 231/251\n",
      "Error in batch 232: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 232/251\n",
      "Error in batch 232: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 232/251\n",
      "Error in batch 233: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 233/251\n",
      "Error in batch 233: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 233/251\n",
      "Error in batch 234: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 234/251\n",
      "Error in batch 234: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 234/251\n",
      "Error in batch 235: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 235/251\n",
      "Error in batch 235: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 235/251\n",
      "Error in batch 236: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 236/251\n",
      "Error in batch 236: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 236/251\n",
      "Error in batch 237: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 237/251\n",
      "Error in batch 237: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 237/251\n",
      "Error in batch 238: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 238/251\n",
      "Error in batch 238: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 238/251\n",
      "Error in batch 239: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 239/251\n",
      "Error in batch 239: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 239/251\n",
      "Error in batch 240: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 240/251\n",
      "Error in batch 240: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 240/251\n",
      "Error in batch 241: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 241/251\n",
      "Error in batch 241: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 241/251\n",
      "Error in batch 242: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 242/251\n",
      "Error in batch 242: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 242/251\n",
      "Error in batch 243: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 243/251\n",
      "Error in batch 243: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 243/251\n",
      "Error in batch 244: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 244/251\n",
      "Error in batch 244: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 244/251\n",
      "Error in batch 245: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 245/251\n",
      "Error in batch 245: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 245/251\n",
      "Error in batch 246: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 246/251\n",
      "Error in batch 246: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 246/251\n",
      "Error in batch 247: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 247/251\n",
      "Error in batch 247: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 247/251\n",
      "Error in batch 248: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 248/251\n",
      "Error in batch 248: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 248/251\n",
      "Error in batch 249: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 249/251\n",
      "Error in batch 249: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 249/251\n",
      "Error in batch 250: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 250/251\n",
      "Error in batch 250: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 250/251\n",
      "Error in batch 251: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 251/251\n",
      "Error in batch 251: Error code: 429 - {'error': {'message': 'Hit token rate limit. Minute limit: 0 / 128000 tokens. Day limit: 2003798 / 2000000 tokens. Week limit: 4006146 / 9223372036854775807 tokens. Month limit: 4006146 / 9223372036854775807 tokens.', 'display_message': \"You've exceeded your daily token limit\", 'code': '429'}}\n",
      "Processed batches: 251/251\n",
      "Finish: 2025-11-02 20:33:16.772277\n",
      "Processing time: 1:07:34.723538\n",
      "Terms processed: 5019\n",
      "Batches with errors: 175\n",
      "Empty definitions: 3499\n",
      "Results saved to: C:\\Users\\Denis_Davydov2\\OneDrive - EPAM\\Prophet_AI_docs\\Datasets\\AI_skills\\Topics\\topics_definitions_2025-11-02_3.csv\n",
      "\n",
      "Finish: 2025-11-02 20:33:16.772277\n",
      "Processing time: 1:07:34.723538\n",
      "Terms processed: 5019\n",
      "Batches with errors: 175\n",
      "Empty definitions: 3499\n",
      "Results saved to: C:\\Users\\Denis_Davydov2\\OneDrive - EPAM\\Prophet_AI_docs\\Datasets\\AI_skills\\Topics\\topics_definitions_2025-11-02_3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>term</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4982</td>\n",
       "      <td>data lifecycle management</td>\n",
       "      <td>Data lifecycle management in AI/ML is the end-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4983</td>\n",
       "      <td>data lineage</td>\n",
       "      <td>In AI/ML, data lineage is the process of track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4984</td>\n",
       "      <td>data literacy</td>\n",
       "      <td>Data literacy in the context of AI/ML is the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4985</td>\n",
       "      <td>data loaders</td>\n",
       "      <td>Data loaders are utilities that provide an ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4986</td>\n",
       "      <td>data loading</td>\n",
       "      <td>Data loading is the process of reading data fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4987</td>\n",
       "      <td>data loading optimization</td>\n",
       "      <td>Data loading optimization refers to the set of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4988</td>\n",
       "      <td>data logging</td>\n",
       "      <td>In machine learning, data logging is the syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4989</td>\n",
       "      <td>data loss prevention (ai)</td>\n",
       "      <td>Data loss prevention in AI is the application ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4990</td>\n",
       "      <td>data loss prevention (dlp)</td>\n",
       "      <td>In the context of AI/ML, Data Loss Prevention ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4991</td>\n",
       "      <td>data management</td>\n",
       "      <td>Data management in AI/ML is the end-to-end pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4992</td>\n",
       "      <td>data management (ai training)</td>\n",
       "      <td>Data management for AI training encompasses th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4993</td>\n",
       "      <td>data management (ai)</td>\n",
       "      <td>Data management for AI is the end-to-end proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4994</td>\n",
       "      <td>data management (for ai)</td>\n",
       "      <td>Data management for AI is the end-to-end proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4995</td>\n",
       "      <td>data management for ai</td>\n",
       "      <td>Data management for AI is the process of acqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4996</td>\n",
       "      <td>data management for ml</td>\n",
       "      <td>Data management for ML is a specialized discip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4997</td>\n",
       "      <td>data manipulation</td>\n",
       "      <td>Data manipulation is the process of programmat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4998</td>\n",
       "      <td>data mapping</td>\n",
       "      <td>Data mapping is the process of establishing a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4999</td>\n",
       "      <td>data masking</td>\n",
       "      <td>Data masking is a process of creating a struct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5000</td>\n",
       "      <td>data memorisation</td>\n",
       "      <td>Data memorization is a form of overfitting whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5001</td>\n",
       "      <td>data memorization</td>\n",
       "      <td>Data memorization is a phenomenon where a mode...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                           term  \\\n",
       "0   4982      data lifecycle management   \n",
       "1   4983                   data lineage   \n",
       "2   4984                  data literacy   \n",
       "3   4985                   data loaders   \n",
       "4   4986                   data loading   \n",
       "5   4987      data loading optimization   \n",
       "6   4988                   data logging   \n",
       "7   4989      data loss prevention (ai)   \n",
       "8   4990     data loss prevention (dlp)   \n",
       "9   4991                data management   \n",
       "10  4992  data management (ai training)   \n",
       "11  4993           data management (ai)   \n",
       "12  4994       data management (for ai)   \n",
       "13  4995         data management for ai   \n",
       "14  4996         data management for ml   \n",
       "15  4997              data manipulation   \n",
       "16  4998                   data mapping   \n",
       "17  4999                   data masking   \n",
       "18  5000              data memorisation   \n",
       "19  5001              data memorization   \n",
       "\n",
       "                                           definition  \n",
       "0   Data lifecycle management in AI/ML is the end-...  \n",
       "1   In AI/ML, data lineage is the process of track...  \n",
       "2   Data literacy in the context of AI/ML is the a...  \n",
       "3   Data loaders are utilities that provide an ite...  \n",
       "4   Data loading is the process of reading data fr...  \n",
       "5   Data loading optimization refers to the set of...  \n",
       "6   In machine learning, data logging is the syste...  \n",
       "7   Data loss prevention in AI is the application ...  \n",
       "8   In the context of AI/ML, Data Loss Prevention ...  \n",
       "9   Data management in AI/ML is the end-to-end pro...  \n",
       "10  Data management for AI training encompasses th...  \n",
       "11  Data management for AI is the end-to-end proce...  \n",
       "12  Data management for AI is the end-to-end proce...  \n",
       "13  Data management for AI is the process of acqui...  \n",
       "14  Data management for ML is a specialized discip...  \n",
       "15  Data manipulation is the process of programmat...  \n",
       "16  Data mapping is the process of establishing a ...  \n",
       "17  Data masking is a process of creating a struct...  \n",
       "18  Data memorization is a form of overfitting whe...  \n",
       "19  Data memorization is a phenomenon where a mode...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 1 (standart)\n",
    "# Terms definition with Azure OpenAI\n",
    "# Uses DIAL_API_KEY from environment. Outputs CSV: id, term, definition\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from typing import List, Dict\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Ensure topics dataframe (topic_items) exists\n",
    "if 'topic_items' not in globals():\n",
    "    raise RuntimeError(\"'topic_items' DataFrame not found. Run previous cells that build it.\")\n",
    "if not set(['id','topic']).issubset(topic_items.columns):\n",
    "    raise ValueError(\"topic_items must contain 'id' and 'topic' columns.\")\n",
    "\n",
    "DIAL_API_KEY = os.getenv('DIAL_API_KEY')\n",
    "if not DIAL_API_KEY:\n",
    "    raise EnvironmentError(\"DIAL_API_KEY environment variable is not set. Add it to .env or your session.\")\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = \"https://ai-proxy.lab.epam.com\"\n",
    "# Choose a deployment that supports web search / tools (adjust if needed)\n",
    "AZURE_OPENAI_DEPLOYMENT = \"gemini-2.5-pro\" \n",
    "#AZURE_OPENAI_DEPLOYMENT = \"gemini-2.5-pro-google-search\"  # fallback to \"gemini-2.5-pro\" if not available\n",
    "API_VERSION = \"2025-04-01-preview\"\n",
    "\n",
    "# Config\n",
    "OUTPUT_FILE = f\"topics_definitions_{date.today()}_3.csv\"  \n",
    "BATCH_SIZE = 20\n",
    "SLEEP_BETWEEN_CALLS = 2.0  # adjust for rate limits\n",
    "TEMPERATURE = 0\n",
    "\n",
    "SYSTEM_MESSAGE = (\n",
    "    \"You are a talent recruiter building a canonical AI skills glossary. \"\n",
    "    \"Provide a concise 1-2 sentence definition for each AI-related term. \"\n",
    "    \"Be precise, neutral, and industry-standard; avoid marketing fluff.\"\n",
    ")\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Please define the term \"{text}\" strictly in the context of AI / Machine Learning.\n",
    "Use web search to provide the most current and reliable definition.\n",
    "Return ONLY the definition (1-2 sentences). Do not include preambles, lists, or quotes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_MESSAGE),\n",
    "    (\"human\", PROMPT_TEMPLATE),\n",
    "])\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=DIAL_API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT,\n",
    "    temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Helper batching\n",
    "def batch_iterable(items: List[Dict], size: int):\n",
    "    for i in range(0, len(items), size):\n",
    "        yield items[i:i+size]\n",
    "\n",
    "# Prepare inputs\n",
    "df_terms = topic_items.dropna(subset=[\"topic\"]).copy()\n",
    "print(f\"Rows to process (after dropping NaN topics): {len(df_terms)}\")\n",
    "\n",
    "payloads = [{\"id\": int(row.id), \"text\": str(row.topic).strip()} for row in df_terms.itertuples(index=False) if str(row.topic).strip()]\n",
    "print(f\"Total payloads: {len(payloads)}\")\n",
    "\n",
    "# Process\n",
    "ts_start = datetime.now()\n",
    "print('Start:', ts_start)\n",
    "results = []\n",
    "errors = 0\n",
    "batches_total = (len(payloads) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "processed_batches = 0\n",
    "print(f\"Processed batches: 0/{batches_total}\", end='', flush=True)\n",
    "\n",
    "for batch in batch_iterable(payloads, BATCH_SIZE):\n",
    "    try:\n",
    "        batch_inputs = [{\"text\": item[\"text\"]} for item in batch]\n",
    "        outputs = chain.batch(batch_inputs)\n",
    "        for item, definition in zip(batch, outputs):\n",
    "            definition_clean = (definition or \"\").strip().replace(\"\\n\", \" \")\n",
    "            definition_clean = ' '.join(definition_clean.split())  # collapse whitespace\n",
    "            results.append({\"id\": item[\"id\"], \"term\": item[\"text\"], \"definition\": definition_clean})\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"\\nError in batch {processed_batches+1}: {e}\")\n",
    "        # Add empty definitions so ID alignment is preserved\n",
    "        for item in batch:\n",
    "            results.append({\"id\": item[\"id\"], \"term\": item[\"text\"], \"definition\": \"\"})\n",
    "    finally:\n",
    "        processed_batches += 1\n",
    "        print(f\"\\rProcessed batches: {processed_batches}/{batches_total}\", end='', flush=True)\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "print()  # newline\n",
    "\n",
    "# Build DataFrame\n",
    "df_definitions = pd.DataFrame(results, columns=[\"id\",\"term\",\"definition\"]).sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "# Stats\n",
    "ts_end = datetime.now()\n",
    "print('Finish:', ts_end)\n",
    "print('Processing time:', ts_end - ts_start)\n",
    "print('Terms processed:', len(df_definitions))\n",
    "print('Batches with errors:', errors)\n",
    "empty_defs = (df_definitions[\"definition\"].str.len() == 0).sum()\n",
    "print('Empty definitions:', empty_defs)\n",
    "\n",
    "# Save\n",
    "output_path = os.path.join(folder_path, OUTPUT_FILE)\n",
    "df_definitions.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "# Preview\n",
    "df_definitions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128127c",
   "metadata": {},
   "source": [
    "### 2. Web search version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "405e7a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool binding failed, falling back to base model. Reason: 'NoneType' object has no attribute 'startswith'\n",
      "Rows to process (after dropping NaN topics): 236\n",
      "Total payloads to process: 236\n",
      "Web search tool type: web_search | Web search enabled: False\n",
      "Start time: 2025-11-03 21:15:07.305365\n",
      "Processed batches: 12/12\n",
      "\n",
      "Finish time: 2025-11-03 21:20:32.945990\n",
      "Total processing time: 0:05:25.640625\n",
      "Terms processed: 236\n",
      "Batches with errors: 0\n",
      "Empty definitions: 1\n",
      "Results saved to: C:\\Users\\Denis_Davydov2\\OneDrive - EPAM\\Prophet_AI_docs\\Datasets\\AI_skills\\Topics\\topics_definitions_2025-11-03_g2.csv\n",
      "\n",
      "--- Preview of Definitions ---\n",
      "      id                        term  \\\n",
      "0    244               active recall   \n",
      "1    618                      agones   \n",
      "2   1522                   ai-gradio   \n",
      "3   1710                      almond   \n",
      "4   1959                         any   \n",
      "5   2146         artificial analysis   \n",
      "6   2229                      athena   \n",
      "7   2626                      avc-lm   \n",
      "8   2843             bean validation   \n",
      "9   2888  behavioural canary testing   \n",
      "10  2937                    bfloat11   \n",
      "11  3057                        birl   \n",
      "12  3225         bytecode generation   \n",
      "13  3524                      clairs   \n",
      "14  3932               comet listing   \n",
      "15  4496              cork dampening   \n",
      "16  4600                      crispr   \n",
      "17  4708                     cumulus   \n",
      "18  5585    differential transformer   \n",
      "19  5651                        dior   \n",
      "\n",
      "                                           definition  \n",
      "0   In AI/Machine Learning, \"active recall\" refers...  \n",
      "1   The term \"agones\" does not have a widely recog...  \n",
      "2   Gradio is an open-source Python library that e...  \n",
      "3   Almond is an open-source virtual assistant pla...  \n",
      "4   In AI and Machine Learning, 'any' most commonl...  \n",
      "5   \"Artificial analysis\" in AI/ML refers to the p...  \n",
      "6   In AI/Machine Learning contexts, \"Athena\" most...  \n",
      "7   \"avc-lm\" is not a standard, widely recognized ...  \n",
      "8   In the context of AI/ML, bean validation refer...  \n",
      "9   Behavioural canary testing in AI/ML involves d...  \n",
      "10  Bfloat11 is not a widely recognized or standar...  \n",
      "11  \"Birl\" is not a recognized or standard technic...  \n",
      "12  In AI/ML, bytecode generation refers to compil...  \n",
      "13  \"Clairs\" is not a standard or widely recognize...  \n",
      "14  In the context of AI/Machine Learning, a \"Come...  \n",
      "15  \"Cork dampening\" is not a standard or recogniz...  \n",
      "16  In AI/ML, CRISPR refers to the biological gene...  \n",
      "17  The term \"cumulus\" does not have a standard or...  \n",
      "18  A differential transformer, in the context of ...  \n",
      "19  In the context of AI and Machine Learning, \"di...  \n",
      "\n",
      "\n",
      "Finish time: 2025-11-03 21:20:32.945990\n",
      "Total processing time: 0:05:25.640625\n",
      "Terms processed: 236\n",
      "Batches with errors: 0\n",
      "Empty definitions: 1\n",
      "Results saved to: C:\\Users\\Denis_Davydov2\\OneDrive - EPAM\\Prophet_AI_docs\\Datasets\\AI_skills\\Topics\\topics_definitions_2025-11-03_g2.csv\n",
      "\n",
      "--- Preview of Definitions ---\n",
      "      id                        term  \\\n",
      "0    244               active recall   \n",
      "1    618                      agones   \n",
      "2   1522                   ai-gradio   \n",
      "3   1710                      almond   \n",
      "4   1959                         any   \n",
      "5   2146         artificial analysis   \n",
      "6   2229                      athena   \n",
      "7   2626                      avc-lm   \n",
      "8   2843             bean validation   \n",
      "9   2888  behavioural canary testing   \n",
      "10  2937                    bfloat11   \n",
      "11  3057                        birl   \n",
      "12  3225         bytecode generation   \n",
      "13  3524                      clairs   \n",
      "14  3932               comet listing   \n",
      "15  4496              cork dampening   \n",
      "16  4600                      crispr   \n",
      "17  4708                     cumulus   \n",
      "18  5585    differential transformer   \n",
      "19  5651                        dior   \n",
      "\n",
      "                                           definition  \n",
      "0   In AI/Machine Learning, \"active recall\" refers...  \n",
      "1   The term \"agones\" does not have a widely recog...  \n",
      "2   Gradio is an open-source Python library that e...  \n",
      "3   Almond is an open-source virtual assistant pla...  \n",
      "4   In AI and Machine Learning, 'any' most commonl...  \n",
      "5   \"Artificial analysis\" in AI/ML refers to the p...  \n",
      "6   In AI/Machine Learning contexts, \"Athena\" most...  \n",
      "7   \"avc-lm\" is not a standard, widely recognized ...  \n",
      "8   In the context of AI/ML, bean validation refer...  \n",
      "9   Behavioural canary testing in AI/ML involves d...  \n",
      "10  Bfloat11 is not a widely recognized or standar...  \n",
      "11  \"Birl\" is not a recognized or standard technic...  \n",
      "12  In AI/ML, bytecode generation refers to compil...  \n",
      "13  \"Clairs\" is not a standard or widely recognize...  \n",
      "14  In the context of AI/Machine Learning, a \"Come...  \n",
      "15  \"Cork dampening\" is not a standard or recogniz...  \n",
      "16  In AI/ML, CRISPR refers to the biological gene...  \n",
      "17  The term \"cumulus\" does not have a standard or...  \n",
      "18  A differential transformer, in the context of ...  \n",
      "19  In the context of AI and Machine Learning, \"di...  \n"
     ]
    }
   ],
   "source": [
    "#Version 2 with web search (robust error handling)\n",
    "\"\"\"\n",
    "Terms definition with Azure OpenAI (web-search/tool-enabled deployment).\n",
    "Adds defensive checks against NoneType errors on tool binding and batch execution.\n",
    "\n",
    "Output CSV format: id, term, definition\n",
    "\"\"\"\n",
    "\n",
    "# --- Imports ---\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# --- Environment & Pre-flight Checks ---\n",
    "if 'topic_items' not in globals():\n",
    "    raise RuntimeError(\"'topic_items' DataFrame not found. Please run the preceding cells that create it.\")\n",
    "if not {'id', 'topic'}.issubset(topic_items.columns):\n",
    "    raise ValueError(\"The 'topic_items' DataFrame must contain 'id' and 'topic' columns.\")\n",
    "\n",
    "\n",
    "# =============================== Configuration ==========================================\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://ai-proxy.lab.epam.com\")\n",
    "#AZURE_OPENAI_DEPLOYMENT = 'gpt-5-mini-2025-08-07'\n",
    "AZURE_OPENAI_DEPLOYMENT = 'gemini-2.5-flash'\n",
    "#AZURE_OPENAI_DEPLOYMENT = 'gemini-2.5-pro-google-search'\n",
    "#AZURE_OPENAI_DEPLOYMENT = 'gemini-2.5-pro'\n",
    "\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-04-01-preview\")\n",
    "\n",
    "# Infer search tool type safely\n",
    "SEARCH_TOOL_TYPE = os.getenv(\"AZURE_OPENAI_SEARCH_TOOL_TYPE\") or (\n",
    "    \"google_search\" if \"google\" in (AZURE_OPENAI_DEPLOYMENT or \"\").lower() else \"web_search\"\n",
    ")\n",
    "\n",
    "OUTPUT_FILE = f\"topics_definitions_{date.today()}_g2.csv\"\n",
    "BATCH_SIZE = 20\n",
    "SLEEP_BETWEEN_CALLS = 2.0\n",
    "TEMPERATURE = 0\n",
    "MAX_RETRIES = 0\n",
    "\n",
    "SYSTEM_MESSAGE = (\n",
    "    \"You are a talent recruiter building a canonical AI skills glossary. \"\n",
    "    \"Provide a concise 1-2 sentence definition for each AI-related term. \"\n",
    "    \"Be precise, neutral, and industry-standard; avoid marketing fluff. \"\n",
    "    \"Prefer up-to-date and authoritative sources when using web search.\"\n",
    ")\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Please define the term \"{text}\" strictly in the context of AI / Machine Learning.\n",
    "Use web search when helpful to provide the most current and reliable definition.\n",
    "Return ONLY the definition (1-2 sentences). Do not include preambles, lists, or quotes.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_MESSAGE),\n",
    "    (\"human\", PROMPT_TEMPLATE),\n",
    "])\n",
    "\n",
    "# --- Model Initialization with Safe Tool Binding ---\n",
    "base_model = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=DIAL_API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT,\n",
    "    #temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "WEB_SEARCH_ENABLED = False\n",
    "model = base_model\n",
    "\n",
    "# Attempt tool binding only if SEARCH_TOOL_TYPE seems valid\n",
    "if isinstance(SEARCH_TOOL_TYPE, str) and SEARCH_TOOL_TYPE.strip():\n",
    "    tools = [{\"type\": SEARCH_TOOL_TYPE.strip()}]\n",
    "    try:\n",
    "        candidate = base_model.bind(tools=tools)\n",
    "        # Quick dry-run call to ensure the bound model works; single trivial invocation\n",
    "        _ = (prompt | candidate | StrOutputParser()).invoke({\"text\": \"ai\"})\n",
    "        model = candidate\n",
    "        WEB_SEARCH_ENABLED = True\n",
    "    except Exception as e:\n",
    "        print(f\"Tool binding failed, falling back to base model. Reason: {e}\")\n",
    "        WEB_SEARCH_ENABLED = False\n",
    "else:\n",
    "    print(\"No valid SEARCH_TOOL_TYPE provided; continuing without tools.\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def batch_iterable(items: List[Dict], size: int):\n",
    "    for i in range(0, len(items), size):\n",
    "        yield items[i:i + size]\n",
    "\n",
    "def run_batch_with_retries(batch_inputs, retries=MAX_RETRIES, sleep=SLEEP_BETWEEN_CALLS):\n",
    "    last_err: Optional[Exception] = None\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            return chain.batch(batch_inputs)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if attempt < retries:\n",
    "                # Exponential backoff\n",
    "                backoff = sleep * (1.5 ** attempt)\n",
    "                print(f\"Retry {attempt+1}/{retries} after error: {e}. Sleeping {backoff:.1f}s\")\n",
    "                time.sleep(backoff)\n",
    "            else:\n",
    "                raise e\n",
    "    if last_err:\n",
    "        raise last_err\n",
    "\n",
    "# --- Data Preparation ---\n",
    "df_terms = topic_items.dropna(subset=[\"topic\"]).copy()\n",
    "# Defensive strip & filter\n",
    "payloads = []\n",
    "for row in df_terms.itertuples(index=False):\n",
    "    raw = getattr(row, 'topic', '')\n",
    "    if raw is None:\n",
    "        continue\n",
    "    text = str(raw).strip()\n",
    "    if not text:\n",
    "        continue\n",
    "    payloads.append({\"id\": int(row.id), \"text\": text})\n",
    "\n",
    "print(f\"Rows to process (after dropping NaN topics): {len(df_terms)}\")\n",
    "print(f\"Total payloads to process: {len(payloads)}\")\n",
    "print(f\"Web search tool type: {SEARCH_TOOL_TYPE} | Web search enabled: {WEB_SEARCH_ENABLED}\")\n",
    "\n",
    "# --- Main Processing Loop ---\n",
    "ts_start = datetime.now()\n",
    "print(f'Start time: {ts_start}')\n",
    "\n",
    "results = []\n",
    "errors = 0\n",
    "batches_total = (len(payloads) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "processed_batches = 0\n",
    "print(f\"Processed batches: 0/{batches_total}\", end='', flush=True)\n",
    "\n",
    "for batch in batch_iterable(payloads, BATCH_SIZE):\n",
    "    try:\n",
    "        batch_inputs = [{\"text\": item[\"text\"]} for item in batch]\n",
    "        outputs = run_batch_with_retries(batch_inputs)\n",
    "        for item, definition in zip(batch, outputs):\n",
    "            definition_clean = (definition or \"\").strip().replace(\"\\n\", \" \")\n",
    "            definition_clean = ' '.join(definition_clean.split())\n",
    "            results.append({\"id\": item[\"id\"], \"term\": item[\"text\"], \"definition\": definition_clean})\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"\\nError processing batch {processed_batches + 1}: {e}\")\n",
    "        for item in batch:\n",
    "            results.append({\"id\": item[\"id\"], \"term\": item[\"text\"], \"definition\": \"\"})\n",
    "    finally:\n",
    "        processed_batches += 1\n",
    "        print(f\"\\rProcessed batches: {processed_batches}/{batches_total}\", end='', flush=True)\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Results, Statistics, and Saving ---\n",
    "df_definitions = pd.DataFrame(results, columns=[\"id\", \"term\", \"definition\"]).sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "ts_end = datetime.now()\n",
    "print(f'Finish time: {ts_end}')\n",
    "print(f'Total processing time: {ts_end - ts_start}')\n",
    "print(f'Terms processed: {len(df_definitions)}')\n",
    "print(f'Batches with errors: {errors}')\n",
    "empty_defs = (df_definitions[\"definition\"].str.len() == 0).sum()\n",
    "print(f'Empty definitions: {empty_defs}')\n",
    "\n",
    "if 'folder_path' not in globals():\n",
    "    folder_path = os.getcwd()\n",
    "output_path = os.path.join(folder_path, OUTPUT_FILE)\n",
    "df_definitions.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "print(\"\\n--- Preview of Definitions ---\")\n",
    "print(df_definitions.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b9116",
   "metadata": {},
   "source": [
    "#### Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c43914a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: C:\\Users\\Denis_Davydov2\\OneDrive - EPAM\\Prophet_AI_docs\\Datasets\\AI_skills\\Topics\\topics_defenition_2025-10-31.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "output_path = os.path.join(folder_path, OUTPUT_FILE)\n",
    "df_definitions.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33b503",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2a32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
